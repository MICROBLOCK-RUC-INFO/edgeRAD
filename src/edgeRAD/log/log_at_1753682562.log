2025-07-28 14:02:42 - DEBUG - Using actor
2025-07-28 14:02:42 - DEBUG - 
start of episode 0, step 0

2025-07-28 14:02:42 - DEBUG - State: [0.97456986 0.973902   0.97325563 0.9726309  0.97202796 0.9714469
 0.9708877  0.97035074 0.9698359  0.96934336]
2025-07-28 14:02:42 - DEBUG - Action: [4.78206   5.155346  4.8394904 4.8231177 4.7775955 5.19403   4.9406395
 4.8935623 4.831395  4.875862 ]
2025-07-28 14:02:42 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:42 - DEBUG - Reward: -9.978197282870564
2025-07-28 14:02:42 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895869 -0.91895869 -0.91895869 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:42 - DEBUG - Next state: [0.96687496 0.9643648  0.9632686  0.9638134  0.9638407  0.96490395
 0.9680768  0.9734513  0.980887   0.98876095]
2025-07-28 14:02:42 - DEBUG - 
end of episode 0, step 0, episode_reward -9.978197282870564, reward -9.978197282870564

2025-07-28 14:02:42 - DEBUG - Using actor
2025-07-28 14:02:42 - DEBUG - 
start of episode 0, step 1

2025-07-28 14:02:42 - DEBUG - State: [0.96687496 0.9643648  0.9632686  0.9638134  0.9638407  0.96490395
 0.9680768  0.9734513  0.980887   0.98876095]
2025-07-28 14:02:42 - DEBUG - Action: [4.7821255 5.1551285 4.839636  4.823613  4.777392  5.1938004 4.9403963
 4.8933573 4.8318057 4.8756313]
2025-07-28 14:02:42 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:42 - DEBUG - Reward: -9.978197276803861
2025-07-28 14:02:42 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:42 - DEBUG - Next state: [0.9942909 0.9983998 0.9999733 1.        1.        1.        1.
 1.        1.        1.       ]
2025-07-28 14:02:42 - DEBUG - 
end of episode 0, step 1, episode_reward -19.956394559674425, reward -9.978197276803861

2025-07-28 14:02:42 - DEBUG - Using actor
2025-07-28 14:02:42 - DEBUG - 
start of episode 0, step 2

2025-07-28 14:02:42 - DEBUG - State: [0.9942909 0.9983998 0.9999733 1.        1.        1.        1.
 1.        1.        1.       ]
2025-07-28 14:02:42 - DEBUG - Action: [4.7821965 5.1552153 4.83939   4.8219986 4.7779875 5.1944823 4.940702
 4.892304  4.8311863 4.8758097]
2025-07-28 14:02:42 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:42 - DEBUG - Reward: -9.97819728508548
2025-07-28 14:02:42 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895869 -0.91895869 -0.91895869]
2025-07-28 14:02:42 - DEBUG - Next state: [1.         1.         0.9999998  0.9995809  0.995066   0.98486686
 0.9741948  0.9645794  0.9560667  0.9486979 ]
2025-07-28 14:02:42 - DEBUG - 
end of episode 0, step 2, episode_reward -29.934591844759908, reward -9.97819728508548

2025-07-28 14:02:42 - DEBUG - Using actor
2025-07-28 14:02:42 - DEBUG - 
start of episode 0, step 3

2025-07-28 14:02:42 - DEBUG - State: [1.         1.         0.9999998  0.9995809  0.995066   0.98486686
 0.9741948  0.9645794  0.9560667  0.9486979 ]
2025-07-28 14:02:42 - DEBUG - Action: [4.7821918 5.155608  4.8389463 4.822059  4.778009  5.1945887 4.9410734
 4.893282  4.8305006 4.8765287]
2025-07-28 14:02:42 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:42 - DEBUG - Reward: -9.978197296072434
2025-07-28 14:02:42 - DEBUG - Reward array: [-0.91895869 -1.3132639  -0.91895869 -0.91895869 -0.91895869 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:42 - DEBUG - Next state: [0.9422757  0.93996686 0.9446321  0.95170313 0.95993125 0.9692678
 0.9796874  0.99076134 0.9984488  1.        ]
2025-07-28 14:02:42 - DEBUG - 
end of episode 0, step 3, episode_reward -39.912789140832345, reward -9.978197296072434

2025-07-28 14:02:42 - DEBUG - Using actor
2025-07-28 14:02:42 - DEBUG - 
start of episode 0, step 4

2025-07-28 14:02:42 - DEBUG - State: [0.9422757  0.93996686 0.9446321  0.95170313 0.95993125 0.9692678
 0.9796874  0.99076134 0.9984488  1.        ]
2025-07-28 14:02:42 - DEBUG - Action: [4.7815847 5.154412  4.8401203 4.8243065 4.7771144 5.1935387 4.9400015
 4.8935194 4.832416  4.875059 ]
2025-07-28 14:02:42 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:42 - DEBUG - Reward: -9.978197276770423
2025-07-28 14:02:42 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:42 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:42 - DEBUG - 
end of episode 0, step 4, episode_reward -49.89098641760277, reward -9.978197276770423

2025-07-28 14:02:42 - DEBUG - Using actor
2025-07-28 14:02:42 - DEBUG - 
start of episode 0, step 5

2025-07-28 14:02:42 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:42 - DEBUG - Action: [4.7822156 5.155298  4.839348  4.821914  4.778039  5.1944966 4.940769
 4.8922772 4.8311267 4.8758483]
2025-07-28 14:02:42 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:42 - DEBUG - Reward: -9.978197276770423
2025-07-28 14:02:42 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:42 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:42 - DEBUG - 
end of episode 0, step 5, episode_reward -59.86918369437319, reward -9.978197276770423

2025-07-28 14:02:42 - DEBUG - Using actor
2025-07-28 14:02:42 - DEBUG - 
start of episode 0, step 6

2025-07-28 14:02:42 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:42 - DEBUG - Action: [4.7822156 5.155298  4.839348  4.821914  4.778039  5.1944966 4.940769
 4.8922772 4.8311267 4.8758483]
2025-07-28 14:02:42 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:42 - DEBUG - Reward: -9.978197276770423
2025-07-28 14:02:42 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:42 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:42 - DEBUG - 
end of episode 0, step 6, episode_reward -69.84738097114362, reward -9.978197276770423

2025-07-28 14:02:42 - DEBUG - Using actor
2025-07-28 14:02:42 - DEBUG - 
start of episode 0, step 7

2025-07-28 14:02:42 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:42 - DEBUG - Action: [4.7822156 5.155298  4.839348  4.821914  4.778039  5.1944966 4.940769
 4.8922772 4.8311267 4.8758483]
2025-07-28 14:02:42 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:42 - DEBUG - Reward: -9.978197276948581
2025-07-28 14:02:42 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:42 - DEBUG - Next state: [1.         1.         0.99997926 0.99960554 0.9985229  0.99714196
 0.9953085  0.9937478  0.992466   0.9914209 ]
2025-07-28 14:02:42 - DEBUG - 
end of episode 0, step 7, episode_reward -79.8255782480922, reward -9.978197276948581

2025-07-28 14:02:42 - DEBUG - Using actor
2025-07-28 14:02:42 - DEBUG - 
start of episode 0, step 8

2025-07-28 14:02:42 - DEBUG - State: [1.         1.         0.99997926 0.99960554 0.9985229  0.99714196
 0.9953085  0.9937478  0.992466   0.9914209 ]
2025-07-28 14:02:42 - DEBUG - Action: [4.7822556 5.155385  4.839284  4.821923  4.7780495 5.194496  4.9408107
 4.8924575 4.8310223 4.8759384]
2025-07-28 14:02:42 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:42 - DEBUG - Reward: -9.978197277039085
2025-07-28 14:02:42 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:42 - DEBUG - Next state: [0.9906378  0.9904001  0.99044085 0.9914749  0.9928021  0.994406
 0.99627584 0.9980667  0.9992404  0.9999914 ]
2025-07-28 14:02:42 - DEBUG - 
end of episode 0, step 8, episode_reward -89.80377552513129, reward -9.978197277039085

2025-07-28 14:02:42 - DEBUG - Using actor
2025-07-28 14:02:42 - DEBUG - 
start of episode 0, step 9

2025-07-28 14:02:42 - DEBUG - State: [0.9906378  0.9904001  0.99044085 0.9914749  0.9928021  0.994406
 0.99627584 0.9980667  0.9992404  0.9999914 ]
2025-07-28 14:02:42 - DEBUG - Action: [4.7821145 5.1551795 4.839451  4.8223376 4.777898  5.1943197 4.9406466
 4.8925    4.8313355 4.875709 ]
2025-07-28 14:02:42 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:42 - DEBUG - Reward: -9.978197277252029
2025-07-28 14:02:42 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:42 - DEBUG - Next state: [1.         0.9999905  0.9998071  0.99898404 0.9971627  0.994509
 0.99095714 0.9875088  0.9853153  0.9839052 ]
2025-07-28 14:02:42 - DEBUG - 
end of episode 0, step 9, episode_reward -99.78197280238331, reward -9.978197277252029

2025-07-28 14:02:42 - DEBUG - Using actor
2025-07-28 14:02:42 - DEBUG - 
start of episode 0, step 10

2025-07-28 14:02:42 - DEBUG - State: [1.         0.9999905  0.9998071  0.99898404 0.9971627  0.994509
 0.99095714 0.9875088  0.9853153  0.9839052 ]
2025-07-28 14:02:42 - DEBUG - Action: [4.7822976 5.1554537 4.8392286 4.8219495 4.778044  5.194488  4.940862
 4.892614  4.8309383 4.8760376]
2025-07-28 14:02:42 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:42 - DEBUG - Reward: -9.978197278027478
2025-07-28 14:02:42 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:42 - DEBUG - Next state: [0.98272735 0.9813915  0.9797291  0.9789344  0.9801186  0.98276263
 0.9866699  0.9905288  0.992401   0.99092346]
2025-07-28 14:02:42 - DEBUG - 
end of episode 0, step 10, episode_reward -109.76017008041079, reward -9.978197278027478

2025-07-28 14:02:42 - DEBUG - Using actor
2025-07-28 14:02:42 - DEBUG - 
start of episode 0, step 11

2025-07-28 14:02:42 - DEBUG - State: [0.98272735 0.9813915  0.9797291  0.9789344  0.9801186  0.98276263
 0.9866699  0.9905288  0.992401   0.99092346]
2025-07-28 14:02:42 - DEBUG - Action: [4.782032  5.15521   4.83954   4.8227506 4.777722  5.194195  4.9405975
 4.892961  4.8314757 4.87568  ]
2025-07-28 14:02:42 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:42 - DEBUG - Reward: -10.352251504207933
2025-07-28 14:02:42 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.9189587  -0.91895925 -0.91898228 -1.31331971
 -0.92209694 -0.93654345 -0.99689461 -1.19427398]
2025-07-28 14:02:42 - DEBUG - Next state: [0.9860867  0.9700923  0.93511033 0.8871517  0.83332056 0.7859878
 0.7484976  0.71226466 0.6764393  0.6410097 ]
2025-07-28 14:02:42 - DEBUG - 
end of episode 0, step 11, episode_reward -120.11242158461872, reward -10.352251504207933

2025-07-28 14:02:42 - DEBUG - Using actor
2025-07-28 14:02:42 - DEBUG - 
start of episode 0, step 12

2025-07-28 14:02:42 - DEBUG - State: [0.9860867  0.9700923  0.93511033 0.8871517  0.83332056 0.7859878
 0.7484976  0.71226466 0.6764393  0.6410097 ]
2025-07-28 14:02:42 - DEBUG - Action: [4.780242  5.159835  4.838239  4.8260794 4.7769837 5.19681   4.945406
 4.9002166 4.8340096 4.883233 ]
2025-07-28 14:02:42 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:42 - DEBUG - Reward: -11.237345184360848
2025-07-28 14:02:42 - DEBUG - Reward array: [-1.57094559 -1.70474381 -1.11908306 -0.9342965  -0.91917754 -1.31326394
 -0.91895869 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:42 - DEBUG - Next state: [0.6125545  0.61147755 0.650542   0.71531636 0.7972311  0.87989736
 0.9441154  0.98503244 0.9998644  1.        ]
2025-07-28 14:02:42 - DEBUG - 
end of episode 0, step 12, episode_reward -131.34976676897958, reward -11.237345184360848

2025-07-28 14:02:42 - DEBUG - Using actor
2025-07-28 14:02:42 - DEBUG - 
start of episode 0, step 13

2025-07-28 14:02:42 - DEBUG - State: [0.6125545  0.61147755 0.650542   0.71531636 0.7972311  0.87989736
 0.9441154  0.98503244 0.9998644  1.        ]
2025-07-28 14:02:42 - DEBUG - Action: [4.774223  5.1505303 4.841257  4.828324  4.7684174 5.1899886 4.9374437
 4.897578  4.8428693 4.8744626]
2025-07-28 14:02:42 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:42 - DEBUG - Reward: -9.978197276770423
2025-07-28 14:02:42 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:42 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:42 - DEBUG - 
end of episode 0, step 13, episode_reward -141.32796404575, reward -9.978197276770423

2025-07-28 14:02:42 - DEBUG - Using actor
2025-07-28 14:02:42 - DEBUG - 
start of episode 0, step 14

2025-07-28 14:02:42 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:42 - DEBUG - Action: [4.7822156 5.155298  4.839348  4.821914  4.778039  5.1944966 4.940769
 4.8922772 4.8311267 4.8758483]
2025-07-28 14:02:42 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:42 - DEBUG - Reward: -9.978197276770423
2025-07-28 14:02:42 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:42 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:42 - DEBUG - 
end of episode 0, step 14, episode_reward -151.30616132252044, reward -9.978197276770423

2025-07-28 14:02:42 - DEBUG - Using actor
2025-07-28 14:02:42 - DEBUG - 
start of episode 0, step 15

2025-07-28 14:02:42 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:42 - DEBUG - Action: [4.7822156 5.155298  4.839348  4.821914  4.778039  5.1944966 4.940769
 4.8922772 4.8311267 4.8758483]
2025-07-28 14:02:42 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:42 - DEBUG - Reward: -9.978197276770423
2025-07-28 14:02:42 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:42 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:42 - DEBUG - 
end of episode 0, step 15, episode_reward -161.28435859929087, reward -9.978197276770423

2025-07-28 14:02:42 - DEBUG - Using actor
2025-07-28 14:02:42 - DEBUG - 
start of episode 0, step 16

2025-07-28 14:02:42 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:42 - DEBUG - Action: [4.7822156 5.155298  4.839348  4.821914  4.778039  5.1944966 4.940769
 4.8922772 4.8311267 4.8758483]
2025-07-28 14:02:42 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:42 - DEBUG - Reward: -9.978197277076426
2025-07-28 14:02:42 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:42 - DEBUG - Next state: [1.         1.         1.         1.         1.         0.9999389
 0.99873674 0.9945885  0.9885489  0.98292816]
2025-07-28 14:02:42 - DEBUG - 
end of episode 0, step 16, episode_reward -171.2625558763673, reward -9.978197277076426

2025-07-28 14:02:42 - DEBUG - Using actor
2025-07-28 14:02:42 - DEBUG - 
start of episode 0, step 17

2025-07-28 14:02:42 - DEBUG - State: [1.         1.         1.         1.         1.         0.9999389
 0.99873674 0.9945885  0.9885489  0.98292816]
2025-07-28 14:02:42 - DEBUG - Action: [4.782104  5.155397  4.8393006 4.8218246 4.778082  5.194571  4.9408736
 4.892592  4.8309655 4.875984 ]
2025-07-28 14:02:42 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:42 - DEBUG - Reward: -9.978197279880149
2025-07-28 14:02:42 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:42 - DEBUG - Next state: [0.9782485  0.97453856 0.9716754  0.96961385 0.9699757  0.97226644
 0.9754109  0.97954404 0.98463774 0.99062514]
2025-07-28 14:02:42 - DEBUG - 
end of episode 0, step 17, episode_reward -181.24075315624742, reward -9.978197279880149

2025-07-28 14:02:42 - DEBUG - Using actor
2025-07-28 14:02:42 - DEBUG - 
start of episode 0, step 18

2025-07-28 14:02:42 - DEBUG - State: [0.9782485  0.97453856 0.9716754  0.96961385 0.9699757  0.97226644
 0.9754109  0.97954404 0.98463774 0.99062514]
2025-07-28 14:02:42 - DEBUG - Action: [4.782166  5.1552434 4.8395486 4.8231664 4.7775583 5.1939926 4.940528
 4.893145  4.8316374 4.8757133]
2025-07-28 14:02:42 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:42 - DEBUG - Reward: -9.978197282252587
2025-07-28 14:02:42 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895869 -0.91895869 -0.91895869]
2025-07-28 14:02:42 - DEBUG - Next state: [0.996357   0.998879   0.99723935 0.99170595 0.9832804  0.9744328
 0.96795934 0.963953   0.96133965 0.9592127 ]
2025-07-28 14:02:42 - DEBUG - 
end of episode 0, step 18, episode_reward -191.2189504385, reward -9.978197282252587

2025-07-28 14:02:42 - DEBUG - Using actor
2025-07-28 14:02:42 - DEBUG - 
start of episode 0, step 19

2025-07-28 14:02:42 - DEBUG - State: [0.996357   0.998879   0.99723935 0.99170595 0.9832804  0.9744328
 0.96795934 0.963953   0.96133965 0.9592127 ]
2025-07-28 14:02:42 - DEBUG - Action: [4.7824583 5.155657  4.83907   4.822289  4.777895  5.1945095 4.9409704
 4.8932858 4.8307233 4.8764515]
2025-07-28 14:02:42 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:42 - DEBUG - Reward: -9.978197282279073
2025-07-28 14:02:42 - DEBUG - Reward array: [-0.91895869 -1.3132639  -0.91895869 -0.91895869 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:42 - DEBUG - Next state: [0.9579512  0.95808107 0.96006244 0.964148   0.9709392  0.9800074
 0.98945636 0.9964276  0.99962044 0.9999995 ]
2025-07-28 14:02:42 - DEBUG - 
end of episode 0, step 19, episode_reward -201.19714772077907, reward -9.978197282279073

2025-07-28 14:02:42 - DEBUG - Using actor
2025-07-28 14:02:42 - DEBUG - 
start of episode 0, step 20

2025-07-28 14:02:42 - DEBUG - State: [0.9579512  0.95808107 0.96006244 0.964148   0.9709392  0.9800074
 0.98945636 0.9964276  0.99962044 0.9999995 ]
2025-07-28 14:02:42 - DEBUG - Action: [4.7817235 5.1546497 4.83991   4.823596  4.7773867 5.1938353 4.9401894
 4.8932033 4.8321004 4.8752446]
2025-07-28 14:02:42 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:42 - DEBUG - Reward: -9.978197276770423
2025-07-28 14:02:42 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:42 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:42 - DEBUG - 
end of episode 0, step 20, episode_reward -211.1753449975495, reward -9.978197276770423

2025-07-28 14:02:42 - DEBUG - Using actor
2025-07-28 14:02:42 - DEBUG - 
start of episode 0, step 21

2025-07-28 14:02:42 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:42 - DEBUG - Action: [4.7822156 5.155298  4.839348  4.821914  4.778039  5.1944966 4.940769
 4.8922772 4.8311267 4.8758483]
2025-07-28 14:02:42 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:42 - DEBUG - Reward: -9.978197276770423
2025-07-28 14:02:42 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:42 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:42 - DEBUG - 
end of episode 0, step 21, episode_reward -221.15354227431993, reward -9.978197276770423

2025-07-28 14:02:42 - DEBUG - Using actor
2025-07-28 14:02:42 - DEBUG - 
start of episode 0, step 22

2025-07-28 14:02:42 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:42 - DEBUG - Action: [4.7822156 5.155298  4.839348  4.821914  4.778039  5.1944966 4.940769
 4.8922772 4.8311267 4.8758483]
2025-07-28 14:02:42 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:42 - DEBUG - Reward: -9.978197276770423
2025-07-28 14:02:42 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:42 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:42 - DEBUG - 
end of episode 0, step 22, episode_reward -231.13173955109036, reward -9.978197276770423

2025-07-28 14:02:42 - DEBUG - Using actor
2025-07-28 14:02:42 - DEBUG - 
start of episode 0, step 23

2025-07-28 14:02:43 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:43 - DEBUG - Action: [4.7822156 5.155298  4.839348  4.821914  4.778039  5.1944966 4.940769
 4.8922772 4.8311267 4.8758483]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -9.978197276770423
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:43 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 23, episode_reward -241.1099368278608, reward -9.978197276770423

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 24

2025-07-28 14:02:43 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:43 - DEBUG - Action: [4.7822156 5.155298  4.839348  4.821914  4.778039  5.1944966 4.940769
 4.8922772 4.8311267 4.8758483]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -9.978197276770423
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:43 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 24, episode_reward -251.08813410463122, reward -9.978197276770423

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 25

2025-07-28 14:02:43 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:43 - DEBUG - Action: [4.7822156 5.155298  4.839348  4.821914  4.778039  5.1944966 4.940769
 4.8922772 4.8311267 4.8758483]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -9.978197276770423
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:43 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 25, episode_reward -261.06633138140165, reward -9.978197276770423

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 26

2025-07-28 14:02:43 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:43 - DEBUG - Action: [4.7822156 5.155298  4.839348  4.821914  4.778039  5.1944966 4.940769
 4.8922772 4.8311267 4.8758483]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -9.978197276852836
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:43 - DEBUG - Next state: [1.         1.         1.         1.         1.         1.
 0.9999715  0.99945694 0.997088   0.9906868 ]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 26, episode_reward -271.0445286582545, reward -9.978197276852836

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 27

2025-07-28 14:02:43 - DEBUG - State: [1.         1.         1.         1.         1.         1.
 0.9999715  0.99945694 0.997088   0.9906868 ]
2025-07-28 14:02:43 - DEBUG - Action: [4.7821083 5.155375  4.8393717 4.821848  4.778059  5.194573  4.940837
 4.89246   4.831027  4.8758965]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -9.978197294547194
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895869 -0.91895869 -0.91895869 -1.3132639
 -0.91895869 -0.91895869 -0.91895869 -0.91895869]
2025-07-28 14:02:43 - DEBUG - Next state: [0.9806556  0.97126734 0.9639561  0.9586054  0.95422786 0.95030767
 0.94879067 0.9510928  0.955653   0.96241134]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 27, episode_reward -281.0227259528017, reward -9.978197294547194

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 28

2025-07-28 14:02:43 - DEBUG - State: [0.9806556  0.97126734 0.9639561  0.9586054  0.95422786 0.95030767
 0.94879067 0.9510928  0.955653   0.96241134]
2025-07-28 14:02:43 - DEBUG - Action: [4.782333  5.155678  4.839463  4.8235188 4.777413  5.1939006 4.940857
 4.8938737 4.831441  4.8761773]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -9.978197277423398
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:43 - DEBUG - Next state: [0.9712841  0.98180157 0.99201024 0.9984872  0.99999124 1.
 1.         1.         1.         1.        ]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 28, episode_reward -291.0009232302251, reward -9.978197277423398

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 29

2025-07-28 14:02:43 - DEBUG - State: [0.9712841  0.98180157 0.99201024 0.9984872  0.99999124 1.
 1.         1.         1.         1.        ]
2025-07-28 14:02:43 - DEBUG - Action: [4.781947  5.1548395 4.8395877 4.8225904 4.7778196 5.194202  4.940397
 4.892515  4.831436  4.875524 ]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -9.978197276770423
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:43 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 29, episode_reward -300.9791205069955, reward -9.978197276770423

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 30

2025-07-28 14:02:43 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:43 - DEBUG - Action: [4.7822156 5.155298  4.839348  4.821914  4.778039  5.1944966 4.940769
 4.8922772 4.8311267 4.8758483]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -9.978197276770423
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:43 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 30, episode_reward -310.9573177837659, reward -9.978197276770423

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 31

2025-07-28 14:02:43 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:43 - DEBUG - Action: [4.7822156 5.155298  4.839348  4.821914  4.778039  5.1944966 4.940769
 4.8922772 4.8311267 4.8758483]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -9.978243108929659
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895871 -0.91895972 -0.91900346]
2025-07-28 14:02:43 - DEBUG - Next state: [1.         1.         1.         1.         1.         0.9922929
 0.96795356 0.92902803 0.87892425 0.8232974 ]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 31, episode_reward -320.93556089269555, reward -9.978243108929659

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 32

2025-07-28 14:02:43 - DEBUG - State: [1.         1.         1.         1.         1.         0.9922929
 0.96795356 0.92902803 0.87892425 0.8232974 ]
2025-07-28 14:02:43 - DEBUG - Action: [4.7807045 5.1553593 4.8383493 4.8214283 4.7785616 5.1959276 4.9422827
 4.8952785 4.830087  4.877398 ]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -10.010409041560795
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.919753   -1.31416498 -0.92650015 -0.92666692 -0.92663768 -1.31509118
 -0.92366617 -0.91994685 -0.91902189 -0.91896022]
2025-07-28 14:02:43 - DEBUG - Next state: [0.77454233 0.7424151  0.7306393  0.7301795  0.7302594  0.730282
 0.74037254 0.7705422  0.8177881  0.8734938 ]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 32, episode_reward -330.94596993425637, reward -10.010409041560795

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 33

2025-07-28 14:02:43 - DEBUG - State: [0.77454233 0.7424151  0.7306393  0.7301795  0.7302594  0.730282
 0.74037254 0.7705422  0.8177881  0.8734938 ]
2025-07-28 14:02:43 - DEBUG - Action: [4.779651  5.1563845 4.8434405 4.8319206 4.771331  5.1900816 4.9398603
 4.8982573 4.8357205 4.879684 ]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -9.97819731128763
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.91895872 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:43 - DEBUG - Next state: [0.9244467 0.9647502 0.9903157 0.9968824 0.9917439 0.9857566 0.9804076
 0.9757092 0.9716834 0.9682926]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 33, episode_reward -340.924167245544, reward -9.97819731128763

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 34

2025-07-28 14:02:43 - DEBUG - State: [0.9244467 0.9647502 0.9903157 0.9968824 0.9917439 0.9857566 0.9804076
 0.9757092 0.9716834 0.9682926]
2025-07-28 14:02:43 - DEBUG - Action: [4.781919  5.154503  4.839675  4.8233128 4.777259  5.194011  4.939948
 4.8934817 4.8316174 4.875616 ]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -9.978197278640828
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:43 - DEBUG - Next state: [0.9675934  0.9695486  0.97326887 0.9776671  0.98272747 0.9884283
 0.9945772  0.9986312  0.99999595 1.        ]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 34, episode_reward -350.90236452418486, reward -9.978197278640828

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 35

2025-07-28 14:02:43 - DEBUG - State: [0.9675934  0.9695486  0.97326887 0.9776671  0.98272747 0.9884283
 0.9945772  0.9986312  0.99999595 1.        ]
2025-07-28 14:02:43 - DEBUG - Action: [4.7818274 5.154805  4.839737  4.8231096 4.777587  5.1939945 4.9403124
 4.8928933 4.8317823 4.875378 ]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -9.978197276784652
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:43 - DEBUG - Next state: [1.        1.        1.        1.        1.        1.        1.
 0.9999695 0.9994174 0.9976922]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 35, episode_reward -360.88056180096953, reward -9.978197276784652

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 36

2025-07-28 14:02:43 - DEBUG - State: [1.        1.        1.        1.        1.        1.        1.
 0.9999695 0.9994174 0.9976922]
2025-07-28 14:02:43 - DEBUG - Action: [4.782188  5.1553183 4.839359  4.8218946 4.778041  5.194515  4.9407873
 4.8923225 4.831103  4.8758593]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -9.978197277305068
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:43 - DEBUG - Next state: [0.9958626  0.9942216  0.9927756  0.9915246  0.99043417 0.9898175
 0.9905781  0.9917143  0.9928186  0.98311704]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 36, episode_reward -370.8587590782746, reward -9.978197277305068

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 37

2025-07-28 14:02:43 - DEBUG - State: [0.9958626  0.9942216  0.9927756  0.9915246  0.99043417 0.9898175
 0.9905781  0.9917143  0.9928186  0.98311704]
2025-07-28 14:02:43 - DEBUG - Action: [4.782104  5.155468  4.8394246 4.8221736 4.7779465 5.1944823 4.9408426
 4.8928266 4.831065  4.875917 ]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -18.75957265321992
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.91895869 -1.31326392 -0.91904353 -0.92917336 -1.2241099  -2.40470681
 -3.10344244 -2.74811642 -2.49413261 -2.70462496]
2025-07-28 14:02:43 - DEBUG - Next state: [0.9484603  0.890568   0.8130185  0.7241933  0.6378344  0.5771422
 0.5614697  0.57028157 0.57724726 0.5714288 ]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 37, episode_reward -389.61833173149455, reward -18.75957265321992

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 38

2025-07-28 14:02:43 - DEBUG - State: [0.9484603  0.890568   0.8130185  0.7241933  0.6378344  0.5771422
 0.5614697  0.57028157 0.57724726 0.5714288 ]
2025-07-28 14:02:43 - DEBUG - Action: [4.7813807 5.1623864 4.840061  4.831026  4.773157  5.194716  4.9465103
 4.9009185 4.835438  4.886919 ]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -13.770200460704462
2025-07-28 14:02:43 - DEBUG - Reward array: [-3.10299429 -2.5162359  -1.30838139 -0.93438746 -0.91910275 -1.31326393
 -0.91895869 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:43 - DEBUG - Next state: [0.5614802  0.573408   0.63009137 0.7151851  0.8042835  0.884058
 0.9460268  0.98554045 0.999869   1.        ]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 38, episode_reward -403.388532192199, reward -13.770200460704462

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 39

2025-07-28 14:02:43 - DEBUG - State: [0.5614802  0.573408   0.63009137 0.7151851  0.8042835  0.884058
 0.9460268  0.98554045 0.999869   1.        ]
2025-07-28 14:02:43 - DEBUG - Action: [4.773303  5.1499615 4.8413186 4.8279457 4.767608  5.189722  4.9372764
 4.8974867 4.8442163 4.8743105]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -9.97819727677054
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:43 - DEBUG - Next state: [1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.99997383]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 39, episode_reward -413.36672946896954, reward -9.97819727677054

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 40

2025-07-28 14:02:43 - DEBUG - State: [1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.99997383]
2025-07-28 14:02:43 - DEBUG - Action: [4.782215  5.1552987 4.8393483 4.821914  4.778039  5.1944966 4.9407697
 4.892278  4.831126  4.8758483]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -9.978197331616487
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895869 -1.3132639
 -0.91895869 -0.91895869 -0.9189587  -0.91895871]
2025-07-28 14:02:43 - DEBUG - Next state: [0.99950135 0.99734807 0.99142444 0.9798945  0.9654456  0.9529984
 0.9446301  0.93890077 0.93392503 0.929123  ]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 40, episode_reward -423.34492680058605, reward -9.978197331616487

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 41

2025-07-28 14:02:43 - DEBUG - State: [0.99950135 0.99734807 0.99142444 0.9798945  0.9654456  0.9529984
 0.9446301  0.93890077 0.93392503 0.929123  ]
2025-07-28 14:02:43 - DEBUG - Action: [4.7825055 5.155912  4.838925  4.822575  4.7777886 5.194599  4.9412646
 4.8940363 4.830474  4.8769827]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -9.978197327786525
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.91895871 -1.3132639  -0.9189587  -0.91895869 -0.91895869 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:43 - DEBUG - Next state: [0.9268669  0.9280635  0.9337417  0.94394183 0.958204   0.9744728
 0.98900837 0.9975073  0.99998087 1.        ]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 41, episode_reward -433.32312412837257, reward -9.978197327786525

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 42

2025-07-28 14:02:43 - DEBUG - State: [0.9268669  0.9280635  0.9337417  0.94394183 0.958204   0.9744728
 0.98900837 0.9975073  0.99998087 1.        ]
2025-07-28 14:02:43 - DEBUG - Action: [4.781172  5.154027  4.8403378 4.8245583 4.7770233 5.193405  4.939741
 4.8937697 4.832795  4.8747883]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -9.9781972776346
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:43 - DEBUG - Next state: [1.         1.         1.         0.999984   0.99969745 0.9984013
 0.9948728  0.9879645  0.9798122  0.9733851 ]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 42, episode_reward -443.30132140600716, reward -9.9781972776346

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 43

2025-07-28 14:02:43 - DEBUG - State: [1.         1.         1.         0.999984   0.99969745 0.9984013
 0.9948728  0.9879645  0.9798122  0.9733851 ]
2025-07-28 14:02:43 - DEBUG - Action: [4.782101  5.155439  4.8392234 4.82184   4.7780786 5.1945806 4.940933
 4.892771  4.830858  4.8761067]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -9.97819728373182
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895869 -0.91895869 -0.91895869 -1.3132639
 -0.91895869 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:43 - DEBUG - Next state: [0.96914893 0.96626866 0.963711   0.9612979  0.9607719  0.96217155
 0.9654197  0.9710739  0.9789067  0.98773813]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 43, episode_reward -453.279518689739, reward -9.97819728373182

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 44

2025-07-28 14:02:43 - DEBUG - State: [0.96914893 0.96626866 0.963711   0.9612979  0.9607719  0.96217155
 0.9654197  0.9710739  0.9789067  0.98773813]
2025-07-28 14:02:43 - DEBUG - Action: [4.7821913 5.1552134 4.8396335 4.8236046 4.77736   5.1938396 4.940448
 4.8933773 4.8318114 4.8757157]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -9.978197276795793
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:43 - DEBUG - Next state: [0.9954099 0.9992982 0.9999966 1.        1.        1.        1.
 1.        1.        1.       ]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 44, episode_reward -463.2577159665348, reward -9.978197276795793

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 45

2025-07-28 14:02:43 - DEBUG - State: [0.9954099 0.9992982 0.9999966 1.        1.        1.        1.
 1.        1.        1.       ]
2025-07-28 14:02:43 - DEBUG - Action: [4.7822065 5.1552296 4.8393793 4.821969  4.778     5.1944923 4.9407163
 4.892296  4.831177  4.875819 ]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -9.978197276770423
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:43 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 45, episode_reward -473.2359132433052, reward -9.978197276770423

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 46

2025-07-28 14:02:43 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:43 - DEBUG - Action: [4.7822156 5.155298  4.839348  4.821914  4.778039  5.1944966 4.940769
 4.8922772 4.8311267 4.8758483]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -9.978197276770423
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:43 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 46, episode_reward -483.2141105200756, reward -9.978197276770423

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 47

2025-07-28 14:02:43 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:43 - DEBUG - Action: [4.7822156 5.155298  4.839348  4.821914  4.778039  5.1944966 4.940769
 4.8922772 4.8311267 4.8758483]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -9.978197276770423
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:43 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 47, episode_reward -493.192307796846, reward -9.978197276770423

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 48

2025-07-28 14:02:43 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:43 - DEBUG - Action: [4.7822156 5.155298  4.839348  4.821914  4.778039  5.1944966 4.940769
 4.8922772 4.8311267 4.8758483]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -9.97819727837094
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895869]
2025-07-28 14:02:43 - DEBUG - Next state: [1.         1.         1.         1.         0.999968   0.9993985
 0.99671465 0.98942584 0.9769897  0.9639362 ]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 48, episode_reward -503.17050507521697, reward -9.97819727837094

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 49

2025-07-28 14:02:43 - DEBUG - State: [1.         1.         1.         1.         0.999968   0.9993985
 0.99671465 0.98942584 0.9769897  0.9639362 ]
2025-07-28 14:02:43 - DEBUG - Action: [4.7819242 5.1554437 4.8392434 4.82176   4.778054  5.194702  4.940997
 4.892947  4.830784  4.876152 ]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -9.978197294286328
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.91895869 -1.3132639  -0.91895869 -0.91895869 -0.91895869 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:43 - DEBUG - Next state: [0.95378184 0.9476818  0.94540846 0.94712645 0.95433736 0.9652095
 0.97443    0.98074096 0.9828778  0.9822795 ]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 49, episode_reward -513.1487023695033, reward -9.978197294286328

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 50

2025-07-28 14:02:43 - DEBUG - State: [0.95378184 0.9476818  0.94540846 0.94712645 0.95433736 0.9652095
 0.97443    0.98074096 0.9828778  0.9822795 ]
2025-07-28 14:02:43 - DEBUG - Action: [4.781621  5.1548524 4.839974  4.824019  4.777146  5.193659  4.9402485
 4.89375   4.8322344 4.875345 ]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -9.978197280985682
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895869 -0.91895869 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:43 - DEBUG - Next state: [0.9799818  0.9759097  0.97044045 0.9656427  0.9637751  0.96616715
 0.97168493 0.97781336 0.9834856  0.98923814]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 50, episode_reward -523.126899650489, reward -9.978197280985682

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 51

2025-07-28 14:02:43 - DEBUG - State: [0.9799818  0.9759097  0.97044045 0.9656427  0.9637751  0.96616715
 0.97168493 0.97781336 0.9834856  0.98923814]
2025-07-28 14:02:43 - DEBUG - Action: [4.7822447 5.155326  4.839561  4.8232093 4.77751   5.194071  4.9405727
 4.8932505 4.8316708 4.875801 ]
2025-07-28 14:02:43 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:43 - DEBUG - Reward: -9.9781972768053
2025-07-28 14:02:43 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:43 - DEBUG - Next state: [0.9943321  0.9979209  0.99959564 0.9999974  1.         1.
 1.         1.         1.         1.        ]
2025-07-28 14:02:43 - DEBUG - 
end of episode 0, step 51, episode_reward -533.1050969272943, reward -9.9781972768053

2025-07-28 14:02:43 - DEBUG - Using actor
2025-07-28 14:02:43 - DEBUG - 
start of episode 0, step 52

2025-07-28 14:02:44 - DEBUG - State: [0.9943321  0.9979209  0.99959564 0.9999974  1.         1.
 1.         1.         1.         1.        ]
2025-07-28 14:02:44 - DEBUG - Action: [4.7821884 5.1552143 4.83939   4.8220115 4.7779903 5.1944714 4.9407005
 4.89231   4.8311863 4.8758035]
2025-07-28 14:02:44 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:44 - DEBUG - Reward: -9.978197276770423
2025-07-28 14:02:44 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:44 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:44 - DEBUG - 
end of episode 0, step 52, episode_reward -543.0832942040647, reward -9.978197276770423

2025-07-28 14:02:44 - DEBUG - Using actor
2025-07-28 14:02:44 - DEBUG - 
start of episode 0, step 53

2025-07-28 14:02:44 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:44 - DEBUG - Action: [4.7822156 5.155298  4.839348  4.821914  4.778039  5.1944966 4.940769
 4.8922772 4.8311267 4.8758483]
2025-07-28 14:02:44 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:44 - DEBUG - Reward: -9.978197276770423
2025-07-28 14:02:44 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:44 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:44 - DEBUG - 
end of episode 0, step 53, episode_reward -553.0614914808351, reward -9.978197276770423

2025-07-28 14:02:44 - DEBUG - Using actor
2025-07-28 14:02:44 - DEBUG - 
start of episode 0, step 54

2025-07-28 14:02:44 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:44 - DEBUG - Action: [4.7822156 5.155298  4.839348  4.821914  4.778039  5.1944966 4.940769
 4.8922772 4.8311267 4.8758483]
2025-07-28 14:02:44 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:44 - DEBUG - Reward: -9.978197276770423
2025-07-28 14:02:44 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:44 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:44 - DEBUG - 
end of episode 0, step 54, episode_reward -563.0396887576055, reward -9.978197276770423

2025-07-28 14:02:44 - DEBUG - Using actor
2025-07-28 14:02:44 - DEBUG - 
start of episode 0, step 55

2025-07-28 14:02:44 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:44 - DEBUG - Action: [4.7822156 5.155298  4.839348  4.821914  4.778039  5.1944966 4.940769
 4.8922772 4.8311267 4.8758483]
2025-07-28 14:02:44 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:44 - DEBUG - Reward: -9.978197276770423
2025-07-28 14:02:44 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:44 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:44 - DEBUG - 
end of episode 0, step 55, episode_reward -573.0178860343759, reward -9.978197276770423

2025-07-28 14:02:44 - DEBUG - Using actor
2025-07-28 14:02:44 - DEBUG - 
start of episode 0, step 56

2025-07-28 14:02:44 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:44 - DEBUG - Action: [4.7822156 5.155298  4.839348  4.821914  4.778039  5.1944966 4.940769
 4.8922772 4.8311267 4.8758483]
2025-07-28 14:02:44 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:44 - DEBUG - Reward: -9.978197276795958
2025-07-28 14:02:44 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:44 - DEBUG - Next state: [1.         1.         1.         1.         1.         1.
 1.         0.9999591  0.9992157  0.99595743]
2025-07-28 14:02:44 - DEBUG - 
end of episode 0, step 56, episode_reward -582.9960833111719, reward -9.978197276795958

2025-07-28 14:02:44 - DEBUG - Using actor
2025-07-28 14:02:44 - DEBUG - 
start of episode 0, step 57

2025-07-28 14:02:44 - DEBUG - State: [1.         1.         1.         1.         1.         1.
 1.         0.9999591  0.9992157  0.99595743]
2025-07-28 14:02:44 - DEBUG - Action: [4.782167  5.1553354 4.8393703 4.821883  4.778043  5.19453   4.9408016
 4.892358  4.831084  4.8758674]
2025-07-28 14:02:44 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:44 - DEBUG - Reward: -9.978197280747976
2025-07-28 14:02:44 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:44 - DEBUG - Next state: [0.9908273  0.9851744  0.97885275 0.9742967  0.9718224  0.9704987
 0.9704107  0.9702834  0.9695982  0.97055036]
2025-07-28 14:02:44 - DEBUG - 
end of episode 0, step 57, episode_reward -592.9742805919199, reward -9.978197280747976

2025-07-28 14:02:44 - DEBUG - Using actor
2025-07-28 14:02:44 - DEBUG - 
start of episode 0, step 58

2025-07-28 14:02:44 - DEBUG - State: [0.9908273  0.9851744  0.97885275 0.9742967  0.9718224  0.9704987
 0.9704107  0.9702834  0.9695982  0.97055036]
2025-07-28 14:02:44 - DEBUG - Action: [4.7822537 5.155593  4.8393607 4.8227396 4.7777424 5.194231  4.9408536
 4.8934073 4.8312254 4.8760705]
2025-07-28 14:02:44 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:44 - DEBUG - Reward: -9.978197277471416
2025-07-28 14:02:44 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:44 - DEBUG - Next state: [0.9733942  0.97852415 0.9853536  0.9913814  0.99595666 0.9993268
 0.9999969  1.         1.         1.        ]
2025-07-28 14:02:44 - DEBUG - 
end of episode 0, step 58, episode_reward -602.9524778693913, reward -9.978197277471416

2025-07-28 14:02:44 - DEBUG - Using actor
2025-07-28 14:02:44 - DEBUG - 
start of episode 0, step 59

2025-07-28 14:02:44 - DEBUG - State: [0.9733942  0.97852415 0.9853536  0.9913814  0.99595666 0.9993268
 0.9999969  1.         1.         1.        ]
2025-07-28 14:02:44 - DEBUG - Action: [4.781871  5.154866  4.8396416 4.8227024 4.7777824 5.194115  4.940425
 4.892586  4.8315406 4.875482 ]
2025-07-28 14:02:44 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:44 - DEBUG - Reward: -9.978197276770423
2025-07-28 14:02:44 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:44 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:44 - DEBUG - 
end of episode 0, step 59, episode_reward -612.9306751461617, reward -9.978197276770423

2025-07-28 14:02:44 - DEBUG - Using actor
2025-07-28 14:02:44 - DEBUG - 
start of episode 0, step 60

2025-07-28 14:02:44 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:44 - DEBUG - Action: [4.7822156 5.155298  4.839348  4.821914  4.778039  5.1944966 4.940769
 4.8922772 4.8311267 4.8758483]
2025-07-28 14:02:44 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:44 - DEBUG - Reward: -9.97819728160985
2025-07-28 14:02:44 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895869 -0.91895869 -0.91895869]
2025-07-28 14:02:44 - DEBUG - Next state: [0.9999595  0.99923724 0.995832   0.98884887 0.98149943 0.9752359
 0.9701249  0.9660238  0.9624141  0.96070933]
2025-07-28 14:02:44 - DEBUG - 
end of episode 0, step 60, episode_reward -622.9088724277715, reward -9.97819728160985

2025-07-28 14:02:44 - DEBUG - Using actor
2025-07-28 14:02:44 - DEBUG - 
start of episode 0, step 61

2025-07-28 14:02:44 - DEBUG - State: [0.9999595  0.99923724 0.995832   0.98884887 0.98149943 0.9752359
 0.9701249  0.9660238  0.9624141  0.96070933]
2025-07-28 14:02:44 - DEBUG - Action: [4.7824373 5.155697  4.8391037 4.822258  4.777906  5.194523  4.941011
 4.893268  4.830766  4.8764462]
2025-07-28 14:02:44 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:44 - DEBUG - Reward: -9.978197279117335
2025-07-28 14:02:44 - DEBUG - Reward array: [-0.91895869 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:44 - DEBUG - Next state: [0.9626519  0.96653765 0.9716252  0.9778498  0.9851666  0.99289197
 0.9984789  0.9999901  1.         1.        ]
2025-07-28 14:02:44 - DEBUG - 
end of episode 0, step 61, episode_reward -632.8870697068888, reward -9.978197279117335

2025-07-28 14:02:44 - DEBUG - Using actor
2025-07-28 14:02:44 - DEBUG - 
start of episode 0, step 62

2025-07-28 14:02:44 - DEBUG - State: [0.9626519  0.96653765 0.9716252  0.9778498  0.9851666  0.99289197
 0.9984789  0.9999901  1.         1.        ]
2025-07-28 14:02:44 - DEBUG - Action: [4.7817106 5.154681  4.839829  4.823166  4.777579  5.193941  4.940259
 4.8929086 4.831894  4.875308 ]
2025-07-28 14:02:44 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:44 - DEBUG - Reward: -9.978228427627203
2025-07-28 14:02:44 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895869 -0.9189589  -0.91898962]
2025-07-28 14:02:44 - DEBUG - Next state: [1.         1.         1.         1.         1.         1.
 0.9891296  0.95518714 0.9003813  0.82911515]
2025-07-28 14:02:44 - DEBUG - 
end of episode 0, step 62, episode_reward -642.865298134516, reward -9.978228427627203

2025-07-28 14:02:44 - DEBUG - Using actor
2025-07-28 14:02:44 - DEBUG - 
start of episode 0, step 63

2025-07-28 14:02:44 - DEBUG - State: [1.         1.         1.         1.         1.         1.
 0.9891296  0.95518714 0.9003813  0.82911515]
2025-07-28 14:02:44 - DEBUG - Action: [4.7803597 5.155189  4.8385315 4.8211184 4.778572  5.1960363 4.9420695
 4.8952837 4.830015  4.8771067]
2025-07-28 14:02:44 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:44 - DEBUG - Reward: -13.913544098366506
2025-07-28 14:02:44 - DEBUG - Reward array: [-0.92206155 -1.34288599 -1.34860017 -1.69308894 -1.74651369 -1.81590379
 -1.70804375 -1.39589883 -1.01694802 -0.92359936]
2025-07-28 14:02:44 - DEBUG - Next state: [0.7487217  0.67636317 0.62687737 0.6062883  0.6037863  0.6037935
 0.6055749  0.6233987  0.6704251  0.74066275]
2025-07-28 14:02:44 - DEBUG - 
end of episode 0, step 63, episode_reward -656.7788422328825, reward -13.913544098366506

2025-07-28 14:02:44 - DEBUG - critic loss: 106.91232299804688
2025-07-28 14:02:44 - DEBUG - actor loss: 0.21707618236541748
2025-07-28 14:02:44 - DEBUG - Using actor
2025-07-28 14:02:44 - DEBUG - 
start of episode 0, step 64

2025-07-28 14:02:44 - DEBUG - State: [0.7487217  0.67636317 0.62687737 0.6062883  0.6037863  0.6037935
 0.6055749  0.6233987  0.6704251  0.74066275]
2025-07-28 14:02:44 - DEBUG - Action: [4.7518167 5.1144133 4.8206925 4.825284  4.7382255 5.1498804 4.9264684
 4.874305  4.7857213 4.901145 ]
2025-07-28 14:02:44 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:44 - DEBUG - Reward: -12.457974860270925
2025-07-28 14:02:44 - DEBUG - Reward array: [-0.91904515 -1.31326422 -0.91896348 -0.91901212 -0.92159748 -1.33746765
 -1.28588238 -1.58402796 -1.62953191 -1.6291825 ]
2025-07-28 14:02:44 - DEBUG - Next state: [0.81270957 0.8546894  0.85722023 0.8204803  0.7519054  0.68068844
 0.6320106  0.61184156 0.6094443  0.60946226]
2025-07-28 14:02:44 - DEBUG - 
end of episode 0, step 64, episode_reward -669.2368170931535, reward -12.457974860270925

2025-07-28 14:02:44 - DEBUG - critic loss: 103.4780502319336
2025-07-28 14:02:44 - DEBUG - actor loss: 0.6639245748519897
2025-07-28 14:02:44 - DEBUG - Using actor
2025-07-28 14:02:44 - DEBUG - 
start of episode 0, step 65

2025-07-28 14:02:44 - DEBUG - State: [0.81270957 0.8546894  0.85722023 0.8204803  0.7519054  0.68068844
 0.6320106  0.61184156 0.6094443  0.60946226]
2025-07-28 14:02:44 - DEBUG - Action: [4.723992  5.061446  4.788938  4.811287  4.713564  5.113094  4.905705
 4.845969  4.7334223 4.919856 ]
2025-07-28 14:02:44 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:44 - DEBUG - Reward: -10.959601003028798
2025-07-28 14:02:44 - DEBUG - Reward array: [-1.59693914 -1.52984907 -1.00182827 -0.92288329 -0.91900259 -1.31326391
 -0.91895869 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:44 - DEBUG - Next state: [0.61114866 0.6283965  0.67484254 0.7440445  0.82360864 0.89530796
 0.9512015  0.98691684 0.99988145 1.        ]
2025-07-28 14:02:44 - DEBUG - 
end of episode 0, step 65, episode_reward -680.1964180961822, reward -10.959601003028798

2025-07-28 14:02:44 - DEBUG - critic loss: 95.02429962158203
2025-07-28 14:02:44 - DEBUG - actor loss: 1.664496660232544
2025-07-28 14:02:44 - DEBUG - Using actor
2025-07-28 14:02:44 - DEBUG - 
start of episode 0, step 66

2025-07-28 14:02:44 - DEBUG - State: [0.61114866 0.6283965  0.67484254 0.7440445  0.82360864 0.89530796
 0.9512015  0.98691684 0.99988145 1.        ]
2025-07-28 14:02:44 - DEBUG - Action: [4.6895037 5.0053687 4.7576556 4.808057  4.666711  5.074551  4.8762317
 4.8118043 4.6838717 4.9323945]
2025-07-28 14:02:44 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:44 - DEBUG - Reward: -9.978197276772745
2025-07-28 14:02:44 - DEBUG - Reward array: [-0.91895868 -1.3132639  -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:44 - DEBUG - Next state: [1.         1.         1.         1.         1.         1.
 1.         1.         0.99997455 0.9995151 ]
2025-07-28 14:02:44 - DEBUG - 
end of episode 0, step 66, episode_reward -690.174615372955, reward -9.978197276772745

2025-07-28 14:02:44 - DEBUG - critic loss: 76.73493957519531
2025-07-28 14:02:44 - DEBUG - actor loss: 3.7580924034118652
2025-07-28 14:02:44 - DEBUG - Using actor
2025-07-28 14:02:44 - DEBUG - 
start of episode 0, step 67

2025-07-28 14:02:44 - DEBUG - State: [1.         1.         1.         1.         1.         1.
 1.         1.         0.99997455 0.9995151 ]
2025-07-28 14:02:44 - DEBUG - Action: [4.6411886 4.9368157 4.704172  4.7992544 4.6253486 5.035019  4.8483243
 4.762261  4.59776   4.967478 ]
2025-07-28 14:02:44 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:44 - DEBUG - Reward: -9.583892059700476
2025-07-28 14:02:44 - DEBUG - Reward array: [-0.91895868 -0.91895868 -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:44 - DEBUG - Next state: [0.997693   0.99520046 0.99178797 0.9883804  0.9858846  0.98422456
 0.9830055  0.982447   0.98174566 0.98190045]
2025-07-28 14:02:44 - DEBUG - 
end of episode 0, step 67, episode_reward -699.7585074326555, reward -9.583892059700476

2025-07-28 14:02:44 - DEBUG - critic loss: 44.81293869018555
2025-07-28 14:02:44 - DEBUG - actor loss: 7.840505599975586
2025-07-28 14:02:44 - DEBUG - Using actor
2025-07-28 14:02:44 - DEBUG - 
start of episode 0, step 68

2025-07-28 14:02:44 - DEBUG - State: [0.997693   0.99520046 0.99178797 0.9883804  0.9858846  0.98422456
 0.9830055  0.982447   0.98174566 0.98190045]
2025-07-28 14:02:44 - DEBUG - Action: [4.6043677 4.885102  4.6684413 4.7926955 4.588949  5.011019  4.8238463
 4.7334604 4.5434885 4.983753 ]
2025-07-28 14:02:44 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:44 - DEBUG - Reward: -9.58389205905019
2025-07-28 14:02:44 - DEBUG - Reward array: [-0.91895868 -0.91895868 -0.91895868 -0.91895868 -0.91895868 -1.3132639
 -0.91895868 -0.91895868 -0.91895868 -0.91895868]
2025-07-28 14:02:44 - DEBUG - Next state: [0.9834274  0.9859084  0.98931336 0.9932511  0.9964404  0.99898624
 0.99999154 1.         1.         1.        ]
2025-07-28 14:02:44 - DEBUG - 
end of episode 0, step 68, episode_reward -709.3423994917057, reward -9.58389205905019

2025-07-28 14:02:45 - DEBUG - critic loss: 8.17371654510498
2025-07-28 14:02:45 - DEBUG - actor loss: 15.419065475463867
2025-07-28 14:02:45 - DEBUG - Using actor
2025-07-28 14:02:45 - DEBUG - 
start of episode 0, step 69

2025-07-28 14:02:45 - DEBUG - State: [0.9834274  0.9859084  0.98931336 0.9932511  0.9964404  0.99898624
 0.99999154 1.         1.         1.        ]
2025-07-28 14:02:45 - DEBUG - Action: [4.563294  4.829672  4.6283417 4.784351  4.547545  4.987012  4.7938876
 4.7007565 4.4844685 5.0000267]
2025-07-28 14:02:45 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:45 - DEBUG - Reward: -9.583892058614046
2025-07-28 14:02:45 - DEBUG - Reward array: [-0.91895868 -0.91895868 -0.91895868 -0.91895868 -0.91895868 -0.91895868
 -0.91895868 -0.91895868 -0.91895868 -1.3132639 ]
2025-07-28 14:02:45 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:45 - DEBUG - 
end of episode 0, step 69, episode_reward -718.9262915503198, reward -9.583892058614046

2025-07-28 14:02:45 - DEBUG - critic loss: 30.946937561035156
2025-07-28 14:02:45 - DEBUG - actor loss: 14.64076042175293
2025-07-28 14:02:45 - DEBUG - Using actor
2025-07-28 14:02:45 - DEBUG - 
start of episode 0, step 70

2025-07-28 14:02:45 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:45 - DEBUG - Action: [4.51766   4.765082  4.5802436 4.773955  4.500734  4.956879  4.7586613
 4.6615458 4.4180818 5.0160556]
2025-07-28 14:02:45 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:45 - DEBUG - Reward: -9.583892058614046
2025-07-28 14:02:45 - DEBUG - Reward array: [-0.91895868 -0.91895868 -0.91895868 -0.91895868 -0.91895868 -0.91895868
 -0.91895868 -0.91895868 -0.91895868 -1.3132639 ]
2025-07-28 14:02:45 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:45 - DEBUG - 
end of episode 0, step 70, episode_reward -728.5101836089339, reward -9.583892058614046

2025-07-28 14:02:45 - DEBUG - critic loss: 22.476430892944336
2025-07-28 14:02:45 - DEBUG - actor loss: 11.440764427185059
2025-07-28 14:02:45 - DEBUG - Using actor
2025-07-28 14:02:45 - DEBUG - 
start of episode 0, step 71

2025-07-28 14:02:45 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:45 - DEBUG - Action: [4.467158  4.6931677 4.5255165 4.761399  4.447997  4.92386   4.7199574
 4.616462  4.3441114 5.0321608]
2025-07-28 14:02:45 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:45 - DEBUG - Reward: -9.583892058614046
2025-07-28 14:02:45 - DEBUG - Reward array: [-0.91895868 -0.91895868 -0.91895868 -0.91895868 -0.91895868 -0.91895868
 -0.91895868 -0.91895868 -0.91895868 -1.3132639 ]
2025-07-28 14:02:45 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:45 - DEBUG - 
end of episode 0, step 71, episode_reward -738.0940756675479, reward -9.583892058614046

2025-07-28 14:02:45 - DEBUG - critic loss: 3.459367275238037
2025-07-28 14:02:45 - DEBUG - actor loss: 8.699600219726562
2025-07-28 14:02:45 - DEBUG - Using actor
2025-07-28 14:02:45 - DEBUG - 
start of episode 0, step 72

2025-07-28 14:02:45 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:45 - DEBUG - Action: [4.4080706 4.6103606 4.461699  4.7473273 4.386613  4.8869824 4.678029
 4.5657806 4.260819  5.0511675]
2025-07-28 14:02:45 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:45 - DEBUG - Reward: -9.58389205868796
2025-07-28 14:02:45 - DEBUG - Reward array: [-0.91895868 -0.91895868 -0.91895868 -0.91895868 -0.91895868 -0.91895868
 -0.91895868 -0.91895868 -0.91895868 -1.3132639 ]
2025-07-28 14:02:45 - DEBUG - Next state: [1.         1.         0.99998236 0.9996718  0.9989861  0.99809533
 0.99711895 0.9962937  0.99562263 0.99508023]
2025-07-28 14:02:45 - DEBUG - 
end of episode 0, step 72, episode_reward -747.6779677262359, reward -9.58389205868796

2025-07-28 14:02:45 - DEBUG - critic loss: 4.015233516693115
2025-07-28 14:02:45 - DEBUG - actor loss: 7.085271835327148
2025-07-28 14:02:45 - DEBUG - Using actor
2025-07-28 14:02:45 - DEBUG - 
start of episode 0, step 73

2025-07-28 14:02:45 - DEBUG - State: [1.         1.         0.99998236 0.9996718  0.9989861  0.99809533
 0.99711895 0.9962937  0.99562263 0.99508023]
2025-07-28 14:02:45 - DEBUG - Action: [4.343217  4.5180435 4.3914065 4.7278414 4.3153467 4.843806  4.6323423
 4.507611  4.16727   5.072613 ]
2025-07-28 14:02:45 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:45 - DEBUG - Reward: -9.583892187094555
2025-07-28 14:02:45 - DEBUG - Reward array: [-0.91895868 -0.91895868 -0.91895868 -0.91895868 -0.91895868 -0.91895868
 -0.91895869 -0.91895869 -0.91895877 -1.31326393]
2025-07-28 14:02:45 - DEBUG - Next state: [0.99480504 0.99466085 0.9935051  0.99005336 0.98434603 0.9773379
 0.96399486 0.9402538  0.9114862  0.8835913 ]
2025-07-28 14:02:45 - DEBUG - 
end of episode 0, step 73, episode_reward -757.2618599133305, reward -9.583892187094555

2025-07-28 14:02:45 - DEBUG - critic loss: 12.09347915649414
2025-07-28 14:02:45 - DEBUG - actor loss: 6.382072925567627
2025-07-28 14:02:45 - DEBUG - Using actor
2025-07-28 14:02:45 - DEBUG - 
start of episode 0, step 74

2025-07-28 14:02:45 - DEBUG - State: [0.99480504 0.99466085 0.9935051  0.99005336 0.98434603 0.9773379
 0.96399486 0.9402538  0.9114862  0.8835913 ]
2025-07-28 14:02:45 - DEBUG - Action: [4.281767  4.427994  4.3247657 4.704396  4.2421246 4.80016   4.589289
 4.4488754 4.0762644 5.091601 ]
2025-07-28 14:02:45 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:45 - DEBUG - Reward: -9.674153152894316
2025-07-28 14:02:45 - DEBUG - Reward array: [-0.91896219 -0.9189674  -0.91897009 -0.91897354 -0.91901163 -0.9195015
 -0.92540941 -0.95373412 -0.96496497 -1.3156583 ]
2025-07-28 14:02:45 - DEBUG - Next state: [0.8617282  0.84841096 0.8444019  0.84040576 0.82062817 0.7814026
 0.7339022  0.6964913  0.68972325 0.7255045 ]
2025-07-28 14:02:45 - DEBUG - 
end of episode 0, step 74, episode_reward -766.9360130662247, reward -9.674153152894316

2025-07-28 14:02:45 - DEBUG - critic loss: 14.867950439453125
2025-07-28 14:02:45 - DEBUG - actor loss: 6.334671974182129
2025-07-28 14:02:45 - DEBUG - Using actor
2025-07-28 14:02:45 - DEBUG - 
start of episode 0, step 75

2025-07-28 14:02:45 - DEBUG - State: [0.8617282  0.84841096 0.8444019  0.84040576 0.82062817 0.7814026
 0.7339022  0.6964913  0.68972325 0.7255045 ]
2025-07-28 14:02:45 - DEBUG - Action: [4.271476  4.407424  4.3156395 4.6924744 4.2240515 4.791998  4.579774
 4.4399605 4.064046  5.0886106]
2025-07-28 14:02:45 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:45 - DEBUG - Reward: -9.5842971034398
2025-07-28 14:02:45 - DEBUG - Reward array: [-0.91935705 -0.91896527 -0.91895877 -0.91895869 -0.91895868 -0.91895868
 -0.91895868 -0.91895868 -0.91895868 -1.3132639 ]
2025-07-28 14:02:45 - DEBUG - Next state: [0.78687614 0.8525596  0.912157   0.9590003  0.98899406 0.9999002
 1.         1.         1.         1.        ]
2025-07-28 14:02:45 - DEBUG - 
end of episode 0, step 75, episode_reward -776.5203101696645, reward -9.5842971034398

2025-07-28 14:02:45 - DEBUG - critic loss: 17.16743278503418
2025-07-28 14:02:45 - DEBUG - actor loss: 6.852506160736084
2025-07-28 14:02:45 - DEBUG - Using actor
2025-07-28 14:02:45 - DEBUG - 
start of episode 0, step 76

2025-07-28 14:02:45 - DEBUG - State: [0.78687614 0.8525596  0.912157   0.9590003  0.98899406 0.9999002
 1.         1.         1.         1.        ]
2025-07-28 14:02:45 - DEBUG - Action: [4.1138935 4.2045774 4.1612864 4.6452346 4.044189  4.6905828 4.4734354
 4.307132  3.8513758 5.1442904]
2025-07-28 14:02:45 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:45 - DEBUG - Reward: -9.24488799687849
2025-07-28 14:02:45 - DEBUG - Reward array: [-0.91895868 -0.91895868 -0.91895868 -0.91895868 -0.91895868 -0.91895868
 -0.91895868 -0.91895868 -0.57995462 -1.3132639 ]
2025-07-28 14:02:45 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:45 - DEBUG - 
end of episode 0, step 76, episode_reward -785.765198166543, reward -9.24488799687849

2025-07-28 14:02:45 - DEBUG - critic loss: 12.772720336914062
2025-07-28 14:02:45 - DEBUG - actor loss: 7.9324870109558105
2025-07-28 14:02:45 - DEBUG - Using actor
2025-07-28 14:02:45 - DEBUG - 
start of episode 0, step 77

2025-07-28 14:02:45 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:45 - DEBUG - Action: [3.9758248 4.019745  4.017648  4.594025  3.8813426 4.596996  4.3809056
 4.1838737 3.6595592 5.1995397]
2025-07-28 14:02:45 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:45 - DEBUG - Reward: -8.566879873407375
2025-07-28 14:02:45 - DEBUG - Reward array: [-0.57995462 -0.91895868 -0.91895868 -0.91895868 -0.57995462 -0.91895868
 -0.91895868 -0.91895868 -0.57995462 -1.3132639 ]
2025-07-28 14:02:45 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:45 - DEBUG - 
end of episode 0, step 77, episode_reward -794.3320780399504, reward -8.566879873407375

2025-07-28 14:02:45 - DEBUG - critic loss: 6.6543684005737305
2025-07-28 14:02:45 - DEBUG - actor loss: 9.391523361206055
2025-07-28 14:02:45 - DEBUG - Using actor
2025-07-28 14:02:45 - DEBUG - 
start of episode 0, step 78

2025-07-28 14:02:45 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:45 - DEBUG - Action: [3.8486142 3.8504744 3.8911405 4.544602  3.7293453 4.5099826 4.295432
 4.0748363 3.491789  5.2479963]
2025-07-28 14:02:45 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:45 - DEBUG - Reward: -7.888871760400139
2025-07-28 14:02:45 - DEBUG - Reward array: [-0.57995462 -0.57995462 -0.57995462 -0.91895868 -0.57995463 -0.91895868
 -0.91895868 -0.91895868 -0.57995463 -1.3132639 ]
2025-07-28 14:02:45 - DEBUG - Next state: [1.         0.99939597 0.9982938  0.9972068  0.9961348  0.99507827
 0.9940369  0.99301094 0.99309635 0.99412376]
2025-07-28 14:02:45 - DEBUG - 
end of episode 0, step 78, episode_reward -802.2209498003505, reward -7.888871760400139

2025-07-28 14:02:46 - DEBUG - critic loss: 2.5011870861053467
2025-07-28 14:02:46 - DEBUG - actor loss: 11.055266380310059
2025-07-28 14:02:46 - DEBUG - Using actor
2025-07-28 14:02:46 - DEBUG - 
start of episode 0, step 79

2025-07-28 14:02:46 - DEBUG - State: [1.         0.99939597 0.9982938  0.9972068  0.9961348  0.99507827
 0.9940369  0.99301094 0.99309635 0.99412376]
2025-07-28 14:02:46 - DEBUG - Action: [3.710594  3.6663074 3.7495847 4.4873414 3.562063  4.409461  4.200672
 3.9550233 3.3080306 5.3038163]
2025-07-28 14:02:46 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:46 - DEBUG - Reward: -7.549867697164198
2025-07-28 14:02:46 - DEBUG - Reward array: [-0.57995463 -0.57995463 -0.57995462 -0.91895868 -0.57995462 -0.91895868
 -0.91895868 -0.57995462 -0.57995462 -1.3132639 ]
2025-07-28 14:02:46 - DEBUG - Next state: [0.99516654 0.9962246  0.9972979  0.99838644 0.99948996 1.
 1.         0.9999998  0.9999176  0.9991915 ]
2025-07-28 14:02:46 - DEBUG - 
end of episode 0, step 79, episode_reward -809.7708174975147, reward -7.549867697164198

2025-07-28 14:02:46 - DEBUG - critic loss: 4.049238681793213
2025-07-28 14:02:46 - DEBUG - actor loss: 12.22764778137207
2025-07-28 14:02:46 - DEBUG - Using actor
2025-07-28 14:02:46 - DEBUG - 
start of episode 0, step 80

2025-07-28 14:02:46 - DEBUG - State: [0.99516654 0.9962246  0.9972979  0.99838644 0.99948996 1.
 1.         0.9999998  0.9999176  0.9991915 ]
2025-07-28 14:02:46 - DEBUG - Action: [3.551743  3.453062  3.5839338 4.4191594 3.3692968 4.2925735 4.089922
 3.8155265 3.1011438 5.371075 ]
2025-07-28 14:02:46 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:46 - DEBUG - Reward: -7.549867950167249
2025-07-28 14:02:46 - DEBUG - Reward array: [-0.57995462 -0.57995463 -0.57995464 -0.91895868 -0.57995467 -0.91895868
 -0.91895868 -0.57995471 -0.57995472 -1.3132639 ]
2025-07-28 14:02:46 - DEBUG - Next state: [0.9966168  0.9912588  0.9844522  0.97863746 0.9743165  0.9711925
 0.9684881  0.9663087  0.9658695  0.9675253 ]
2025-07-28 14:02:46 - DEBUG - 
end of episode 0, step 80, episode_reward -817.320685447682, reward -7.549867950167249

2025-07-28 14:02:46 - DEBUG - critic loss: 8.740540504455566
2025-07-28 14:02:46 - DEBUG - actor loss: 12.33418083190918
2025-07-28 14:02:46 - DEBUG - Using actor
2025-07-28 14:02:46 - DEBUG - 
start of episode 0, step 81

2025-07-28 14:02:46 - DEBUG - State: [0.9966168  0.9912588  0.9844522  0.97863746 0.9743165  0.9711925
 0.9684881  0.9663087  0.9658695  0.9675253 ]
2025-07-28 14:02:46 - DEBUG - Action: [3.395732  3.2460542 3.4194646 4.3452673 3.1817162 4.1745734 3.9792147
 3.6762607 2.9019773 5.4416733]
2025-07-28 14:02:46 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:46 - DEBUG - Reward: -6.934054067223052
2025-07-28 14:02:46 - DEBUG - Reward array: [-0.57995468 -0.57995466 -0.57995465 -0.91895868 -0.57995463 -0.91895868
 -0.57995462 -0.57995462 -0.30314493 -1.3132639 ]
2025-07-28 14:02:46 - DEBUG - Next state: [0.970982   0.97598994 0.9824884  0.9897966  0.9961138  0.9994273
 1.         1.         1.         1.        ]
2025-07-28 14:02:46 - DEBUG - 
end of episode 0, step 81, episode_reward -824.254739514905, reward -6.934054067223052

2025-07-28 14:02:46 - DEBUG - critic loss: 9.40356159210205
2025-07-28 14:02:46 - DEBUG - actor loss: 11.26482105255127
2025-07-28 14:02:46 - DEBUG - Using actor
2025-07-28 14:02:46 - DEBUG - 
start of episode 0, step 82

2025-07-28 14:02:46 - DEBUG - State: [0.970982   0.97598994 0.9824884  0.9897966  0.9961138  0.9994273
 1.         1.         1.         1.        ]
2025-07-28 14:02:46 - DEBUG - Action: [3.186901  2.9722502 3.1993473 4.246008  2.930325  4.0137243 3.8254113
 3.4892106 2.6422894 5.538331 ]
2025-07-28 14:02:46 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:46 - DEBUG - Reward: -6.380437786501487
2025-07-28 14:02:46 - DEBUG - Reward array: [-0.57995462 -0.30314493 -0.57995462 -0.91895868 -0.30314496 -0.91895868
 -0.57995463 -0.57995464 -0.30314811 -1.3132639 ]
2025-07-28 14:02:46 - DEBUG - Next state: [1.         1.         1.         0.99999857 0.9996934  0.99690604
 0.991894   0.98545736 0.98008794 0.9751955 ]
2025-07-28 14:02:46 - DEBUG - 
end of episode 0, step 82, episode_reward -830.6351773014065, reward -6.380437786501487

2025-07-28 14:02:46 - DEBUG - critic loss: 5.607409954071045
2025-07-28 14:02:46 - DEBUG - actor loss: 9.906272888183594
2025-07-28 14:02:46 - DEBUG - Using actor
2025-07-28 14:02:46 - DEBUG - 
start of episode 0, step 83

2025-07-28 14:02:46 - DEBUG - State: [1.         1.         1.         0.99999857 0.9996934  0.99690604
 0.991894   0.98545736 0.98008794 0.9751955 ]
2025-07-28 14:02:46 - DEBUG - Action: [2.9640803 2.6837814 2.9638433 4.1327195 2.6654215 3.836824  3.6571467
 3.2874613 2.3727872 5.64748  ]
2025-07-28 14:02:46 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:46 - DEBUG - Reward: -5.487845913955861
2025-07-28 14:02:46 - DEBUG - Reward array: [-0.30315077 -0.30315199 -0.3031525  -0.91895868 -0.30315101 -0.57995467
 -0.57995468 -0.57995469 -0.30315302 -1.3132639 ]
2025-07-28 14:02:46 - DEBUG - Next state: [0.9717803  0.96888816 0.9677958  0.96850455 0.97117656 0.97410226
 0.9730911  0.96982586 0.9667374  0.9622602 ]
2025-07-28 14:02:46 - DEBUG - 
end of episode 0, step 83, episode_reward -836.1230232153624, reward -5.487845913955861

2025-07-28 14:02:46 - DEBUG - critic loss: 2.1368024349212646
2025-07-28 14:02:46 - DEBUG - actor loss: 8.61801815032959
2025-07-28 14:02:46 - DEBUG - Using actor
2025-07-28 14:02:46 - DEBUG - 
start of episode 0, step 84

2025-07-28 14:02:46 - DEBUG - State: [0.9717803  0.96888816 0.9677958  0.96850455 0.97117656 0.97410226
 0.9730911  0.96982586 0.9667374  0.9622602 ]
2025-07-28 14:02:46 - DEBUG - Action: [2.7597964 2.4258862 2.7498121 4.021203  2.4242566 3.6643493 3.4981532
 3.102814  2.1381032 5.754397 ]
2025-07-28 14:02:46 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:46 - DEBUG - Reward: -5.487886430309908
2025-07-28 14:02:46 - DEBUG - Reward array: [-0.30315895 -0.30316371 -0.30316841 -0.91895869 -0.30316195 -0.57995476
 -0.5799547  -0.57995466 -0.3031467  -1.3132639 ]
2025-07-28 14:02:46 - DEBUG - Next state: [0.95751977 0.9523164  0.94821066 0.94948477 0.95408916 0.96052
 0.9680936  0.9770091  0.98652214 0.9961071 ]
2025-07-28 14:02:46 - DEBUG - 
end of episode 0, step 84, episode_reward -841.6109096456723, reward -5.487886430309908

2025-07-28 14:02:46 - DEBUG - critic loss: 3.833226203918457
2025-07-28 14:02:46 - DEBUG - actor loss: 7.718834400177002
2025-07-28 14:02:46 - DEBUG - Using actor
2025-07-28 14:02:46 - DEBUG - 
start of episode 0, step 85

2025-07-28 14:02:46 - DEBUG - State: [0.95751977 0.9523164  0.94821066 0.94948477 0.95408916 0.96052
 0.9680936  0.9770091  0.98652214 0.9961071 ]
2025-07-28 14:02:46 - DEBUG - Action: [2.516891  2.1278908 2.4951768 3.8845487 2.14203   3.4486065 3.3037307
 2.8780282 1.8686396 5.890019 ]
2025-07-28 14:02:46 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:46 - DEBUG - Reward: -4.6699041482930275
2025-07-28 14:02:46 - DEBUG - Reward array: [-0.30314496 -0.30314493 -0.30314493 -0.57995462 -0.30314493 -0.57995462
 -0.57995462 -0.30314569 -0.10105093 -1.3132639 ]
2025-07-28 14:02:46 - DEBUG - Next state: [0.9997194  1.         1.         1.         1.         1.
 1.         0.99308324 0.9647409  0.91865355]
2025-07-28 14:02:46 - DEBUG - 
end of episode 0, step 85, episode_reward -846.2808137939653, reward -4.6699041482930275

2025-07-28 14:02:46 - DEBUG - critic loss: 4.95705509185791
2025-07-28 14:02:46 - DEBUG - actor loss: 7.267831802368164
2025-07-28 14:02:46 - DEBUG - Using actor
2025-07-28 14:02:46 - DEBUG - 
start of episode 0, step 86

2025-07-28 14:02:46 - DEBUG - State: [0.9997194  1.         1.         1.         1.         1.
 1.         0.99308324 0.9647409  0.91865355]
2025-07-28 14:02:46 - DEBUG - Action: [2.2086096 1.7643692 2.170417  3.698293  1.7955687 3.1590307 3.0469732
 2.5829868 1.5421393 6.075839 ]
2025-07-28 14:02:46 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:46 - DEBUG - Reward: -7.930361055464239
2025-07-28 14:02:46 - DEBUG - Reward array: [-0.30451231 -0.24601541 -0.39401085 -0.6742021  -1.52081283 -0.82681575
 -0.80474097 -0.70222644 -0.69891243 -1.75811198]
2025-07-28 14:02:46 - DEBUG - Next state: [0.86121625 0.79444176 0.74388033 0.7004936  0.67705905 0.67046267
 0.6735576  0.6894057  0.72743136 0.774434  ]
2025-07-28 14:02:46 - DEBUG - 
end of episode 0, step 86, episode_reward -854.2111748494295, reward -7.930361055464239

2025-07-28 14:02:46 - DEBUG - critic loss: 8.070585250854492
2025-07-28 14:02:46 - DEBUG - actor loss: 7.145762920379639
2025-07-28 14:02:46 - DEBUG - Using actor
2025-07-28 14:02:46 - DEBUG - 
start of episode 0, step 87

2025-07-28 14:02:46 - DEBUG - State: [0.86121625 0.79444176 0.74388033 0.7004936  0.67705905 0.67046267
 0.6735576  0.6894057  0.72743136 0.774434  ]
2025-07-28 14:02:46 - DEBUG - Action: [2.3928099 1.9836003 2.3649545 3.772192  1.9875946 3.3064938 3.190064
 2.7637696 1.7557976 5.981796 ]
2025-07-28 14:02:46 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:46 - DEBUG - Reward: -4.275324629307921
2025-07-28 14:02:46 - DEBUG - Reward array: [-0.30711122 -0.10816108 -0.30316583 -0.57995464 -0.10030041 -0.57995462
 -0.57995462 -0.30314497 -0.10031333 -1.3132639 ]
2025-07-28 14:02:46 - DEBUG - Next state: [0.8348112  0.9017709  0.9503554  0.98618037 0.99970645 0.99992806
 0.99992555 0.99959725 0.99856615 0.9972822 ]
2025-07-28 14:02:46 - DEBUG - 
end of episode 0, step 87, episode_reward -858.4864994787374, reward -4.275324629307921

2025-07-28 14:02:46 - DEBUG - critic loss: 5.13899564743042
2025-07-28 14:02:46 - DEBUG - actor loss: 7.4413886070251465
2025-07-28 14:02:46 - DEBUG - Using actor
2025-07-28 14:02:46 - DEBUG - 
start of episode 0, step 88

2025-07-28 14:02:46 - DEBUG - State: [0.8348112  0.9017709  0.9503554  0.98618037 0.99970645 0.99992806
 0.99992555 0.99959725 0.99856615 0.9972822 ]
2025-07-28 14:02:46 - DEBUG - Action: [1.6980565 1.2151641 1.6383582 3.3404489 1.2547183 2.6224518 2.573474
 2.0768669 1.0606453 6.417441 ]
2025-07-28 14:02:46 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:46 - DEBUG - Reward: -3.7493875570758264
2025-07-28 14:02:46 - DEBUG - Reward array: [-0.10035029 -0.10037004 -0.10038703 -0.57995463 -0.10041151 -0.30314598
 -0.30314598 -0.30314585 -0.10038261 -1.75809363]
2025-07-28 14:02:46 - DEBUG - Next state: [0.99553674 0.99404037 0.99281245 0.9918261  0.99113065 0.9909388
 0.99093455 0.99184144 0.99312675 0.99455094]
2025-07-28 14:02:46 - DEBUG - 
end of episode 0, step 88, episode_reward -862.2358870358132, reward -3.7493875570758264

2025-07-28 14:02:46 - DEBUG - critic loss: 6.756546974182129
2025-07-28 14:02:46 - DEBUG - actor loss: 7.86077356338501
2025-07-28 14:02:46 - DEBUG - Using actor
2025-07-28 14:02:46 - DEBUG - 
start of episode 0, step 89

2025-07-28 14:02:46 - DEBUG - State: [0.99553674 0.99404037 0.99281245 0.9918261  0.99113065 0.9909388
 0.99093455 0.99184144 0.99312675 0.99455094]
2025-07-28 14:02:46 - DEBUG - Action: [1.3684943 0.8951771 1.2954924 3.0777464 0.9390521 2.2417932 2.2396708
 1.7315894 0.7795757 6.670743 ]
2025-07-28 14:02:46 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:46 - DEBUG - Reward: -3.4221842507570357
2025-07-28 14:02:46 - DEBUG - Reward array: [-0.10033938 -0.05647486 -0.10030582 -0.57995462 -0.05451281 -0.30314494
 -0.30314501 -0.10034923 -0.06586395 -1.75809363]
2025-07-28 14:02:46 - DEBUG - Next state: [0.9963984  0.9980854  0.9992236  0.9999876  1.         0.9999497
 0.9991833  0.99561906 0.9896794  0.9844086 ]
2025-07-28 14:02:46 - DEBUG - 
end of episode 0, step 89, episode_reward -865.6580712865702, reward -3.4221842507570357

2025-07-28 14:02:47 - DEBUG - critic loss: 4.350357532501221
2025-07-28 14:02:47 - DEBUG - actor loss: 8.503973960876465
2025-07-28 14:02:47 - DEBUG - Using actor
2025-07-28 14:02:47 - DEBUG - 
start of episode 0, step 90

2025-07-28 14:02:47 - DEBUG - State: [0.9963984  0.9980854  0.9992236  0.9999876  1.         0.9999497
 0.9991833  0.99561906 0.9896794  0.9844086 ]
2025-07-28 14:02:47 - DEBUG - Action: [1.0999614  0.6598142  1.018458   2.826418   0.700987   1.8973079
 1.9318187  1.4388168  0.57568014 6.8976984 ]
2025-07-28 14:02:47 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:47 - DEBUG - Reward: -2.806646224073565
2025-07-28 14:02:47 - DEBUG - Reward array: [-0.10062775 -0.08466662 -0.10076489 -0.30314986 -0.08227766 -0.10058838
 -0.1005426  -0.10053946 -0.07539537 -1.75809363]
2025-07-28 14:02:47 - DEBUG - Next state: [0.97940534 0.97566736 0.97383046 0.97424173 0.97728294 0.9812205
 0.9834818  0.98364335 0.98218375 0.98064655]
2025-07-28 14:02:47 - DEBUG - 
end of episode 0, step 90, episode_reward -868.4647175106438, reward -2.806646224073565

2025-07-28 14:02:47 - DEBUG - critic loss: 4.456836223602295
2025-07-28 14:02:47 - DEBUG - actor loss: 9.10537338256836
2025-07-28 14:02:47 - DEBUG - Using actor
2025-07-28 14:02:47 - DEBUG - 
start of episode 0, step 91

2025-07-28 14:02:47 - DEBUG - State: [0.97940534 0.97566736 0.97383046 0.97424173 0.97728294 0.9812205
 0.9834818  0.98364335 0.98218375 0.98064655]
2025-07-28 14:02:47 - DEBUG - Action: [0.8850843  0.49032927 0.80058783 2.5897675  0.526222   1.5935514
 1.656661   1.1959088  0.4295981  7.087605  ]
2025-07-28 14:02:47 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:47 - DEBUG - Reward: -3.20466730772132
2025-07-28 14:02:47 - DEBUG - Reward array: [-0.07836279 -0.07741922 -0.07496005 -0.30314686 -0.06537034 -0.10037261
 -0.10033713 -0.10030749 -0.05452373 -2.24986709]
2025-07-28 14:02:47 - DEBUG - Next state: [0.98002356 0.9807024  0.98250705 0.9856906  0.9900936  0.9938514
 0.99657893 0.99907595 0.99998915 0.9998268 ]
2025-07-28 14:02:47 - DEBUG - 
end of episode 0, step 91, episode_reward -871.6693848183652, reward -3.20466730772132

2025-07-28 14:02:47 - DEBUG - critic loss: 3.898066282272339
2025-07-28 14:02:47 - DEBUG - actor loss: 9.448465347290039
2025-07-28 14:02:47 - DEBUG - Using actor
2025-07-28 14:02:47 - DEBUG - 
start of episode 0, step 92

2025-07-28 14:02:47 - DEBUG - State: [0.98002356 0.9807024  0.98250705 0.9856906  0.9900936  0.9938514
 0.99657893 0.99907595 0.99998915 0.9998268 ]
2025-07-28 14:02:47 - DEBUG - Action: [0.6547761  0.32630235 0.5730039  2.2959094  0.3553334  1.2460113
 1.3331923  0.92411697 0.28751463 7.3190975 ]
2025-07-28 14:02:47 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:47 - DEBUG - Reward: -3.1039077151487082
2025-07-28 14:02:47 - DEBUG - Reward array: [-0.05537639 -0.05645109 -0.05745366 -0.30314532 -0.05951062 -0.10036154
 -0.10036722 -0.06073397 -0.06064081 -2.24986709]
2025-07-28 14:02:47 - DEBUG - Next state: [0.99914974 0.9981082  0.9971525  0.9961204  0.995238   0.99467516
 0.9942489  0.99412745 0.9942113  0.9942836 ]
2025-07-28 14:02:47 - DEBUG - 
end of episode 0, step 92, episode_reward -874.7732925335139, reward -3.1039077151487082

2025-07-28 14:02:47 - DEBUG - critic loss: 5.690542221069336
2025-07-28 14:02:47 - DEBUG - actor loss: 9.372054100036621
2025-07-28 14:02:47 - DEBUG - Using actor
2025-07-28 14:02:47 - DEBUG - 
start of episode 0, step 93

2025-07-28 14:02:47 - DEBUG - State: [0.99914974 0.9981082  0.9971525  0.9961204  0.995238   0.99467516
 0.9942489  0.99412745 0.9942113  0.9942836 ]
2025-07-28 14:02:47 - DEBUG - Action: [0.468615   0.20970762 0.3948182  2.0019863  0.2313152  0.93693316
 1.0375595  0.6923589  0.18609405 7.5372458 ]
2025-07-28 14:02:47 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:47 - DEBUG - Reward: -3.050954750272904
2025-07-28 14:02:47 - DEBUG - Reward array: [-0.06003553 -0.05919657 -0.05803779 -0.30314514 -0.05576602 -0.05521466
 -0.10029932 -0.05466195 -0.05473066 -2.24986709]
2025-07-28 14:02:47 - DEBUG - Next state: [0.99475896 0.99552643 0.99660265 0.9977861  0.99877006 0.99930805
 0.9998044  0.9998523  0.99978435 0.99952847]
2025-07-28 14:02:47 - DEBUG - 
end of episode 0, step 93, episode_reward -877.8242472837868, reward -3.050954750272904

2025-07-28 14:02:47 - DEBUG - critic loss: 7.317230224609375
2025-07-28 14:02:47 - DEBUG - actor loss: 8.870675086975098
2025-07-28 14:02:47 - DEBUG - Using actor
2025-07-28 14:02:47 - DEBUG - 
start of episode 0, step 94

2025-07-28 14:02:47 - DEBUG - State: [0.99475896 0.99552643 0.99660265 0.9977861  0.99877006 0.99930805
 0.9998044  0.9998523  0.99978435 0.99952847]
2025-07-28 14:02:47 - DEBUG - Action: [0.32563984 0.13102949 0.2629605  1.7186632  0.14600009 0.67766815
 0.7811892  0.50407827 0.11722267 7.734932  ]
2025-07-28 14:02:47 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:47 - DEBUG - Reward: -2.7954214403008715
2025-07-28 14:02:47 - DEBUG - Reward array: [-0.05522387 -0.05541697 -0.05561005 -0.1003114  -0.05599613 -0.05611984
 -0.0558646  -0.0556191  -0.05539238 -2.24986709]
2025-07-28 14:02:47 - DEBUG - Next state: [0.99929905 0.9991101  0.99892175 0.998734   0.9985469  0.9984273
 0.99867433 0.99891293 0.9991341  0.9993569 ]
2025-07-28 14:02:47 - DEBUG - 
end of episode 0, step 94, episode_reward -880.6196687240877, reward -2.7954214403008715

2025-07-28 14:02:47 - DEBUG - critic loss: 7.069626331329346
2025-07-28 14:02:47 - DEBUG - actor loss: 8.063460350036621
2025-07-28 14:02:47 - DEBUG - Using actor
2025-07-28 14:02:47 - DEBUG - 
start of episode 0, step 95

2025-07-28 14:02:47 - DEBUG - State: [0.99929905 0.9991101  0.99892175 0.998734   0.9985469  0.9984273
 0.99867433 0.99891293 0.9991341  0.9993569 ]
2025-07-28 14:02:47 - DEBUG - Action: [0.2194053  0.07943541 0.16909689 1.4496553  0.08921653 0.47033638
 0.56746125 0.35562158 0.07167488 7.911648  ]
2025-07-28 14:02:47 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:47 - DEBUG - Reward: -2.8254366321917086
2025-07-28 14:02:47 - DEBUG - Reward array: [-0.05493639 -0.05470716 -0.05451281 -0.10029716 -0.05459564 -0.05587956
 -0.0598849  -0.06599438 -0.07476153 -2.24986709]
2025-07-28 14:02:47 - DEBUG - Next state: [0.99958146 0.9998076  1.         1.         0.9999179  0.99865985
 0.99489605 0.98957044 0.98265505 0.9741571 ]
2025-07-28 14:02:47 - DEBUG - 
end of episode 0, step 95, episode_reward -883.4451053562793, reward -2.8254366321917086

2025-07-28 14:02:47 - DEBUG - critic loss: 5.3945512771606445
2025-07-28 14:02:47 - DEBUG - actor loss: 7.317695617675781
2025-07-28 14:02:47 - DEBUG - Using actor
2025-07-28 14:02:47 - DEBUG - 
start of episode 0, step 96

2025-07-28 14:02:47 - DEBUG - State: [0.99958146 0.9998076  1.         1.         0.9999179  0.99865985
 0.99489605 0.98957044 0.98265505 0.9741571 ]
2025-07-28 14:02:47 - DEBUG - Action: [0.14645606 0.04805058 0.10757834 1.2173071  0.0542438  0.31852782
 0.4039088  0.24753481 0.0437361  8.052916  ]
2025-07-28 14:02:47 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:47 - DEBUG - Reward: -3.863295905069769
2025-07-28 14:02:47 - DEBUG - Reward array: [-0.10182502 -0.11419072 -0.11627679 -0.10123037 -0.10760454 -0.11135492
 -0.12431952 -0.14346967 -0.15726255 -2.7857618 ]
2025-07-28 14:02:47 - DEBUG - Next state: [0.96513057 0.9584773  0.9574185  0.96017134 0.96193653 0.9599444
 0.9534878  0.9449637  0.93942505 0.940269  ]
2025-07-28 14:02:47 - DEBUG - 
end of episode 0, step 96, episode_reward -887.3084012613491, reward -3.863295905069769

2025-07-28 14:02:47 - DEBUG - critic loss: 5.817214012145996
2025-07-28 14:02:47 - DEBUG - actor loss: 6.650699138641357
2025-07-28 14:02:47 - DEBUG - Using actor
2025-07-28 14:02:47 - DEBUG - 
start of episode 0, step 97

2025-07-28 14:02:47 - DEBUG - State: [0.96513057 0.9584773  0.9574185  0.96017134 0.96193653 0.9599444
 0.9534878  0.9449637  0.93942505 0.940269  ]
2025-07-28 14:02:47 - DEBUG - Action: [0.11008531 0.0342074  0.07787675 1.0763636  0.03850162 0.2351129
 0.3106585  0.19043088 0.03145486 8.094043  ]
2025-07-28 14:02:47 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:47 - DEBUG - Reward: -3.509565143561246
2025-07-28 14:02:47 - DEBUG - Reward array: [-0.13610776 -0.10998263 -0.08552402 -0.10046002 -0.05823378 -0.05594389
 -0.05734428 -0.05927888 -0.06092809 -2.7857618 ]
2025-07-28 14:02:47 - DEBUG - Next state: [0.94811463 0.96066636 0.9750974  0.9880611  0.99641925 0.9985975
 0.99725604 0.9954507  0.99395305 0.9929499 ]
2025-07-28 14:02:47 - DEBUG - 
end of episode 0, step 97, episode_reward -890.8179664049103, reward -3.509565143561246

2025-07-28 14:02:47 - DEBUG - critic loss: 5.966011047363281
2025-07-28 14:02:47 - DEBUG - actor loss: 6.266384124755859
2025-07-28 14:02:47 - DEBUG - Using actor
2025-07-28 14:02:47 - DEBUG - 
start of episode 0, step 98

2025-07-28 14:02:47 - DEBUG - State: [0.94811463 0.96066636 0.9750974  0.9880611  0.99641925 0.9985975
 0.99725604 0.9954507  0.99395305 0.9929499 ]
2025-07-28 14:02:47 - DEBUG - Action: [0.06358296 0.01737326 0.04213929 0.85554034 0.01967013 0.1362294
 0.19301087 0.11544645 0.01618564 8.240037  ]
2025-07-28 14:02:47 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:47 - DEBUG - Reward: -3.3415959387126546
2025-07-28 14:02:47 - DEBUG - Reward array: [-0.06284723 -0.0634049  -0.0636547  -0.06352821 -0.0631147  -0.06225987
 -0.06090183 -0.05907987 -0.05704284 -2.7857618 ]
2025-07-28 14:02:47 - DEBUG - Next state: [0.9922556  0.99177116 0.99155533 0.9916645  0.99202275 0.99277014
 0.99397665 0.99563396 0.9975423  0.9990017 ]
2025-07-28 14:02:47 - DEBUG - 
end of episode 0, step 98, episode_reward -894.159562343623, reward -3.3415959387126546

2025-07-28 14:02:47 - DEBUG - critic loss: 4.560004711151123
2025-07-28 14:02:47 - DEBUG - actor loss: 6.203885555267334
2025-07-28 14:02:47 - DEBUG - Using actor
2025-07-28 14:02:47 - DEBUG - 
start of episode 0, step 99

2025-07-28 14:02:47 - DEBUG - State: [0.9922556  0.99177116 0.99155533 0.9916645  0.99202275 0.99277014
 0.99397665 0.99563396 0.9975423  0.9990017 ]
2025-07-28 14:02:47 - DEBUG - Action: [0.03875792 0.0094983  0.0241217  0.6967476  0.01077503 0.08130133
 0.12319535 0.07264912 0.00895679 8.319558  ]
2025-07-28 14:02:47 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:47 - DEBUG - Reward: -3.2765562094902063
2025-07-28 14:02:47 - DEBUG - Reward array: [-0.05469195 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -2.7857618 ]
2025-07-28 14:02:47 - DEBUG - Next state: [0.9998226 1.        1.        1.        1.        1.        1.
 1.        1.        1.       ]
2025-07-28 14:02:47 - DEBUG - 
end of episode 0, step 99, episode_reward -897.4361185531131, reward -3.2765562094902063

2025-07-28 14:02:47 - DEBUG - critic loss: 6.6286163330078125
2025-07-28 14:02:47 - DEBUG - actor loss: 6.263789176940918
2025-07-28 14:02:47 - DEBUG - Using actor
2025-07-28 14:02:47 - DEBUG - 
start of episode 0, step 100

2025-07-28 14:02:47 - DEBUG - State: [0.9998226 1.        1.        1.        1.        1.        1.
 1.        1.        1.       ]
2025-07-28 14:02:47 - DEBUG - Action: [2.3915768e-02 5.2893162e-03 1.3956726e-02 5.7201535e-01 5.9983134e-03
 4.8461854e-02 7.8411400e-02 4.5858026e-02 5.0514936e-03 8.3578491e+00]
2025-07-28 14:02:47 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:47 - DEBUG - Reward: -3.6218552198112457
2025-07-28 14:02:47 - DEBUG - Reward array: [-0.05451281 -0.05463695 -0.05660018 -0.06466055 -0.07865597 -0.10049664
 -0.12386797 -0.14388017 -0.15878218 -2.7857618 ]
2025-07-28 14:02:47 - DEBUG - Next state: [1.         0.99987704 0.9979651  0.9906941  0.9798141  0.9658874
 0.95370245 0.9447923  0.9388412  0.93464845]
2025-07-28 14:02:47 - DEBUG - 
end of episode 0, step 100, episode_reward -901.0579737729244, reward -3.6218552198112457

2025-07-28 14:02:47 - DEBUG - critic loss: 5.694121360778809
2025-07-28 14:02:47 - DEBUG - actor loss: 6.499397277832031
2025-07-28 14:02:47 - DEBUG - Using actor
2025-07-28 14:02:47 - DEBUG - 
start of episode 0, step 101

2025-07-28 14:02:47 - DEBUG - State: [1.         0.99987704 0.9979651  0.9906941  0.9798141  0.9658874
 0.95370245 0.9447923  0.9388412  0.93464845]
2025-07-28 14:02:47 - DEBUG - Action: [1.7603338e-02 3.6999583e-03 9.8052621e-03 5.0935656e-01 4.1660666e-03
 3.3685267e-02 5.7239234e-02 3.3684075e-02 3.5691261e-03 8.2901611e+00]
2025-07-28 14:02:47 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:47 - DEBUG - Reward: -3.908302891981185
2025-07-28 14:02:47 - DEBUG - Reward array: [-0.17450583 -0.17626908 -0.16751511 -0.15024284 -0.12685187 -0.10157237
 -0.0823165  -0.07326305 -0.07000444 -2.7857618 ]
2025-07-28 14:02:47 - DEBUG - Next state: [0.9330714  0.93245304 0.9355779  0.9421881  0.9522967  0.9652738
 0.97725636 0.9837836  0.986311   0.9844232 ]
2025-07-28 14:02:47 - DEBUG - 
end of episode 0, step 101, episode_reward -904.9662766649055, reward -3.908302891981185

2025-07-28 14:02:47 - DEBUG - critic loss: 4.73427152633667
2025-07-28 14:02:47 - DEBUG - actor loss: 6.807528972625732
2025-07-28 14:02:47 - DEBUG - Using actor
2025-07-28 14:02:47 - DEBUG - 
start of episode 0, step 102

2025-07-28 14:02:48 - DEBUG - State: [0.9330714  0.93245304 0.9355779  0.9421881  0.9522967  0.9652738
 0.97725636 0.9837836  0.986311   0.9844232 ]
2025-07-28 14:02:48 - DEBUG - Action: [1.2657642e-02 2.5197864e-03 6.7287683e-03 4.5420051e-01 2.8216839e-03
 2.2847354e-02 4.0812194e-02 2.4201572e-02 2.4551153e-03 8.1877670e+00]
2025-07-28 14:02:48 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:48 - DEBUG - Reward: -3.524399456926596
2025-07-28 14:02:48 - DEBUG - Reward array: [-0.07625254 -0.07933458 -0.08186216 -0.08101613 -0.07906289 -0.07988078
 -0.0829759  -0.08710656 -0.09114612 -2.7857618 ]
2025-07-28 14:02:48 - DEBUG - Next state: [0.98155206 0.97933203 0.97756827 0.9781531  0.97952455 0.9789466
 0.97680646 0.9740588  0.971482   0.96923494]
2025-07-28 14:02:48 - DEBUG - 
end of episode 0, step 102, episode_reward -908.4906761218322, reward -3.524399456926596

2025-07-28 14:02:48 - DEBUG - critic loss: 5.226442337036133
2025-07-28 14:02:48 - DEBUG - actor loss: 6.950420379638672
2025-07-28 14:02:48 - DEBUG - Using actor
2025-07-28 14:02:48 - DEBUG - 
start of episode 0, step 103

2025-07-28 14:02:48 - DEBUG - State: [0.98155206 0.97933203 0.97756827 0.9781531  0.97952455 0.9789466
 0.97680646 0.9740588  0.971482   0.96923494]
2025-07-28 14:02:48 - DEBUG - Action: [7.4085593e-03 1.3211370e-03 3.6716461e-03 3.7330985e-01 1.4874339e-03
 1.2701154e-02 2.4432242e-02 1.4321208e-02 1.3008714e-03 8.1046829e+00]
2025-07-28 14:02:48 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:48 - DEBUG - Reward: -3.5839875557146037
2025-07-28 14:02:48 - DEBUG - Reward array: [-0.10025826 -0.10472862 -0.10476833 -0.10132314 -0.09478075 -0.08671076
 -0.07759848 -0.06800747 -0.06004993 -2.7857618 ]
2025-07-28 14:02:48 - DEBUG - Next state: [0.96602416 0.9635063  0.96348435 0.9654155  0.9692491  0.97431695
 0.9805728  0.9879126  0.9947459  0.99858326]
2025-07-28 14:02:48 - DEBUG - 
end of episode 0, step 103, episode_reward -912.0746636775468, reward -3.5839875557146037

2025-07-28 14:02:48 - DEBUG - critic loss: 4.462117671966553
2025-07-28 14:02:48 - DEBUG - actor loss: 6.85038423538208
2025-07-28 14:02:48 - DEBUG - Using actor
2025-07-28 14:02:48 - DEBUG - 
start of episode 0, step 104

2025-07-28 14:02:48 - DEBUG - State: [0.96602416 0.9635063  0.96348435 0.9654155  0.9692491  0.97431695
 0.9805728  0.9879126  0.9947459  0.99858326]
2025-07-28 14:02:48 - DEBUG - Action: [5.0297379e-03 8.3625317e-04 2.3603439e-03 3.2927275e-01 9.4503164e-04
 8.0904365e-03 1.6485155e-02 9.6732378e-03 8.2999468e-04 7.9080462e+00]
2025-07-28 14:02:48 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:48 - DEBUG - Reward: -2.740482356372203
2025-07-28 14:02:48 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -2.24986709]
2025-07-28 14:02:48 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:48 - DEBUG - 
end of episode 0, step 104, episode_reward -914.8151460339191, reward -2.740482356372203

2025-07-28 14:02:48 - DEBUG - critic loss: 4.559622764587402
2025-07-28 14:02:48 - DEBUG - actor loss: 6.604890823364258
2025-07-28 14:02:48 - DEBUG - Using actor
2025-07-28 14:02:48 - DEBUG - 
start of episode 0, step 105

2025-07-28 14:02:48 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:48 - DEBUG - Action: [2.8935075e-03 4.2945147e-04 1.2606382e-03 2.7293026e-01 4.9084425e-04
 4.3803453e-03 9.6315145e-03 5.5810809e-03 4.3004751e-04 7.6928496e+00]
2025-07-28 14:02:48 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:48 - DEBUG - Reward: -2.740482356372203
2025-07-28 14:02:48 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -2.24986709]
2025-07-28 14:02:48 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:48 - DEBUG - 
end of episode 0, step 105, episode_reward -917.5556283902913, reward -2.740482356372203

2025-07-28 14:02:48 - DEBUG - critic loss: 3.8427085876464844
2025-07-28 14:02:48 - DEBUG - actor loss: 6.077609539031982
2025-07-28 14:02:48 - DEBUG - Using actor
2025-07-28 14:02:48 - DEBUG - 
start of episode 0, step 106

2025-07-28 14:02:48 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:48 - DEBUG - Action: [1.9994378e-03 2.7775764e-04 8.2522631e-04 2.4670601e-01 3.2007694e-04
 2.8273463e-03 6.5702200e-03 3.8060546e-03 2.7924776e-04 7.3494649e+00]
2025-07-28 14:02:48 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:48 - DEBUG - Reward: -2.740482356372203
2025-07-28 14:02:48 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -2.24986709]
2025-07-28 14:02:48 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:48 - DEBUG - 
end of episode 0, step 106, episode_reward -920.2961107466635, reward -2.740482356372203

2025-07-28 14:02:48 - DEBUG - critic loss: 3.189408540725708
2025-07-28 14:02:48 - DEBUG - actor loss: 5.443610668182373
2025-07-28 14:02:48 - DEBUG - Using actor
2025-07-28 14:02:48 - DEBUG - 
start of episode 0, step 107

2025-07-28 14:02:48 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:48 - DEBUG - Action: [1.4048815e-03 1.8358231e-04 5.5044889e-04 2.2470891e-01 2.1219254e-04
 1.8608570e-03 4.5394897e-03 2.6425719e-03 1.8537045e-04 7.0495424e+00]
2025-07-28 14:02:48 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:48 - DEBUG - Reward: -2.740482356372203
2025-07-28 14:02:48 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -2.24986709]
2025-07-28 14:02:48 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:48 - DEBUG - 
end of episode 0, step 107, episode_reward -923.0365931030358, reward -2.740482356372203

2025-07-28 14:02:48 - DEBUG - critic loss: 3.3765015602111816
2025-07-28 14:02:48 - DEBUG - actor loss: 4.866453170776367
2025-07-28 14:02:48 - DEBUG - Using actor
2025-07-28 14:02:48 - DEBUG - 
start of episode 0, step 108

2025-07-28 14:02:48 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:48 - DEBUG - Action: [1.0019541e-03 1.2427568e-04 3.7461519e-04 2.0544827e-01 1.4245510e-04
 1.2513995e-03 3.1813979e-03 1.8694997e-03 1.2546778e-04 6.8949246e+00]
2025-07-28 14:02:48 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:48 - DEBUG - Reward: -2.2487088925210905
2025-07-28 14:02:48 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -1.75809363]
2025-07-28 14:02:48 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:48 - DEBUG - 
end of episode 0, step 108, episode_reward -925.2853019955569, reward -2.2487088925210905

2025-07-28 14:02:48 - DEBUG - critic loss: 1.9446532726287842
2025-07-28 14:02:48 - DEBUG - actor loss: 4.414128303527832
2025-07-28 14:02:48 - DEBUG - Using actor
2025-07-28 14:02:48 - DEBUG - 
start of episode 0, step 109

2025-07-28 14:02:48 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:48 - DEBUG - Action: [7.2538853e-04 8.5830688e-05 2.5987625e-04 1.8943965e-01 9.6857548e-05
 8.6069107e-04 2.2619963e-03 1.3509393e-03 8.7320805e-05 6.9047542e+00]
2025-07-28 14:02:48 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:48 - DEBUG - Reward: -2.2487088925210905
2025-07-28 14:02:48 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -1.75809363]
2025-07-28 14:02:48 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:48 - DEBUG - 
end of episode 0, step 109, episode_reward -927.534010888078, reward -2.2487088925210905

2025-07-28 14:02:48 - DEBUG - critic loss: 3.464390754699707
2025-07-28 14:02:48 - DEBUG - actor loss: 4.156771183013916
2025-07-28 14:02:48 - DEBUG - Using actor
2025-07-28 14:02:48 - DEBUG - 
start of episode 0, step 110

2025-07-28 14:02:48 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:48 - DEBUG - Action: [5.3286552e-04 6.0498714e-05 1.8298626e-04 1.7592639e-01 6.6757202e-05
 6.0558319e-04 1.6307831e-03 9.9450350e-04 6.1988831e-05 7.1105075e+00]
2025-07-28 14:02:48 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:48 - DEBUG - Reward: -2.740482356372203
2025-07-28 14:02:48 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -2.24986709]
2025-07-28 14:02:48 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:48 - DEBUG - 
end of episode 0, step 110, episode_reward -930.2744932444502, reward -2.740482356372203

2025-07-28 14:02:48 - DEBUG - critic loss: 3.3923258781433105
2025-07-28 14:02:48 - DEBUG - actor loss: 4.033672332763672
2025-07-28 14:02:48 - DEBUG - Using actor
2025-07-28 14:02:48 - DEBUG - 
start of episode 0, step 111

2025-07-28 14:02:48 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:48 - DEBUG - Action: [3.9786100e-04 4.3809414e-05 1.3142824e-04 1.6657650e-01 4.6491623e-05
 4.3600798e-04 1.1929870e-03 7.4446201e-04 4.5001507e-05 7.3839192e+00]
2025-07-28 14:02:48 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:48 - DEBUG - Reward: -2.740482356372203
2025-07-28 14:02:48 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -2.24986709]
2025-07-28 14:02:48 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:48 - DEBUG - 
end of episode 0, step 111, episode_reward -933.0149756008225, reward -2.740482356372203

2025-07-28 14:02:48 - DEBUG - critic loss: 1.1832436323165894
2025-07-28 14:02:48 - DEBUG - actor loss: 3.9750256538391113
2025-07-28 14:02:48 - DEBUG - Using actor
2025-07-28 14:02:48 - DEBUG - 
start of episode 0, step 112

2025-07-28 14:02:48 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:48 - DEBUG - Action: [3.0189753e-04 3.2186508e-05 9.6261501e-05 1.6045153e-01 3.2782555e-05
 3.2126904e-04 8.8661909e-04 5.6773424e-04 3.3676624e-05 7.7090130e+00]
2025-07-28 14:02:48 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:48 - DEBUG - Reward: -2.740482356372203
2025-07-28 14:02:48 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -2.24986709]
2025-07-28 14:02:48 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:48 - DEBUG - 
end of episode 0, step 112, episode_reward -935.7554579571947, reward -2.740482356372203

2025-07-28 14:02:48 - DEBUG - critic loss: 2.5620977878570557
2025-07-28 14:02:48 - DEBUG - actor loss: 3.9146862030029297
2025-07-28 14:02:48 - DEBUG - Using actor
2025-07-28 14:02:48 - DEBUG - 
start of episode 0, step 113

2025-07-28 14:02:48 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:48 - DEBUG - Action: [2.3335218e-04 2.4139881e-05 7.1823597e-05 1.5578598e-01 2.3841858e-05
 2.4169683e-04 6.7085028e-04 4.4018030e-04 2.5629997e-05 7.9939260e+00]
2025-07-28 14:02:48 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:48 - DEBUG - Reward: -2.740482356372203
2025-07-28 14:02:48 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -2.24986709]
2025-07-28 14:02:48 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:48 - DEBUG - 
end of episode 0, step 113, episode_reward -938.495940313567, reward -2.740482356372203

2025-07-28 14:02:48 - DEBUG - critic loss: 2.0606870651245117
2025-07-28 14:02:48 - DEBUG - actor loss: 3.873861789703369
2025-07-28 14:02:48 - DEBUG - Using actor
2025-07-28 14:02:48 - DEBUG - 
start of episode 0, step 114

2025-07-28 14:02:48 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:48 - DEBUG - Action: [1.8417835e-04 1.8775463e-05 5.4836273e-05 1.5247732e-01 1.7583370e-05
 1.8537045e-04 5.1796436e-04 3.4719706e-04 1.9967556e-05 8.2068052e+00]
2025-07-28 14:02:48 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:48 - DEBUG - Reward: -3.276377064118573
2025-07-28 14:02:48 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -2.7857618 ]
2025-07-28 14:02:48 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:48 - DEBUG - 
end of episode 0, step 114, episode_reward -941.7723173776856, reward -3.276377064118573

2025-07-28 14:02:49 - DEBUG - critic loss: 2.2191221714019775
2025-07-28 14:02:49 - DEBUG - actor loss: 3.698918581008911
2025-07-28 14:02:49 - DEBUG - Using actor
2025-07-28 14:02:49 - DEBUG - 
start of episode 0, step 115

2025-07-28 14:02:49 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:49 - DEBUG - Action: [1.4901161e-04 1.4603138e-05 4.3213367e-05 1.4997989e-01 1.3709068e-05
 1.4632940e-04 4.1127205e-04 2.7835369e-04 1.5795231e-05 8.2507782e+00]
2025-07-28 14:02:49 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:49 - DEBUG - Reward: -3.276377064118573
2025-07-28 14:02:49 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -2.7857618 ]
2025-07-28 14:02:49 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:49 - DEBUG - 
end of episode 0, step 115, episode_reward -945.0486944418042, reward -3.276377064118573

2025-07-28 14:02:49 - DEBUG - critic loss: 2.2232959270477295
2025-07-28 14:02:49 - DEBUG - actor loss: 3.4093830585479736
2025-07-28 14:02:49 - DEBUG - Using actor
2025-07-28 14:02:49 - DEBUG - 
start of episode 0, step 116

2025-07-28 14:02:49 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:49 - DEBUG - Action: [1.2397766e-04 1.1920929e-05 3.4868717e-05 1.4872193e-01 1.1026859e-05
 1.1801720e-04 3.3497810e-04 2.2709370e-04 1.3113022e-05 8.1627560e+00]
2025-07-28 14:02:49 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:49 - DEBUG - Reward: -3.303272627730518
2025-07-28 14:02:49 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05452667 -0.05473542 -0.05562896
 -0.05799858 -0.06270387 -0.0683789  -2.7857618 ]
2025-07-28 14:02:49 - DEBUG - Next state: [1.         1.         1.         0.99998623 0.99977964 0.99890333
 0.9966394  0.9923808  0.98761153 0.98413086]
2025-07-28 14:02:49 - DEBUG - 
end of episode 0, step 116, episode_reward -948.3519670695347, reward -3.303272627730518

2025-07-28 14:02:49 - DEBUG - critic loss: 1.145166277885437
2025-07-28 14:02:49 - DEBUG - actor loss: 2.979653835296631
2025-07-28 14:02:49 - DEBUG - Using actor
2025-07-28 14:02:49 - DEBUG - 
start of episode 0, step 117

2025-07-28 14:02:49 - DEBUG - State: [1.         1.         1.         0.99998623 0.99977964 0.99890333
 0.9966394  0.9923808  0.98761153 0.98413086]
2025-07-28 14:02:49 - DEBUG - Action: [1.08480453e-04 1.01327896e-05 2.98023224e-05 1.50518119e-01
 9.23871994e-06 1.00731850e-04 2.86996365e-04 1.94311142e-04
 1.13248825e-05 7.98815489e+00]
2025-07-28 14:02:49 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:49 - DEBUG - Reward: -3.0012680250273935
2025-07-28 14:02:49 - DEBUG - Reward array: [-0.07610152 -0.07826551 -0.08029946 -0.08227655 -0.08247234 -0.08118931
 -0.08150091 -0.08787336 -0.10142196 -2.24986709]
2025-07-28 14:02:49 - DEBUG - Next state: [0.98166287 0.9800932  0.97865283 0.9772837  0.9771497  0.97803295
 0.9778173  0.9735616  0.9653593  0.956737  ]
2025-07-28 14:02:49 - DEBUG - 
end of episode 0, step 117, episode_reward -951.353235094562, reward -3.0012680250273935

2025-07-28 14:02:49 - DEBUG - critic loss: 1.678091049194336
2025-07-28 14:02:49 - DEBUG - actor loss: 2.5712766647338867
2025-07-28 14:02:49 - DEBUG - Using actor
2025-07-28 14:02:49 - DEBUG - 
start of episode 0, step 118

2025-07-28 14:02:49 - DEBUG - State: [0.98166287 0.9800932  0.97865283 0.9772837  0.9771497  0.97803295
 0.9778173  0.9735616  0.9653593  0.956737  ]
2025-07-28 14:02:49 - DEBUG - Action: [1.14440918e-04 1.10268593e-05 3.12924385e-05 1.62343979e-01
 1.01327896e-05 1.04010105e-04 2.92658806e-04 1.99973583e-04
 1.22189522e-05 7.86877108e+00]
2025-07-28 14:02:49 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:49 - DEBUG - Reward: -3.573023848062737
2025-07-28 14:02:49 - DEBUG - Reward array: [-0.13321335 -0.14703109 -0.15799693 -0.16603085 -0.16772965 -0.16127868
 -0.14953929 -0.13117652 -0.10916039 -2.24986709]
2025-07-28 14:02:49 - DEBUG - Next state: [0.9493947  0.9434902  0.9391423  0.9361219  0.93549967 0.9378926
 0.9424712  0.9503103  0.9611027  0.9731037 ]
2025-07-28 14:02:49 - DEBUG - 
end of episode 0, step 118, episode_reward -954.9262589426247, reward -3.573023848062737

2025-07-28 14:02:49 - DEBUG - critic loss: 2.0310661792755127
2025-07-28 14:02:49 - DEBUG - actor loss: 2.341245651245117
2025-07-28 14:02:49 - DEBUG - Using actor
2025-07-28 14:02:49 - DEBUG - 
start of episode 0, step 119

2025-07-28 14:02:49 - DEBUG - State: [0.9493947  0.9434902  0.9391423  0.9361219  0.93549967 0.9378926
 0.9424712  0.9503103  0.9611027  0.9731037 ]
2025-07-28 14:02:49 - DEBUG - Action: [1.3202429e-04 1.3411045e-05 3.6656857e-05 1.7970562e-01 1.1920929e-05
 1.1861324e-04 3.2484531e-04 2.2619963e-04 1.4901161e-05 7.8357863e+00]
2025-07-28 14:02:49 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:49 - DEBUG - Reward: -2.924865701285897
2025-07-28 14:02:49 - DEBUG - Reward array: [-0.07442611 -0.06936005 -0.07056649 -0.07237264 -0.07350954 -0.0749605
 -0.07730338 -0.0803372  -0.0821627  -2.24986709]
2025-07-28 14:02:49 - DEBUG - Next state: [0.98290586 0.98682326 0.9858677  0.98446405 0.9835965  0.9825067
 0.9807862  0.97862643 0.9773618  0.9785788 ]
2025-07-28 14:02:49 - DEBUG - 
end of episode 0, step 119, episode_reward -957.8511246439106, reward -2.924865701285897

2025-07-28 14:02:49 - DEBUG - critic loss: 0.7170397639274597
2025-07-28 14:02:49 - DEBUG - actor loss: 2.236071825027466
2025-07-28 14:02:49 - DEBUG - Using actor
2025-07-28 14:02:49 - DEBUG - 
start of episode 0, step 120

2025-07-28 14:02:49 - DEBUG - State: [0.98290586 0.98682326 0.9858677  0.98446405 0.9835965  0.9825067
 0.9807862  0.97862643 0.9773618  0.9785788 ]
2025-07-28 14:02:49 - DEBUG - Action: [7.9572201e-05 7.4505806e-06 2.0861626e-05 1.5878052e-01 6.5565109e-06
 6.9737434e-05 1.9907951e-04 1.3828278e-04 8.3446503e-06 8.0156031e+00]
2025-07-28 14:02:49 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:49 - DEBUG - Reward: -3.361727663847135
2025-07-28 14:02:49 - DEBUG - Reward array: [-0.07595155 -0.0699759  -0.06399624 -0.05909324 -0.05578249 -0.05460692
 -0.05607882 -0.06285404 -0.07762667 -2.7857618 ]
2025-07-28 14:02:49 - DEBUG - Next state: [0.98177314 0.9863336  0.99126154 0.9956216  0.998754   0.9999068
 0.9984669  0.99224967 0.9805525  0.96738213]
2025-07-28 14:02:49 - DEBUG - 
end of episode 0, step 120, episode_reward -961.2128523077577, reward -3.361727663847135

2025-07-28 14:02:49 - DEBUG - critic loss: 2.369553565979004
2025-07-28 14:02:49 - DEBUG - actor loss: 2.3073484897613525
2025-07-28 14:02:49 - DEBUG - Using actor
2025-07-28 14:02:49 - DEBUG - 
start of episode 0, step 121

2025-07-28 14:02:49 - DEBUG - State: [0.98177314 0.9863336  0.99126154 0.9956216  0.998754   0.9999068
 0.9984669  0.99224967 0.9805525  0.96738213]
2025-07-28 14:02:49 - DEBUG - Action: [6.49690628e-05 5.96046448e-06 1.66893005e-05 1.56171322e-01
 5.06639481e-06 5.60283661e-05 1.61230564e-04 1.13248825e-04
 6.55651093e-06 8.15142441e+00]
2025-07-28 14:02:49 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:49 - DEBUG - Reward: -4.404340663393916
2025-07-28 14:02:49 - DEBUG - Reward array: [-0.12954483 -0.15746925 -0.17555874 -0.18678424 -0.19241188 -0.19620368
 -0.20406591 -0.19891161 -0.17762871 -2.7857618 ]
2025-07-28 14:02:49 - DEBUG - Next state: [0.9510529  0.93934536 0.93270147 0.92887384 0.9270299  0.92581385
 0.9233561  0.9249578  0.9319799  0.9439248 ]
2025-07-28 14:02:49 - DEBUG - 
end of episode 0, step 121, episode_reward -965.6171929711516, reward -4.404340663393916

2025-07-28 14:02:49 - DEBUG - critic loss: 2.0176737308502197
2025-07-28 14:02:49 - DEBUG - actor loss: 2.466277599334717
2025-07-28 14:02:49 - DEBUG - Using actor
2025-07-28 14:02:49 - DEBUG - 
start of episode 0, step 122

2025-07-28 14:02:49 - DEBUG - State: [0.9510529  0.93934536 0.93270147 0.92887384 0.9270299  0.92581385
 0.9233561  0.9249578  0.9319799  0.9439248 ]
2025-07-28 14:02:49 - DEBUG - Action: [1.0371208e-04 1.0430813e-05 2.7716160e-05 1.9111335e-01 8.9406967e-06
 8.9406967e-05 2.4378300e-04 1.7434359e-04 1.1622906e-05 7.9697847e+00]
2025-07-28 14:02:49 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:49 - DEBUG - Reward: -2.834049457709459
2025-07-28 14:02:49 - DEBUG - Reward array: [-0.10813255 -0.08138841 -0.06561569 -0.05648168 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -2.24986709]
2025-07-28 14:02:49 - DEBUG - Next state: [0.9616524  0.9778951  0.98988736 0.9980788  1.         1.
 1.         1.         1.         1.        ]
2025-07-28 14:02:49 - DEBUG - 
end of episode 0, step 122, episode_reward -968.4512424288611, reward -2.834049457709459

2025-07-28 14:02:49 - DEBUG - critic loss: 0.7263664603233337
2025-07-28 14:02:49 - DEBUG - actor loss: 2.5794570446014404
2025-07-28 14:02:49 - DEBUG - Using actor
2025-07-28 14:02:49 - DEBUG - 
start of episode 0, step 123

2025-07-28 14:02:49 - DEBUG - State: [0.9616524  0.9778951  0.98988736 0.9980788  1.         1.
 1.         1.         1.         1.        ]
2025-07-28 14:02:49 - DEBUG - Action: [5.2154064e-05 4.4703484e-06 1.2814999e-05 1.5786231e-01 3.8743019e-06
 4.3213367e-05 1.2606382e-04 8.7916851e-05 5.0663948e-06 7.8278723e+00]
2025-07-28 14:02:49 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:49 - DEBUG - Reward: -2.740482356372203
2025-07-28 14:02:49 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -2.24986709]
2025-07-28 14:02:49 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:49 - DEBUG - 
end of episode 0, step 123, episode_reward -971.1917247852333, reward -2.740482356372203

2025-07-28 14:02:49 - DEBUG - critic loss: 1.9323015213012695
2025-07-28 14:02:49 - DEBUG - actor loss: 2.699251651763916
2025-07-28 14:02:49 - DEBUG - Using actor
2025-07-28 14:02:49 - DEBUG - 
start of episode 0, step 124

2025-07-28 14:02:49 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:49 - DEBUG - Action: [4.4107437e-05 3.5762787e-06 1.0430813e-05 1.5522003e-01 3.2782555e-06
 3.5762787e-05 1.0609627e-04 7.2717667e-05 4.1723251e-06 7.4094973e+00]
2025-07-28 14:02:49 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:49 - DEBUG - Reward: -2.740482356372203
2025-07-28 14:02:49 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -2.24986709]
2025-07-28 14:02:49 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:49 - DEBUG - 
end of episode 0, step 124, episode_reward -973.9322071416055, reward -2.740482356372203

2025-07-28 14:02:49 - DEBUG - critic loss: 1.892316460609436
2025-07-28 14:02:49 - DEBUG - actor loss: 2.7407610416412354
2025-07-28 14:02:49 - DEBUG - Using actor
2025-07-28 14:02:49 - DEBUG - 
start of episode 0, step 125

2025-07-28 14:02:49 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:49 - DEBUG - Action: [4.1127205e-05 3.2782555e-06 9.8347664e-06 1.5834481e-01 2.9802322e-06
 3.2782555e-05 9.7453594e-05 6.6161156e-05 3.8743019e-06 7.0512080e+00]
2025-07-28 14:02:49 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:49 - DEBUG - Reward: -2.740482356372203
2025-07-28 14:02:49 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -2.24986709]
2025-07-28 14:02:49 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:49 - DEBUG - 
end of episode 0, step 125, episode_reward -976.6726894979778, reward -2.740482356372203

2025-07-28 14:02:49 - DEBUG - critic loss: 1.5277783870697021
2025-07-28 14:02:49 - DEBUG - actor loss: 2.7219903469085693
2025-07-28 14:02:49 - DEBUG - Using actor
2025-07-28 14:02:49 - DEBUG - 
start of episode 0, step 126

2025-07-28 14:02:49 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:49 - DEBUG - Action: [3.8444996e-05 3.2782555e-06 8.9406967e-06 1.6170502e-01 2.6822090e-06
 3.0100346e-05 8.9704990e-05 6.0796738e-05 3.5762787e-06 6.9093571e+00]
2025-07-28 14:02:49 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:49 - DEBUG - Reward: -2.2487088925210905
2025-07-28 14:02:49 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -1.75809363]
2025-07-28 14:02:49 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:49 - DEBUG - 
end of episode 0, step 126, episode_reward -978.9213983904989, reward -2.2487088925210905

2025-07-28 14:02:49 - DEBUG - critic loss: 0.31081801652908325
2025-07-28 14:02:49 - DEBUG - actor loss: 2.6879055500030518
2025-07-28 14:02:49 - DEBUG - Using actor
2025-07-28 14:02:49 - DEBUG - 
start of episode 0, step 127

2025-07-28 14:02:50 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:50 - DEBUG - Action: [3.5762787e-05 2.9802322e-06 8.3446503e-06 1.6605109e-01 2.3841858e-06
 2.7716160e-05 8.2850456e-05 5.6624413e-05 3.2782555e-06 7.0256433e+00]
2025-07-28 14:02:50 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:50 - DEBUG - Reward: -2.740482356372203
2025-07-28 14:02:50 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -2.24986709]
2025-07-28 14:02:50 - DEBUG - Next state: [1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.99984837]
2025-07-28 14:02:50 - DEBUG - 
end of episode 0, step 127, episode_reward -981.6618807468711, reward -2.740482356372203

2025-07-28 14:02:50 - DEBUG - critic loss: 0.41989389061927795
2025-07-28 14:02:50 - DEBUG - actor loss: 2.70145320892334
2025-07-28 14:02:50 - DEBUG - Using actor
2025-07-28 14:02:50 - DEBUG - 
start of episode 0, step 128

2025-07-28 14:02:50 - DEBUG - State: [1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.99984837]
2025-07-28 14:02:50 - DEBUG - Action: [3.3080578e-05 2.6822090e-06 7.4505806e-06 1.7206252e-01 2.3841858e-06
 2.5629997e-05 7.6591969e-05 5.3048134e-05 3.2782555e-06 7.3200350e+00]
2025-07-28 14:02:50 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:50 - DEBUG - Reward: -3.59486724707348
2025-07-28 14:02:50 - DEBUG - Reward array: [-0.0571116  -0.0672231  -0.08845304 -0.12007171 -0.15477537 -0.18555911
 -0.20905447 -0.22790446 -0.23484729 -2.24986709]
2025-07-28 14:02:50 - DEBUG - Next state: [0.9974769  0.9885532  0.9731882  0.9555348  0.9403914  0.92928165
 0.921839   0.91637623 0.91446245 0.91618717]
2025-07-28 14:02:50 - DEBUG - 
end of episode 0, step 128, episode_reward -985.2567479939446, reward -3.59486724707348

2025-07-28 14:02:50 - DEBUG - critic loss: 1.7349066734313965
2025-07-28 14:02:50 - DEBUG - actor loss: 2.827843189239502
2025-07-28 14:02:50 - DEBUG - Using actor
2025-07-28 14:02:50 - DEBUG - 
start of episode 0, step 129

2025-07-28 14:02:50 - DEBUG - State: [0.9974769  0.9885532  0.9731882  0.9555348  0.9403914  0.92928165
 0.921839   0.91637623 0.91446245 0.91618717]
2025-07-28 14:02:50 - DEBUG - Action: [5.3346157e-05 4.7683716e-06 1.3113022e-05 2.1387666e-01 4.1723251e-06
 4.2617321e-05 1.1920929e-04 8.4936619e-05 5.6624413e-06 7.5471220e+00]
2025-07-28 14:02:50 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:50 - DEBUG - Reward: -3.27157574823344
2025-07-28 14:02:50 - DEBUG - Reward array: [-0.21158641 -0.18262732 -0.14813584 -0.11503685 -0.08789101 -0.07253558
 -0.06720299 -0.06755955 -0.0691331  -2.24986709]
2025-07-28 14:02:50 - DEBUG - Next state: [0.921081   0.9302672  0.94303954 0.9580458  0.9735502  0.98433894
 0.98856974 0.9882776  0.9870047  0.98712003]
2025-07-28 14:02:50 - DEBUG - 
end of episode 0, step 129, episode_reward -988.528323742178, reward -3.27157574823344

2025-07-28 14:02:50 - DEBUG - critic loss: 1.8301860094070435
2025-07-28 14:02:50 - DEBUG - actor loss: 3.0676448345184326
2025-07-28 14:02:50 - DEBUG - Using actor
2025-07-28 14:02:50 - DEBUG - 
start of episode 0, step 130

2025-07-28 14:02:50 - DEBUG - State: [0.921081   0.9302672  0.94303954 0.9580458  0.9735502  0.98433894
 0.98856974 0.9882776  0.9870047  0.98712003]
2025-07-28 14:02:50 - DEBUG - Action: [4.3213367e-05 3.8743019e-06 1.0430813e-05 2.1580935e-01 2.9802322e-06
 3.4272671e-05 9.7155571e-05 6.9439411e-05 4.4703484e-06 7.7174196e+00]
2025-07-28 14:02:50 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:50 - DEBUG - Reward: -3.0174078809532463
2025-07-28 14:02:50 - DEBUG - Reward array: [-0.06716729 -0.06510787 -0.06287713 -0.06156982 -0.06463169 -0.07558888
 -0.09636924 -0.12434675 -0.14988214 -2.24986709]
2025-07-28 14:02:50 - DEBUG - Next state: [0.98859906 0.99031496 0.9922296  0.9933802  0.99071866 0.9820406
 0.9682972  0.9534749  0.94233304 0.93601626]
2025-07-28 14:02:50 - DEBUG - 
end of episode 0, step 130, episode_reward -991.5457316231312, reward -3.0174078809532463

2025-07-28 14:02:50 - DEBUG - critic loss: 1.6672927141189575
2025-07-28 14:02:50 - DEBUG - actor loss: 3.3550877571105957
2025-07-28 14:02:50 - DEBUG - Using actor
2025-07-28 14:02:50 - DEBUG - 
start of episode 0, step 131

2025-07-28 14:02:50 - DEBUG - State: [0.98859906 0.99031496 0.9922296  0.9933802  0.99071866 0.9820406
 0.9682972  0.9534749  0.94233304 0.93601626]
2025-07-28 14:02:50 - DEBUG - Action: [3.6358833e-05 3.2782555e-06 8.3446503e-06 2.2042811e-01 2.3841858e-06
 2.8312206e-05 8.1658363e-05 5.7816505e-05 3.5762787e-06 7.6121306e+00]
2025-07-28 14:02:50 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:50 - DEBUG - Reward: -3.658961403103981
2025-07-28 14:02:50 - DEBUG - Reward array: [-0.17647616 -0.18303972 -0.18728142 -0.18990343 -0.18555713 -0.16694647
 -0.13707423 -0.10419518 -0.07862058 -2.24986709]
2025-07-28 14:02:50 - DEBUG - Next state: [0.93238074 0.93012774 0.928709   0.92784595 0.9292823  0.93578583
 0.9476925  0.9638017  0.9798393  0.99166244]
2025-07-28 14:02:50 - DEBUG - 
end of episode 0, step 131, episode_reward -995.2046930262352, reward -3.658961403103981

2025-07-28 14:02:50 - DEBUG - critic loss: 1.3672620058059692
2025-07-28 14:02:50 - DEBUG - actor loss: 3.583963394165039
2025-07-28 14:02:50 - DEBUG - Using actor
2025-07-28 14:02:50 - DEBUG - 
start of episode 0, step 132

2025-07-28 14:02:50 - DEBUG - State: [0.93238074 0.93012774 0.928709   0.92784595 0.9292823  0.93578583
 0.9476925  0.9638017  0.9798393  0.99166244]
2025-07-28 14:02:50 - DEBUG - Action: [5.0067902e-05 4.7683716e-06 1.1920929e-05 2.6170164e-01 3.8743019e-06
 3.9339066e-05 1.0877848e-04 7.7486038e-05 5.3644180e-06 7.1572905e+00]
2025-07-28 14:02:50 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:50 - DEBUG - Reward: -2.7423475683428618
2025-07-28 14:02:50 - DEBUG - Reward array: [-0.05637802 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -2.24986709]
2025-07-28 14:02:50 - DEBUG - Next state: [0.9981784 1.        1.        1.        1.        1.        1.
 1.        1.        1.       ]
2025-07-28 14:02:50 - DEBUG - 
end of episode 0, step 132, episode_reward -997.9470405945781, reward -2.7423475683428618

2025-07-28 14:02:50 - DEBUG - critic loss: 1.577937364578247
2025-07-28 14:02:50 - DEBUG - actor loss: 3.6531195640563965
2025-07-28 14:02:50 - DEBUG - Using actor
2025-07-28 14:02:50 - DEBUG - 
start of episode 0, step 133

2025-07-28 14:02:50 - DEBUG - State: [0.9981784 1.        1.        1.        1.        1.        1.
 1.        1.        1.       ]
2025-07-28 14:02:50 - DEBUG - Action: [2.7120113e-05 2.0861626e-06 5.9604645e-06 2.4034679e-01 1.7881393e-06
 2.0563602e-05 6.0200691e-05 4.1723251e-05 2.6822090e-06 6.6663971e+00]
2025-07-28 14:02:50 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:50 - DEBUG - Reward: -2.2487088925210905
2025-07-28 14:02:50 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -1.75809363]
2025-07-28 14:02:50 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:50 - DEBUG - 
end of episode 0, step 133, episode_reward -1000.1957494870992, reward -2.2487088925210905

2025-07-28 14:02:50 - DEBUG - critic loss: 0.9853616952896118
2025-07-28 14:02:50 - DEBUG - actor loss: 3.584231376647949
2025-07-28 14:02:50 - DEBUG - Using actor
2025-07-28 14:02:50 - DEBUG - 
start of episode 0, step 134

2025-07-28 14:02:50 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:50 - DEBUG - Action: [2.6822090e-05 2.0861626e-06 5.9604645e-06 2.6800931e-01 1.7881393e-06
 1.9967556e-05 5.8710575e-05 4.0233135e-05 2.3841858e-06 6.1000543e+00]
2025-07-28 14:02:50 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:50 - DEBUG - Reward: -2.2819379753445848
2025-07-28 14:02:50 - DEBUG - Reward array: [-0.05451281 -0.05453412 -0.05485656 -0.05612249 -0.05785946 -0.05946262
 -0.06091691 -0.06220805 -0.06337133 -1.75809363]
2025-07-28 14:02:50 - DEBUG - Next state: [1.         0.99997884 0.99966013 0.99842477 0.99676996 0.995282
 0.9939631  0.99281573 0.9918002  0.9910096 ]
2025-07-28 14:02:50 - DEBUG - 
end of episode 0, step 134, episode_reward -1002.4776874624438, reward -2.2819379753445848

2025-07-28 14:02:50 - DEBUG - critic loss: 1.5299986600875854
2025-07-28 14:02:50 - DEBUG - actor loss: 3.508122205734253
2025-07-28 14:02:50 - DEBUG - Using actor
2025-07-28 14:02:50 - DEBUG - 
start of episode 0, step 135

2025-07-28 14:02:50 - DEBUG - State: [1.         0.99997884 0.99966013 0.99842477 0.99676996 0.995282
 0.9939631  0.99281573 0.9918002  0.9910096 ]
2025-07-28 14:02:50 - DEBUG - Action: [2.7716160e-05 2.3841858e-06 5.9604645e-06 3.0868948e-01 1.7881393e-06
 2.0563602e-05 5.9604645e-05 4.0829182e-05 2.6822090e-06 5.7158985e+00]
2025-07-28 14:02:50 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:50 - DEBUG - Reward: -1.8412295161726924
2025-07-28 14:02:50 - DEBUG - Reward array: [-0.06409586 -0.06293341 -0.06159433 -0.06009229 -0.05844191 -0.05667416
 -0.05510803 -0.05451281 -0.05451281 -1.3132639 ]
2025-07-28 14:02:50 - DEBUG - Next state: [0.9911761  0.9921805  0.99335843 0.9947074  0.9962251  0.9978942
 0.99941266 1.         1.         1.        ]
2025-07-28 14:02:50 - DEBUG - 
end of episode 0, step 135, episode_reward -1004.3189169786165, reward -1.8412295161726924

2025-07-28 14:02:50 - DEBUG - critic loss: 1.4353413581848145
2025-07-28 14:02:50 - DEBUG - actor loss: 3.450071334838867
2025-07-28 14:02:50 - DEBUG - Using actor
2025-07-28 14:02:50 - DEBUG - 
start of episode 0, step 136

2025-07-28 14:02:50 - DEBUG - State: [0.9911761  0.9921805  0.99335843 0.9947074  0.9962251  0.9978942
 0.99941266 1.         1.         1.        ]
2025-07-28 14:02:50 - DEBUG - Action: [2.7418137e-05 2.3841858e-06 5.9604645e-06 3.5854697e-01 1.7881393e-06
 2.0265579e-05 5.8412552e-05 3.9935112e-05 2.6822090e-06 5.6858325e+00]
2025-07-28 14:02:50 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:50 - DEBUG - Reward: -2.1590191273590174
2025-07-28 14:02:50 - DEBUG - Reward array: [-0.05451281 -0.05466291 -0.0570582  -0.06638175 -0.08374233 -0.10372016
 -0.12382456 -0.14253702 -0.15931549 -1.3132639 ]
2025-07-28 14:02:50 - DEBUG - Next state: [1.         0.99985135 0.99752766 0.9892479  0.97628754 0.96406585
 0.95372313 0.9453549  0.9386375  0.9333992 ]
2025-07-28 14:02:50 - DEBUG - 
end of episode 0, step 136, episode_reward -1006.4779361059755, reward -2.1590191273590174

2025-07-28 14:02:50 - DEBUG - critic loss: 1.5685701370239258
2025-07-28 14:02:50 - DEBUG - actor loss: 3.4550974369049072
2025-07-28 14:02:50 - DEBUG - Using actor
2025-07-28 14:02:50 - DEBUG - 
start of episode 0, step 137

2025-07-28 14:02:50 - DEBUG - State: [1.         0.99985135 0.99752766 0.9892479  0.97628754 0.96406585
 0.95372313 0.9453549  0.9386375  0.9333992 ]
2025-07-28 14:02:50 - DEBUG - Action: [3.4570694e-05 2.9802322e-06 7.7486038e-06 4.4934511e-01 2.3841858e-06
 2.6226044e-05 7.3015690e-05 5.0663948e-05 3.5762787e-06 5.8679485e+00]
2025-07-28 14:02:50 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:50 - DEBUG - Reward: -2.2634511073678274
2025-07-28 14:02:50 - DEBUG - Reward array: [-0.17403221 -0.15999257 -0.1418148  -0.12123592 -0.09994309 -0.07951634
 -0.06343219 -0.05570729 -0.05451281 -1.3132639 ]
2025-07-28 14:02:50 - DEBUG - Next state: [0.9332384  0.93837965 0.9456594  0.9549675  0.9662054  0.9792035
 0.9917475  0.9988271  1.         1.        ]
2025-07-28 14:02:50 - DEBUG - 
end of episode 0, step 137, episode_reward -1008.7413872133433, reward -2.2634511073678274

2025-07-28 14:02:50 - DEBUG - critic loss: 0.4204617142677307
2025-07-28 14:02:50 - DEBUG - actor loss: 3.5159926414489746
2025-07-28 14:02:50 - DEBUG - Using actor
2025-07-28 14:02:50 - DEBUG - 
start of episode 0, step 138

2025-07-28 14:02:50 - DEBUG - State: [0.9332384  0.93837965 0.9456594  0.9549675  0.9662054  0.9792035
 0.9917475  0.9988271  1.         1.        ]
2025-07-28 14:02:50 - DEBUG - Action: [3.5762787e-05 3.2782555e-06 8.0466270e-06 5.4815233e-01 2.3841858e-06
 2.7418137e-05 7.5101852e-05 5.2750111e-05 3.8743019e-06 6.1669474e+00]
2025-07-28 14:02:50 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:50 - DEBUG - Reward: -29.818776390806747
2025-07-28 14:02:50 - DEBUG - Reward array: [-0.05451281 -0.07167334 -0.14669597 -0.40305044 -1.20194406 -3.10035059
 -5.59804394 -7.35949172 -7.96301446 -3.91999906]
2025-07-28 14:02:50 - DEBUG - Next state: [1.         0.9850037  0.94362754 0.8785752  0.7948991  0.701076
 0.6185534  0.5620742  0.53974897 0.53686225]
2025-07-28 14:02:50 - DEBUG - 
end of episode 0, step 138, episode_reward -1038.56016360415, reward -29.818776390806747

2025-07-28 14:02:50 - DEBUG - critic loss: 0.6067299246788025
2025-07-28 14:02:50 - DEBUG - actor loss: 3.5914623737335205
2025-07-28 14:02:50 - DEBUG - Using actor
2025-07-28 14:02:50 - DEBUG - 
start of episode 0, step 139

2025-07-28 14:02:50 - DEBUG - State: [1.         0.9850037  0.94362754 0.8785752  0.7948991  0.701076
 0.6185534  0.5620742  0.53974897 0.53686225]
2025-07-28 14:02:50 - DEBUG - Action: [2.6345253e-04 3.6358833e-05 7.6293945e-05 9.8881572e-01 2.8312206e-05
 2.2023916e-04 4.9829483e-04 3.6925077e-04 4.0829182e-05 6.2134356e+00]
2025-07-28 14:02:50 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:50 - DEBUG - Reward: -34.83162219288039
2025-07-28 14:02:50 - DEBUG - Reward array: [-8.03491365 -7.9387962  -7.23413322 -5.36617638 -2.85459831 -1.08073873
 -0.36157962 -0.13434548 -0.06824696 -1.75809363]
2025-07-28 14:02:50 - DEBUG - Next state: [0.53685886 0.54070854 0.56639683 0.6257177  0.71057475 0.8038971
 0.88602406 0.9488911  0.9877183  1.        ]
2025-07-28 14:02:50 - DEBUG - 
end of episode 0, step 139, episode_reward -1073.3917857970303, reward -34.83162219288039

2025-07-28 14:02:51 - DEBUG - critic loss: 1.480832576751709
2025-07-28 14:02:51 - DEBUG - actor loss: 3.6875455379486084
2025-07-28 14:02:51 - DEBUG - Using actor
2025-07-28 14:02:51 - DEBUG - 
start of episode 0, step 140

2025-07-28 14:02:51 - DEBUG - State: [0.53685886 0.54070854 0.56639683 0.6257177  0.71057475 0.8038971
 0.88602406 0.9488911  0.9877183  1.        ]
2025-07-28 14:02:51 - DEBUG - Action: [3.4779310e-04 5.1558018e-05 1.0460615e-04 1.2646089e+00 3.9041042e-05
 2.9623508e-04 6.4462423e-04 4.8905611e-04 5.8114529e-05 6.2188745e+00]
2025-07-28 14:02:51 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:51 - DEBUG - Reward: -2.5748125864681772
2025-07-28 14:02:51 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.10029785 -0.05535654 -0.05726084
 -0.07208969 -0.12154305 -0.24663255 -1.75809364]
2025-07-28 14:02:51 - DEBUG - Next state: [1.         1.         1.         0.99993736 0.9991692  0.99733514
 0.98468184 0.9548186  0.911323   0.8627106 ]
2025-07-28 14:02:51 - DEBUG - 
end of episode 0, step 140, episode_reward -1075.9665983834984, reward -2.5748125864681772

2025-07-28 14:02:51 - DEBUG - critic loss: 17.492164611816406
2025-07-28 14:02:51 - DEBUG - actor loss: 3.881791114807129
2025-07-28 14:02:51 - DEBUG - Using actor
2025-07-28 14:02:51 - DEBUG - 
start of episode 0, step 141

2025-07-28 14:02:51 - DEBUG - State: [1.         1.         1.         0.99993736 0.9991692  0.99733514
 0.98468184 0.9548186  0.911323   0.8627106 ]
2025-07-28 14:02:51 - DEBUG - Action: [3.2484531e-05 2.9802322e-06 7.1525574e-06 1.1206386e+00 2.0861626e-06
 2.5629997e-05 6.8247318e-05 4.7981739e-05 3.5762787e-06 6.3213391e+00]
2025-07-28 14:02:51 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:51 - DEBUG - Reward: -20.23327369897691
2025-07-28 14:02:51 - DEBUG - Reward array: [-1.00802781 -1.55649815 -1.97797036 -0.57562095 -2.35470547 -2.68983398
 -3.07376702 -3.01640314 -2.22234826 -1.75809856]
2025-07-28 14:02:51 - DEBUG - Next state: [0.80967253 0.7719855  0.7492064  0.73941857 0.7314976  0.71720773
 0.7020828  0.7042719  0.7374927  0.79111195]
2025-07-28 14:02:51 - DEBUG - 
end of episode 0, step 141, episode_reward -1096.1998720824754, reward -20.23327369897691

2025-07-28 14:02:51 - DEBUG - critic loss: 32.54009246826172
2025-07-28 14:02:51 - DEBUG - actor loss: 4.2222113609313965
2025-07-28 14:02:51 - DEBUG - Using actor
2025-07-28 14:02:51 - DEBUG - 
start of episode 0, step 142

2025-07-28 14:02:51 - DEBUG - State: [0.80967253 0.7719855  0.7492064  0.73941857 0.7314976  0.71720773
 0.7020828  0.7042719  0.7374927  0.79111195]
2025-07-28 14:02:51 - DEBUG - Action: [3.9428473e-04 6.1094761e-05 1.1861324e-04 1.9496074e+00 4.5299530e-05
 3.3736229e-04 7.1823597e-04 5.4091215e-04 6.7651272e-05 5.6384587e+00]
2025-07-28 14:02:51 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:51 - DEBUG - Reward: -4.3271567336726555
2025-07-28 14:02:51 - DEBUG - Reward array: [-0.52708126 -0.22239587 -0.10554644 -0.10041193 -0.05451281 -0.07246468
 -0.15243216 -0.43338916 -1.3286485  -1.33027392]
2025-07-28 14:02:51 - DEBUG - Next state: [0.859596   0.91793084 0.963056   0.9911024  1.         0.98439336
 0.9413144  0.8735242  0.786198   0.68805575]
2025-07-28 14:02:51 - DEBUG - 
end of episode 0, step 142, episode_reward -1100.527028816148, reward -4.3271567336726555

2025-07-28 14:02:51 - DEBUG - critic loss: 21.61392593383789
2025-07-28 14:02:51 - DEBUG - actor loss: 4.519639015197754
2025-07-28 14:02:51 - DEBUG - Using actor
2025-07-28 14:02:51 - DEBUG - 
start of episode 0, step 143

2025-07-28 14:02:51 - DEBUG - State: [0.859596   0.91793084 0.963056   0.9911024  1.         0.98439336
 0.9413144  0.8735242  0.786198   0.68805575]
2025-07-28 14:02:51 - DEBUG - Action: [7.1525574e-05 8.0466270e-06 1.6987324e-05 2.1190019e+00 5.6624413e-06
 5.6922436e-05 1.4036894e-04 1.0013580e-04 8.9406967e-06 5.0124650e+00]
2025-07-28 14:02:51 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:51 - DEBUG - Reward: -43.49791751375415
2025-07-28 14:02:51 - DEBUG - Reward array: [-6.31390145 -7.91008106 -7.7691581  -3.08732066 -4.88662565 -3.97108595
 -3.46126615 -2.82525991 -1.95993696 -1.31328163]
2025-07-28 14:02:51 - DEBUG - Next state: [0.5963294  0.5418377  0.5472551  0.5895108  0.64064175 0.67021865
 0.6878328  0.7117392  0.7501083  0.80240685]
2025-07-28 14:02:51 - DEBUG - 
end of episode 0, step 143, episode_reward -1144.0249463299021, reward -43.49791751375415

2025-07-28 14:02:51 - DEBUG - critic loss: 27.90056037902832
2025-07-28 14:02:51 - DEBUG - actor loss: 4.7458930015563965
2025-07-28 14:02:51 - DEBUG - Using actor
2025-07-28 14:02:51 - DEBUG - 
start of episode 0, step 144

2025-07-28 14:02:51 - DEBUG - State: [0.5963294  0.5418377  0.5472551  0.5895108  0.64064175 0.67021865
 0.6878328  0.7117392  0.7501083  0.80240685]
2025-07-28 14:02:51 - DEBUG - Action: [1.1691451e-03 2.2888184e-04 3.9607286e-04 3.0901525e+00 1.7166138e-04
 1.0266900e-03 1.9705296e-03 1.5285611e-03 2.4139881e-04 4.6249385e+00]
2025-07-28 14:02:51 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:51 - DEBUG - Reward: -3.0086638337573612
2025-07-28 14:02:51 - DEBUG - Reward array: [-0.55086858 -0.27372725 -0.15476274 -0.57995479 -0.10911149 -0.10819115
 -0.1063445  -0.10438263 -0.10236203 -0.91895868]
2025-07-28 14:02:51 - DEBUG - Next state: [0.8563895  0.9045685  0.94039637 0.95806295 0.9611288  0.9616209
 0.96261966 0.96369773 0.96482706 0.966201  ]
2025-07-28 14:02:51 - DEBUG - 
end of episode 0, step 144, episode_reward -1147.0336101636594, reward -3.0086638337573612

2025-07-28 14:02:51 - DEBUG - critic loss: 1.604987382888794
2025-07-28 14:02:51 - DEBUG - actor loss: 4.591363906860352
2025-07-28 14:02:51 - DEBUG - Using actor
2025-07-28 14:02:51 - DEBUG - 
start of episode 0, step 145

2025-07-28 14:02:51 - DEBUG - State: [0.8563895  0.9045685  0.94039637 0.95806295 0.9611288  0.9616209
 0.96261966 0.96369773 0.96482706 0.966201  ]
2025-07-28 14:02:51 - DEBUG - Action: [5.06639481e-05 5.36441803e-06 1.13248825e-05 3.05788708e+00
 3.57627869e-06 3.99351120e-05 9.98377800e-05 7.06315041e-05
 5.96046448e-06 4.53984833e+00]
2025-07-28 14:02:51 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:51 - DEBUG - Reward: -2.217152530178631
2025-07-28 14:02:51 - DEBUG - Reward array: [-0.0979455  -0.09914047 -0.10202881 -0.57995472 -0.0975226  -0.09128003
 -0.08370556 -0.07544452 -0.07117163 -0.91895868]
2025-07-28 14:02:51 - DEBUG - Next state: [0.9673662  0.9666693  0.96501523 0.9655139  0.96761465 0.97139835
 0.97631234 0.98214734 0.9853938  0.98291534]
2025-07-28 14:02:51 - DEBUG - 
end of episode 0, step 145, episode_reward -1149.2507626938382, reward -2.217152530178631

2025-07-28 14:02:51 - DEBUG - critic loss: 5.061677932739258
2025-07-28 14:02:51 - DEBUG - actor loss: 4.34237813949585
2025-07-28 14:02:51 - DEBUG - Using actor
2025-07-28 14:02:51 - DEBUG - 
start of episode 0, step 146

2025-07-28 14:02:51 - DEBUG - State: [0.9673662  0.9666693  0.96501523 0.9655139  0.96761465 0.97139835
 0.97631234 0.98214734 0.9853938  0.98291534]
2025-07-28 14:02:51 - DEBUG - Action: [3.5762787e-05 3.5762787e-06 7.7486038e-06 3.3697457e+00 2.3841858e-06
 2.8312206e-05 7.2121620e-05 5.0961971e-05 4.1723251e-06 4.9084888e+00]
2025-07-28 14:02:51 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:51 - DEBUG - Reward: -2.3649487811710617
2025-07-28 14:02:51 - DEBUG - Reward array: [-0.08244177 -0.09342397 -0.10551387 -0.5799548  -0.12819537 -0.13059084
 -0.12040812 -0.10880202 -0.09665934 -0.91895868]
2025-07-28 14:02:51 - DEBUG - Next state: [0.97717065 0.9700736  0.9630739  0.9569759  0.95167327 0.9505759
 0.95537037 0.9612939  0.9681248  0.9758374 ]
2025-07-28 14:02:51 - DEBUG - 
end of episode 0, step 146, episode_reward -1151.6157114750092, reward -2.3649487811710617

2025-07-28 14:02:51 - DEBUG - critic loss: 25.67828941345215
2025-07-28 14:02:51 - DEBUG - actor loss: 4.262178897857666
2025-07-28 14:02:51 - DEBUG - Using actor
2025-07-28 14:02:51 - DEBUG - 
start of episode 0, step 147

2025-07-28 14:02:51 - DEBUG - State: [0.97717065 0.9700736  0.9630739  0.9569759  0.95167327 0.9505759
 0.95537037 0.9612939  0.9681248  0.9758374 ]
2025-07-28 14:02:51 - DEBUG - Action: [3.9339066e-05 4.1723251e-06 8.6426735e-06 3.2323365e+00 2.6822090e-06
 3.1590462e-05 7.9572201e-05 5.6624413e-05 4.7683716e-06 5.3601928e+00]
2025-07-28 14:02:51 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:51 - DEBUG - Reward: -2.388824701810339
2025-07-28 14:02:51 - DEBUG - Reward array: [-0.07246909 -0.06148044 -0.05594835 -0.57995462 -0.05847402 -0.05996826
 -0.06130462 -0.06246948 -0.06349192 -1.3132639 ]
2025-07-28 14:02:51 - DEBUG - Next state: [0.98438996 0.99345964 0.99859315 0.9977391  0.99619526 0.9948202
 0.9936163  0.992586   0.9916959  0.99138856]
2025-07-28 14:02:51 - DEBUG - 
end of episode 0, step 147, episode_reward -1154.0045361768196, reward -2.388824701810339

2025-07-28 14:02:51 - DEBUG - critic loss: 5.164439678192139
2025-07-28 14:02:51 - DEBUG - actor loss: 4.270382404327393
2025-07-28 14:02:51 - DEBUG - Using actor
2025-07-28 14:02:51 - DEBUG - 
start of episode 0, step 148

2025-07-28 14:02:51 - DEBUG - State: [0.98438996 0.99345964 0.99859315 0.9977391  0.99619526 0.9948202
 0.9936163  0.992586   0.9916959  0.99138856]
2025-07-28 14:02:51 - DEBUG - Action: [2.8312206e-05 2.6822090e-06 5.9604645e-06 2.6250525e+00 1.7881393e-06
 2.2351742e-05 5.8412552e-05 4.1127205e-05 3.2782555e-06 5.7871761e+00]
2025-07-28 14:02:51 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:51 - DEBUG - Reward: -3.5090074689438686
2025-07-28 14:02:51 - DEBUG - Reward array: [-0.06300237 -0.06188445 -0.06059079 -0.30314539 -0.06727791 -0.10630242
 -0.21846025 -0.46392906 -0.8510844  -1.31333044]
2025-07-28 14:02:51 - DEBUG - Next state: [0.99212044 0.9931013  0.9942564  0.99551487 0.9885082  0.9626426
 0.91906214 0.8687301  0.8233391  0.7833988 ]
2025-07-28 14:02:51 - DEBUG - 
end of episode 0, step 148, episode_reward -1157.5135436457633, reward -3.5090074689438686

2025-07-28 14:02:51 - DEBUG - critic loss: 30.87574005126953
2025-07-28 14:02:51 - DEBUG - actor loss: 4.615643501281738
2025-07-28 14:02:51 - DEBUG - Using actor
2025-07-28 14:02:51 - DEBUG - 
start of episode 0, step 149

2025-07-28 14:02:51 - DEBUG - State: [0.99212044 0.9931013  0.9942564  0.99551487 0.9885082  0.9626426
 0.91906214 0.8687301  0.8233391  0.7833988 ]
2025-07-28 14:02:51 - DEBUG - Action: [5.09619713e-05 5.36441803e-06 1.19209290e-05 2.01612520e+00
 3.87430191e-06 4.02331352e-05 1.01327896e-04 7.24196434e-05
 6.25848770e-06 5.83389044e+00]
2025-07-28 14:02:51 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:51 - DEBUG - Reward: -11.66374460714026
2025-07-28 14:02:51 - DEBUG - Reward array: [-1.97298783 -2.39797217 -2.41762484 -0.39027757 -1.42915361 -0.8976519
 -0.49607425 -0.23716242 -0.11157611 -1.3132639 ]
2025-07-28 14:02:51 - DEBUG - Next state: [0.74945503 0.72958463 0.7287229  0.74528074 0.7797251  0.81909114
 0.86396015 0.91383517 0.95982885 0.9892871 ]
2025-07-28 14:02:51 - DEBUG - 
end of episode 0, step 149, episode_reward -1169.1772882529035, reward -11.66374460714026

2025-07-28 14:02:51 - DEBUG - critic loss: 13.622292518615723
2025-07-28 14:02:51 - DEBUG - actor loss: 5.110279083251953
2025-07-28 14:02:51 - DEBUG - Using actor
2025-07-28 14:02:51 - DEBUG - 
start of episode 0, step 150

2025-07-28 14:02:51 - DEBUG - State: [0.74945503 0.72958463 0.7287229  0.74528074 0.7797251  0.81909114
 0.86396015 0.91383517 0.95982885 0.9892871 ]
2025-07-28 14:02:51 - DEBUG - Action: [1.8894672e-04 2.5033951e-05 5.1856041e-05 1.6600499e+00 1.9073486e-05
 1.5318394e-04 3.4689903e-04 2.5779009e-04 2.8610229e-05 5.5092182e+00]
2025-07-28 14:02:51 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:51 - DEBUG - Reward: -1.906844367263365
2025-07-28 14:02:51 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05461045 -0.10031353 -0.05930108 -0.06287351
 -0.06621602 -0.06926834 -0.07197192 -1.3132639 ]
2025-07-28 14:02:51 - DEBUG - Next state: [1.         1.         0.99990326 0.99854946 0.9954303  0.99223274
 0.9893857  0.9868965  0.9847727  0.982946  ]
2025-07-28 14:02:51 - DEBUG - 
end of episode 0, step 150, episode_reward -1171.0841326201669, reward -1.906844367263365

2025-07-28 14:02:51 - DEBUG - critic loss: 2.7902045249938965
2025-07-28 14:02:51 - DEBUG - actor loss: 5.428560256958008
2025-07-28 14:02:51 - DEBUG - Using actor
2025-07-28 14:02:51 - DEBUG - 
start of episode 0, step 151

2025-07-28 14:02:51 - DEBUG - State: [1.         1.         0.99990326 0.99854946 0.9954303  0.99223274
 0.9893857  0.9868965  0.9847727  0.982946  ]
2025-07-28 14:02:51 - DEBUG - Action: [2.9206276e-05 2.6822090e-06 6.2584877e-06 8.8979214e-01 2.0861626e-06
 2.1457672e-05 5.7816505e-05 4.0531158e-05 2.9802322e-06 5.0564013e+00]
2025-07-28 14:02:51 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:51 - DEBUG - Reward: -2.0195220216214804
2025-07-28 14:02:51 - DEBUG - Reward array: [-0.07520948 -0.07328639 -0.07123332 -0.07166204 -0.07369615 -0.07777504
 -0.08289798 -0.0878984  -0.09259932 -1.3132639 ]
2025-07-28 14:02:51 - DEBUG - Next state: [0.9823216  0.98376584 0.9853457  0.9850125  0.9834553  0.9804455
 0.97685945 0.97354543 0.9705799  0.9683756 ]
2025-07-28 14:02:51 - DEBUG - 
end of episode 0, step 151, episode_reward -1173.1036546417884, reward -2.0195220216214804

2025-07-28 14:02:51 - DEBUG - critic loss: 30.29520034790039
2025-07-28 14:02:51 - DEBUG - actor loss: 5.6861724853515625
2025-07-28 14:02:51 - DEBUG - Using actor
2025-07-28 14:02:51 - DEBUG - 
start of episode 0, step 152

2025-07-28 14:02:52 - DEBUG - State: [0.9823216  0.98376584 0.9853457  0.9850125  0.9834553  0.9804455
 0.97685945 0.97354543 0.9705799  0.9683756 ]
2025-07-28 14:02:52 - DEBUG - Action: [3.4868717e-05 2.9802322e-06 7.7486038e-06 6.2814325e-01 2.6822090e-06
 2.4735928e-05 6.6757202e-05 4.6491623e-05 3.5762787e-06 4.4834442e+00]
2025-07-28 14:02:52 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:52 - DEBUG - Reward: -1.6475207950392854
2025-07-28 14:02:52 - DEBUG - Reward array: [-0.09740502 -0.09852539 -0.09741719 -0.09222738 -0.08473394 -0.07558091
 -0.06641165 -0.06019459 -0.05606603 -0.91895868]
2025-07-28 14:02:52 - DEBUG - Next state: [0.9676839  0.96702707 0.96767676 0.9708096  0.9756224  0.9820465
 0.9892231  0.9946146  0.9984793  1.        ]
2025-07-28 14:02:52 - DEBUG - 
end of episode 0, step 152, episode_reward -1174.7511754368277, reward -1.6475207950392854

2025-07-28 14:02:52 - DEBUG - critic loss: 20.70441436767578
2025-07-28 14:02:52 - DEBUG - actor loss: 5.638255596160889
2025-07-28 14:02:52 - DEBUG - Using actor
2025-07-28 14:02:52 - DEBUG - 
start of episode 0, step 153

2025-07-28 14:02:52 - DEBUG - State: [0.9676839  0.96702707 0.96767676 0.9708096  0.9756224  0.9820465
 0.9892231  0.9946146  0.9984793  1.        ]
2025-07-28 14:02:52 - DEBUG - Action: [3.5166740e-05 2.9802322e-06 7.7486038e-06 4.4068009e-01 2.6822090e-06
 2.4139881e-05 6.6161156e-05 4.5895576e-05 3.5762787e-06 3.9921556e+00]
2025-07-28 14:02:52 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:52 - DEBUG - Reward: -1.0706621704668935
2025-07-28 14:02:52 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05460509 -0.57995462]
2025-07-28 14:02:52 - DEBUG - Next state: [1.         1.         1.         1.         1.         1.
 1.         1.         0.99990857 0.99858785]
2025-07-28 14:02:52 - DEBUG - 
end of episode 0, step 153, episode_reward -1175.8218376072946, reward -1.0706621704668935

2025-07-28 14:02:52 - DEBUG - critic loss: 37.31737518310547
2025-07-28 14:02:52 - DEBUG - actor loss: 5.600050926208496
2025-07-28 14:02:52 - DEBUG - Using actor
2025-07-28 14:02:52 - DEBUG - 
start of episode 0, step 154

2025-07-28 14:02:52 - DEBUG - State: [1.         1.         1.         1.         1.         1.
 1.         1.         0.99990857 0.99858785]
2025-07-28 14:02:52 - DEBUG - Action: [2.8312206e-05 2.3841858e-06 6.2584877e-06 2.9241741e-01 2.3841858e-06
 1.9073486e-05 5.3644180e-05 3.6656857e-05 2.6822090e-06 3.7729387e+00]
2025-07-28 14:02:52 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:52 - DEBUG - Reward: -1.217205036987641
2025-07-28 14:02:52 - DEBUG - Reward array: [-0.05871482 -0.06290322 -0.06709292 -0.07071841 -0.07365166 -0.0759733
 -0.07690555 -0.07650642 -0.0747841  -0.57995464]
2025-07-28 14:02:52 - DEBUG - Next state: [0.9959715  0.9922068  0.9886602  0.98574835 0.9834889  0.98175716
 0.98107505 0.98136616 0.9826382  0.98418033]
2025-07-28 14:02:52 - DEBUG - 
end of episode 0, step 154, episode_reward -1177.0390426442823, reward -1.217205036987641

2025-07-28 14:02:52 - DEBUG - critic loss: 41.02302932739258
2025-07-28 14:02:52 - DEBUG - actor loss: 5.561054229736328
2025-07-28 14:02:52 - DEBUG - Using actor
2025-07-28 14:02:52 - DEBUG - 
start of episode 0, step 155

2025-07-28 14:02:52 - DEBUG - State: [0.9959715  0.9922068  0.9886602  0.98574835 0.9834889  0.98175716
 0.98107505 0.98136616 0.9826382  0.98418033]
2025-07-28 14:02:52 - DEBUG - Action: [3.3080578e-05 2.6822090e-06 7.1525574e-06 2.1282434e-01 2.6822090e-06
 2.2053719e-05 6.1392784e-05 4.2319298e-05 3.2782555e-06 3.8248129e+00]
2025-07-28 14:02:52 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:52 - DEBUG - Reward: -1.1548657931413104
2025-07-28 14:02:52 - DEBUG - Reward array: [-0.0705351  -0.06818092 -0.06568584 -0.06400301 -0.06319523 -0.06244019
 -0.06147005 -0.06034001 -0.05906082 -0.57995462]
2025-07-28 14:02:52 - DEBUG - Next state: [0.98589236 0.9877718  0.9898285  0.99125576 0.99195284 0.9926117
 0.9934689  0.9944829  0.9956515  0.9969728 ]
2025-07-28 14:02:52 - DEBUG - 
end of episode 0, step 155, episode_reward -1178.1939084374235, reward -1.1548657931413104

2025-07-28 14:02:52 - DEBUG - critic loss: 30.12993621826172
2025-07-28 14:02:52 - DEBUG - actor loss: 5.548032283782959
2025-07-28 14:02:52 - DEBUG - Using actor
2025-07-28 14:02:52 - DEBUG - 
start of episode 0, step 156

2025-07-28 14:02:52 - DEBUG - State: [0.98589236 0.9877718  0.9898285  0.99125576 0.99195284 0.9926117
 0.9934689  0.9944829  0.9956515  0.9969728 ]
2025-07-28 14:02:52 - DEBUG - Action: [3.0994415e-05 2.3841858e-06 6.8545341e-06 1.4692992e-01 2.6822090e-06
 2.0265579e-05 5.7816505e-05 3.9637089e-05 2.9802322e-06 4.0658512e+00]
2025-07-28 14:02:52 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:52 - DEBUG - Reward: -1.4115180743394524
2025-07-28 14:02:52 - DEBUG - Reward array: [-0.0561209  -0.05484884 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -0.91895868]
2025-07-28 14:02:52 - DEBUG - Next state: [0.99842626 0.9996677  1.         1.         1.         1.
 1.         1.         1.         1.        ]
2025-07-28 14:02:52 - DEBUG - 
end of episode 0, step 156, episode_reward -1179.605426511763, reward -1.4115180743394524

2025-07-28 14:02:52 - DEBUG - critic loss: 4.507509231567383
2025-07-28 14:02:52 - DEBUG - actor loss: 5.296926498413086
2025-07-28 14:02:52 - DEBUG - Using actor
2025-07-28 14:02:52 - DEBUG - 
start of episode 0, step 157

2025-07-28 14:02:52 - DEBUG - State: [0.99842626 0.9996677  1.         1.         1.         1.
 1.         1.         1.         1.        ]
2025-07-28 14:02:52 - DEBUG - Action: [2.8312206e-05 2.0861626e-06 6.2584877e-06 1.0152489e-01 2.3841858e-06
 1.8179417e-05 5.2750111e-05 3.6060810e-05 2.6822090e-06 4.3716450e+00]
2025-07-28 14:02:52 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:52 - DEBUG - Reward: -1.4095739456167424
2025-07-28 14:02:52 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -0.91895868]
2025-07-28 14:02:52 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:52 - DEBUG - 
end of episode 0, step 157, episode_reward -1181.0150004573798, reward -1.4095739456167424

2025-07-28 14:02:52 - DEBUG - critic loss: 12.424309730529785
2025-07-28 14:02:52 - DEBUG - actor loss: 5.026981830596924
2025-07-28 14:02:52 - DEBUG - Using actor
2025-07-28 14:02:52 - DEBUG - 
start of episode 0, step 158

2025-07-28 14:02:52 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:52 - DEBUG - Action: [2.8014183e-05 2.0861626e-06 6.2584877e-06 7.3617697e-02 2.3841858e-06
 1.8179417e-05 5.2452087e-05 3.5762787e-05 2.6822090e-06 4.7204452e+00]
2025-07-28 14:02:52 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:52 - DEBUG - Reward: -1.4095739456167424
2025-07-28 14:02:52 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -0.91895868]
2025-07-28 14:02:52 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:52 - DEBUG - 
end of episode 0, step 158, episode_reward -1182.4245744029965, reward -1.4095739456167424

2025-07-28 14:02:52 - DEBUG - critic loss: 40.54142761230469
2025-07-28 14:02:52 - DEBUG - actor loss: 5.0581464767456055
2025-07-28 14:02:52 - DEBUG - Using actor
2025-07-28 14:02:52 - DEBUG - 
start of episode 0, step 159

2025-07-28 14:02:52 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:52 - DEBUG - Action: [2.7716160e-05 2.0861626e-06 6.2584877e-06 5.4602027e-02 2.3841858e-06
 1.7881393e-05 5.2154064e-05 3.5464764e-05 2.6822090e-06 5.0370383e+00]
2025-07-28 14:02:52 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:52 - DEBUG - Reward: -1.8039136255126254
2025-07-28 14:02:52 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05454727 -1.3132639 ]
2025-07-28 14:02:52 - DEBUG - Next state: [1.         1.         1.         1.         1.         1.
 1.         1.         0.99996585 0.9994476 ]
2025-07-28 14:02:52 - DEBUG - 
end of episode 0, step 159, episode_reward -1184.2284880285092, reward -1.8039136255126254

2025-07-28 14:02:52 - DEBUG - critic loss: 39.52059555053711
2025-07-28 14:02:52 - DEBUG - actor loss: 5.278461933135986
2025-07-28 14:02:52 - DEBUG - Using actor
2025-07-28 14:02:52 - DEBUG - 
start of episode 0, step 160

2025-07-28 14:02:52 - DEBUG - State: [1.         1.         1.         1.         1.         1.
 1.         1.         0.99996585 0.9994476 ]
2025-07-28 14:02:52 - DEBUG - Action: [2.7716160e-05 2.0861626e-06 6.2584877e-06 4.1185319e-02 2.3841858e-06
 1.7583370e-05 5.1856041e-05 3.5166740e-05 2.6822090e-06 5.3678808e+00]
2025-07-28 14:02:52 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:52 - DEBUG - Reward: -1.9881785907604417
2025-07-28 14:02:52 - DEBUG - Reward array: [-0.05729473 -0.06188937 -0.0683801  -0.07468292 -0.07920599 -0.08175421
 -0.08330137 -0.08414415 -0.08426184 -1.3132639 ]
2025-07-28 14:02:52 - DEBUG - Next state: [0.997303   0.9930969  0.9876106  0.98271376 0.9794231  0.97764254
 0.97658557 0.9760172  0.9759382  0.9765237 ]
2025-07-28 14:02:52 - DEBUG - 
end of episode 0, step 160, episode_reward -1186.2166666192697, reward -1.9881785907604417

2025-07-28 14:02:52 - DEBUG - critic loss: 16.68244743347168
2025-07-28 14:02:52 - DEBUG - actor loss: 5.432347774505615
2025-07-28 14:02:52 - DEBUG - Using actor
2025-07-28 14:02:52 - DEBUG - 
start of episode 0, step 161

2025-07-28 14:02:52 - DEBUG - State: [0.997303   0.9930969  0.9876106  0.98271376 0.9794231  0.97764254
 0.97658557 0.9760172  0.9759382  0.9765237 ]
2025-07-28 14:02:52 - DEBUG - Action: [3.2782555e-05 2.3841858e-06 7.4505806e-06 3.4367442e-02 2.9802322e-06
 2.0861626e-05 6.1094761e-05 4.1425228e-05 3.2782555e-06 5.6250663e+00]
2025-07-28 14:02:52 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:52 - DEBUG - Reward: -1.8889467337259842
2025-07-28 14:02:52 - DEBUG - Reward array: [-0.08157797 -0.0778755  -0.07210001 -0.06522033 -0.0593746  -0.05585817
 -0.05465063 -0.05451281 -0.05451281 -1.3132639 ]
2025-07-28 14:02:52 - DEBUG - Next state: [0.97776407 0.9803732  0.98467386 0.99022    0.99536276 0.9986806
 0.9998635  1.         1.         1.        ]
2025-07-28 14:02:52 - DEBUG - 
end of episode 0, step 161, episode_reward -1188.1056133529958, reward -1.8889467337259842

2025-07-28 14:02:52 - DEBUG - critic loss: 17.276660919189453
2025-07-28 14:02:52 - DEBUG - actor loss: 5.384481906890869
2025-07-28 14:02:52 - DEBUG - Using actor
2025-07-28 14:02:52 - DEBUG - 
start of episode 0, step 162

2025-07-28 14:02:52 - DEBUG - State: [0.97776407 0.9803732  0.98467386 0.99022    0.99536276 0.9986806
 0.9998635  1.         1.         1.        ]
2025-07-28 14:02:52 - DEBUG - Action: [2.9802322e-05 2.0861626e-06 6.8545341e-06 2.6169717e-02 2.6822090e-06
 1.8775463e-05 5.5432320e-05 3.7252903e-05 2.6822090e-06 5.6784415e+00]
2025-07-28 14:02:52 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:52 - DEBUG - Reward: -1.8039026932659321
2025-07-28 14:02:52 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05453634 -1.3132639 ]
2025-07-28 14:02:52 - DEBUG - Next state: [1.         1.         1.         1.         1.         1.
 1.         1.         0.9999767  0.99962443]
2025-07-28 14:02:52 - DEBUG - 
end of episode 0, step 162, episode_reward -1189.9095160462616, reward -1.8039026932659321

2025-07-28 14:02:52 - DEBUG - critic loss: 39.16152572631836
2025-07-28 14:02:52 - DEBUG - actor loss: 5.37460994720459
2025-07-28 14:02:52 - DEBUG - Using actor
2025-07-28 14:02:52 - DEBUG - 
start of episode 0, step 163

2025-07-28 14:02:52 - DEBUG - State: [1.         1.         1.         1.         1.         1.
 1.         1.         0.9999767  0.99962443]
2025-07-28 14:02:52 - DEBUG - Action: [2.7120113e-05 1.7881393e-06 6.2584877e-06 2.0506084e-02 2.3841858e-06
 1.6689301e-05 5.0663948e-05 3.3676624e-05 2.3841858e-06 5.5106444e+00]
2025-07-28 14:02:52 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:52 - DEBUG - Reward: -2.841691695708147
2025-07-28 14:02:52 - DEBUG - Reward array: [-0.05640501 -0.05958263 -0.0640884  -0.06846177 -0.08302923 -0.12225865
 -0.20033848 -0.33554443 -0.53871685 -1.31326626]
2025-07-28 14:02:52 - DEBUG - Next state: [0.9981525  0.9951721  0.9911825  0.9875446  0.9767702  0.9544731
 0.92451084 0.89107835 0.858013   0.8296221 ]
2025-07-28 14:02:52 - DEBUG - 
end of episode 0, step 163, episode_reward -1192.7512077419697, reward -2.841691695708147

2025-07-28 14:02:52 - DEBUG - critic loss: 29.451719284057617
2025-07-28 14:02:52 - DEBUG - actor loss: 5.329535007476807
2025-07-28 14:02:52 - DEBUG - Using actor
2025-07-28 14:02:52 - DEBUG - 
start of episode 0, step 164

2025-07-28 14:02:52 - DEBUG - State: [0.9981525  0.9951721  0.9911825  0.9875446  0.9767702  0.9544731
 0.92451084 0.89107835 0.858013   0.8296221 ]
2025-07-28 14:02:52 - DEBUG - Action: [4.8577785e-05 3.5762787e-06 1.1622906e-05 2.3090839e-02 4.7683716e-06
 3.0398369e-05 8.7022781e-05 5.8710575e-05 4.7683716e-06 4.9802165e+00]
2025-07-28 14:02:52 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:52 - DEBUG - Reward: -5.978774752042392
2025-07-28 14:02:52 - DEBUG - Reward array: [-0.93382741 -0.79468178 -0.57339177 -0.42521604 -0.35520833 -0.36845679
 -0.46042964 -0.56701106 -0.58159067 -0.91896126]
2025-07-28 14:02:52 - DEBUG - Next state: [0.8159092  0.82873774 0.85345685 0.874855   0.8872317  0.88474053
 0.86926585 0.8542779  0.8524127  0.86613125]
2025-07-28 14:02:52 - DEBUG - 
end of episode 0, step 164, episode_reward -1198.7299824940121, reward -5.978774752042392

2025-07-28 14:02:53 - DEBUG - critic loss: 25.39643669128418
2025-07-28 14:02:53 - DEBUG - actor loss: 5.085048198699951
2025-07-28 14:02:53 - DEBUG - Using actor
2025-07-28 14:02:53 - DEBUG - 
start of episode 0, step 165

2025-07-28 14:02:53 - DEBUG - State: [0.8159092  0.82873774 0.85345685 0.874855   0.8872317  0.88474053
 0.86926585 0.8542779  0.8524127  0.86613125]
2025-07-28 14:02:53 - DEBUG - Action: [1.3023615e-04 1.2218952e-05 3.4868717e-05 3.2905340e-02 1.5795231e-05
 8.4042549e-05 2.2023916e-04 1.5318394e-04 1.4901161e-05 4.4507365e+00]
2025-07-28 14:02:53 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:53 - DEBUG - Reward: -2.059463167351133
2025-07-28 14:02:53 - DEBUG - Reward array: [-0.34070325 -0.21968793 -0.13629874 -0.0927973  -0.07624479 -0.07043009
 -0.06808835 -0.06744116 -0.06881287 -0.91895868]
2025-07-28 14:02:53 - DEBUG - Next state: [0.890051   0.9187074  0.948031   0.970458   0.9815577  0.98597497
 0.9878469  0.9883745  0.98726165 0.9852251 ]
2025-07-28 14:02:53 - DEBUG - 
end of episode 0, step 165, episode_reward -1200.7894456613633, reward -2.059463167351133

2025-07-28 14:02:53 - DEBUG - critic loss: 39.12529754638672
2025-07-28 14:02:53 - DEBUG - actor loss: 5.0157060623168945
2025-07-28 14:02:53 - DEBUG - Using actor
2025-07-28 14:02:53 - DEBUG - 
start of episode 0, step 166

2025-07-28 14:02:53 - DEBUG - State: [0.890051   0.9187074  0.948031   0.970458   0.9815577  0.98597497
 0.9878469  0.9883745  0.98726165 0.9852251 ]
2025-07-28 14:02:53 - DEBUG - Action: [4.2617321e-05 2.9802322e-06 9.8347664e-06 1.6402304e-02 4.1723251e-06
 2.5331974e-05 7.4207783e-05 4.9471855e-05 3.8743019e-06 3.8609040e+00]
2025-07-28 14:02:53 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:53 - DEBUG - Reward: -1.1337283517782168
2025-07-28 14:02:53 - DEBUG - Reward array: [-0.07132979 -0.0687423  -0.06613691 -0.06352278 -0.06092118 -0.05833213
 -0.05576303 -0.05451281 -0.05451281 -0.57995462]
2025-07-28 14:02:53 - DEBUG - Next state: [0.98527056 0.9873184  0.9894516  0.99166924 0.99395925 0.99632746
 0.9987729  1.         1.         1.        ]
2025-07-28 14:02:53 - DEBUG - 
end of episode 0, step 166, episode_reward -1201.9231740131415, reward -1.1337283517782168

2025-07-28 14:02:53 - DEBUG - critic loss: 12.891195297241211
2025-07-28 14:02:53 - DEBUG - actor loss: 4.886662006378174
2025-07-28 14:02:53 - DEBUG - Using actor
2025-07-28 14:02:53 - DEBUG - 
start of episode 0, step 167

2025-07-28 14:02:53 - DEBUG - State: [0.98527056 0.9873184  0.9894516  0.99166924 0.99395925 0.99632746
 0.9987729  1.         1.         1.        ]
2025-07-28 14:02:53 - DEBUG - Action: [3.0100346e-05 2.0861626e-06 6.5565109e-06 1.2017190e-02 2.9802322e-06
 1.6987324e-05 5.2452087e-05 3.4272671e-05 2.3841858e-06 3.3883777e+00]
2025-07-28 14:02:53 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:53 - DEBUG - Reward: -1.1716460626748233
2025-07-28 14:02:53 - DEBUG - Reward array: [-0.0545292  -0.05477643 -0.05583847 -0.0586657  -0.06369768 -0.06983528
 -0.07508775 -0.07850115 -0.08075975 -0.57995466]
2025-07-28 14:02:53 - DEBUG - Next state: [0.9999837  0.99973917 0.9986997  0.9960171  0.9915183  0.98644507
 0.98241204 0.9799246  0.97833145 0.9769199 ]
2025-07-28 14:02:53 - DEBUG - 
end of episode 0, step 167, episode_reward -1203.0948200758164, reward -1.1716460626748233

2025-07-28 14:02:53 - DEBUG - critic loss: 17.320322036743164
2025-07-28 14:02:53 - DEBUG - actor loss: 4.833596706390381
2025-07-28 14:02:53 - DEBUG - Using actor
2025-07-28 14:02:53 - DEBUG - 
start of episode 0, step 168

2025-07-28 14:02:53 - DEBUG - State: [0.9999837  0.99973917 0.9986997  0.9960171  0.9915183  0.98644507
 0.98241204 0.9799246  0.97833145 0.9769199 ]
2025-07-28 14:02:53 - DEBUG - Action: [3.1292439e-05 2.0861626e-06 6.8545341e-06 1.0714531e-02 2.9802322e-06
 1.7583370e-05 5.4240227e-05 3.5464764e-05 2.3841858e-06 3.2498045e+00]
2025-07-28 14:02:53 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:53 - DEBUG - Reward: -1.24327836151422
2025-07-28 14:02:53 - DEBUG - Reward array: [-0.08470591 -0.08572856 -0.08537181 -0.08257552 -0.07742774 -0.07058087
 -0.0635343  -0.05811886 -0.05528018 -0.57995462]
2025-07-28 14:02:53 - DEBUG - Next state: [0.97564113 0.97496223 0.97519827 0.9770793  0.9806962  0.98585635
 0.9916593  0.9965267  0.99924386 1.        ]
2025-07-28 14:02:53 - DEBUG - 
end of episode 0, step 168, episode_reward -1204.3380984373307, reward -1.24327836151422

2025-07-28 14:02:53 - DEBUG - critic loss: 5.634838104248047
2025-07-28 14:02:53 - DEBUG - actor loss: 4.683958530426025
2025-07-28 14:02:53 - DEBUG - Using actor
2025-07-28 14:02:53 - DEBUG - 
start of episode 0, step 169

2025-07-28 14:02:53 - DEBUG - State: [0.97564113 0.97496223 0.97519827 0.9770793  0.9806962  0.98585635
 0.9916593  0.9965267  0.99924386 1.        ]
2025-07-28 14:02:53 - DEBUG - Action: [3.3080578e-05 2.0861626e-06 7.4505806e-06 9.5859170e-03 3.2782555e-06
 1.8775463e-05 5.7518482e-05 3.7550926e-05 2.6822090e-06 3.4347959e+00]
2025-07-28 14:02:53 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:53 - DEBUG - Reward: -1.0705698838811852
2025-07-28 14:02:53 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -0.57995462]
2025-07-28 14:02:53 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:53 - DEBUG - 
end of episode 0, step 169, episode_reward -1205.408668321212, reward -1.0705698838811852

2025-07-28 14:02:53 - DEBUG - critic loss: 30.339744567871094
2025-07-28 14:02:53 - DEBUG - actor loss: 4.64041805267334
2025-07-28 14:02:53 - DEBUG - Using actor
2025-07-28 14:02:53 - DEBUG - 
start of episode 0, step 170

2025-07-28 14:02:53 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:53 - DEBUG - Action: [2.8014183e-05 1.7881393e-06 6.2584877e-06 7.5614452e-03 2.6822090e-06
 1.5795231e-05 4.9173832e-05 3.1888485e-05 2.0861626e-06 3.7214704e+00]
2025-07-28 14:02:53 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:53 - DEBUG - Reward: -1.2698838275765838
2025-07-28 14:02:53 - DEBUG - Reward array: [-0.05451281 -0.05487641 -0.05875857 -0.06653237 -0.07585652 -0.08540082
 -0.0940963  -0.09952369 -0.10037165 -0.57995469]
2025-07-28 14:02:53 - DEBUG - Next state: [1.         0.9996405  0.99593097 0.989123   0.9818431  0.975179
 0.96966374 0.9664474  0.9659591  0.9694902 ]
2025-07-28 14:02:53 - DEBUG - 
end of episode 0, step 170, episode_reward -1206.6785521487886, reward -1.2698838275765838

2025-07-28 14:02:53 - DEBUG - critic loss: 49.61921691894531
2025-07-28 14:02:53 - DEBUG - actor loss: 5.006269454956055
2025-07-28 14:02:53 - DEBUG - Using actor
2025-07-28 14:02:53 - DEBUG - 
start of episode 0, step 171

2025-07-28 14:02:53 - DEBUG - State: [1.         0.9996405  0.99593097 0.989123   0.9818431  0.975179
 0.96966374 0.9664474  0.9659591  0.9694902 ]
2025-07-28 14:02:53 - DEBUG - Action: [3.3676624e-05 2.0861626e-06 7.7486038e-06 7.3704123e-03 3.2782555e-06
 1.9073486e-05 5.9008598e-05 3.8146973e-05 2.6822090e-06 3.9548192e+00]
2025-07-28 14:02:53 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:53 - DEBUG - Reward: -1.2518096892205834
2025-07-28 14:02:53 - DEBUG - Reward array: [-0.08583763 -0.07975242 -0.07662769 -0.07521911 -0.07365472 -0.07133426
 -0.06996967 -0.06961762 -0.06984193 -0.57995464]
2025-07-28 14:02:53 - DEBUG - Next state: [0.9748903  0.979037   0.9812776  0.98231447 0.98348665 0.9852671
 0.98633856 0.98661804 0.9864398  0.9862992 ]
2025-07-28 14:02:53 - DEBUG - 
end of episode 0, step 171, episode_reward -1207.9303618380093, reward -1.2518096892205834

2025-07-28 14:02:53 - DEBUG - critic loss: 17.282352447509766
2025-07-28 14:02:53 - DEBUG - actor loss: 5.132987976074219
2025-07-28 14:02:53 - DEBUG - Using actor
2025-07-28 14:02:53 - DEBUG - 
start of episode 0, step 172

2025-07-28 14:02:53 - DEBUG - State: [0.9748903  0.979037   0.9812776  0.98231447 0.98348665 0.9852671
 0.98633856 0.98661804 0.9864398  0.9862992 ]
2025-07-28 14:02:53 - DEBUG - Action: [3.3676624e-05 2.0861626e-06 7.7486038e-06 6.6730380e-03 3.2782555e-06
 1.9073486e-05 5.9008598e-05 3.8146973e-05 2.6822090e-06 3.8225603e+00]
2025-07-28 14:02:53 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:53 - DEBUG - Reward: -1.2068819464421985
2025-07-28 14:02:53 - DEBUG - Reward array: [-0.07031133 -0.07086619 -0.071229   -0.07134939 -0.07207503 -0.07168647
 -0.06987171 -0.06675192 -0.06278627 -0.57995463]
2025-07-28 14:02:53 - DEBUG - Next state: [0.98606855 0.98563254 0.98534906 0.9852553  0.9846931  0.9849935
 0.98641616 0.9889413  0.99230886 0.9954406 ]
2025-07-28 14:02:53 - DEBUG - 
end of episode 0, step 172, episode_reward -1209.1372437844516, reward -1.2068819464421985

2025-07-28 14:02:53 - DEBUG - critic loss: 20.870452880859375
2025-07-28 14:02:53 - DEBUG - actor loss: 5.061311721801758
2025-07-28 14:02:53 - DEBUG - Using actor
2025-07-28 14:02:53 - DEBUG - 
start of episode 0, step 173

2025-07-28 14:02:53 - DEBUG - State: [0.98606855 0.98563254 0.98534906 0.9852553  0.9846931  0.9849935
 0.98641616 0.9889413  0.99230886 0.9954406 ]
2025-07-28 14:02:53 - DEBUG - Action: [3.2186508e-05 2.0861626e-06 7.1525574e-06 6.0179830e-03 3.2782555e-06
 1.7881393e-05 5.5432320e-05 3.5762787e-05 2.6822090e-06 3.3579545e+00]
2025-07-28 14:02:53 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:53 - DEBUG - Reward: -1.0735457611065087
2025-07-28 14:02:53 - DEBUG - Reward array: [-0.05696743 -0.05503406 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -0.57995462]
2025-07-28 14:02:53 - DEBUG - Next state: [0.9976141 0.9994854 1.        1.        1.        1.        1.
 1.        1.        1.       ]
2025-07-28 14:02:53 - DEBUG - 
end of episode 0, step 173, episode_reward -1210.210789545558, reward -1.0735457611065087

2025-07-28 14:02:53 - DEBUG - critic loss: 16.206275939941406
2025-07-28 14:02:53 - DEBUG - actor loss: 4.712985038757324
2025-07-28 14:02:53 - DEBUG - Using actor
2025-07-28 14:02:53 - DEBUG - 
start of episode 0, step 174

2025-07-28 14:02:53 - DEBUG - State: [0.9976141 0.9994854 1.        1.        1.        1.        1.
 1.        1.        1.       ]
2025-07-28 14:02:53 - DEBUG - Action: [2.8014183e-05 1.7881393e-06 6.2584877e-06 5.2183867e-03 2.9802322e-06
 1.5199184e-05 4.8279762e-05 3.0696392e-05 2.0861626e-06 2.8366408e+00]
2025-07-28 14:02:53 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:53 - DEBUG - Reward: -0.8282329004285656
2025-07-28 14:02:53 - DEBUG - Reward array: [-0.05457146 -0.05518266 -0.056242   -0.05749383 -0.05863409 -0.05965425
 -0.06054627 -0.06131171 -0.06145103 -0.30314559]
2025-07-28 14:02:53 - DEBUG - Next state: [0.9999419  0.99933946 0.99830943 0.99711454 0.9960464  0.9951066
 0.99429655 0.99360996 0.9934858  0.993817  ]
2025-07-28 14:02:53 - DEBUG - 
end of episode 0, step 174, episode_reward -1211.0390224459866, reward -0.8282329004285656

2025-07-28 14:02:53 - DEBUG - critic loss: 2.460155487060547
2025-07-28 14:02:53 - DEBUG - actor loss: 4.109229564666748
2025-07-28 14:02:53 - DEBUG - Using actor
2025-07-28 14:02:53 - DEBUG - 
start of episode 0, step 175

2025-07-28 14:02:53 - DEBUG - State: [0.9999419  0.99933946 0.99830943 0.99711454 0.9960464  0.9951066
 0.99429655 0.99360996 0.9934858  0.993817  ]
2025-07-28 14:02:53 - DEBUG - Action: [2.8908253e-05 1.7881393e-06 6.2584877e-06 4.9492717e-03 2.9802322e-06
 1.5497208e-05 4.9471855e-05 3.1292439e-05 2.0861626e-06 2.6177263e+00]
2025-07-28 14:02:53 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:53 - DEBUG - Reward: -0.8114766494389571
2025-07-28 14:02:53 - DEBUG - Reward array: [-0.06019094 -0.05920694 -0.05809978 -0.05687787 -0.05560327 -0.0548145
 -0.05451281 -0.05451281 -0.05451281 -0.30314493]
2025-07-28 14:02:53 - DEBUG - Next state: [0.9946179  0.99551684 0.9965446  0.9976995  0.99892837 0.9997016
 1.         1.         1.         1.        ]
2025-07-28 14:02:53 - DEBUG - 
end of episode 0, step 175, episode_reward -1211.8504990954254, reward -0.8114766494389571

2025-07-28 14:02:53 - DEBUG - critic loss: 6.069595813751221
2025-07-28 14:02:53 - DEBUG - actor loss: 3.6751253604888916
2025-07-28 14:02:53 - DEBUG - Using actor
2025-07-28 14:02:53 - DEBUG - 
start of episode 0, step 176

2025-07-28 14:02:53 - DEBUG - State: [0.9946179  0.99551684 0.9965446  0.9976995  0.99892837 0.9997016
 1.         1.         1.         1.        ]
2025-07-28 14:02:53 - DEBUG - Action: [2.8610229e-05 1.7881393e-06 6.2584877e-06 4.4912100e-03 2.9802322e-06
 1.5199184e-05 4.8875809e-05 3.0696392e-05 2.0861626e-06 2.6785440e+00]
2025-07-28 14:02:53 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:53 - DEBUG - Reward: -0.9917198552110857
2025-07-28 14:02:53 - DEBUG - Reward array: [-0.05452992 -0.05485734 -0.05638947 -0.06072871 -0.07021336 -0.08322121
 -0.09503445 -0.10365758 -0.10992911 -0.30315871]
2025-07-28 14:02:53 - DEBUG - Next state: [0.999983   0.99965936 0.9981674  0.99413216 0.98614585 0.9766399
 0.9690961  0.9641007  0.9606947  0.95782346]
2025-07-28 14:02:53 - DEBUG - 
end of episode 0, step 176, episode_reward -1212.8422189506366, reward -0.9917198552110857

2025-07-28 14:02:53 - DEBUG - critic loss: 57.32224655151367
2025-07-28 14:02:53 - DEBUG - actor loss: 4.0012736320495605
2025-07-28 14:02:53 - DEBUG - Using actor
2025-07-28 14:02:53 - DEBUG - 
start of episode 0, step 177

2025-07-28 14:02:53 - DEBUG - State: [0.999983   0.99965936 0.9981674  0.99413216 0.98614585 0.9766399
 0.9690961  0.9641007  0.9606947  0.95782346]
2025-07-28 14:02:53 - DEBUG - Action: [3.3974648e-05 2.0861626e-06 7.4505806e-06 4.5552850e-03 3.5762787e-06
 1.8179417e-05 5.7816505e-05 3.6656857e-05 2.6822090e-06 2.8712044e+00]
2025-07-28 14:02:53 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:53 - DEBUG - Reward: -1.1555835597658866
2025-07-28 14:02:53 - DEBUG - Reward array: [-0.12156406 -0.12293654 -0.11957681 -0.11207714 -0.10000669 -0.08521836
 -0.07098714 -0.06141882 -0.05865244 -0.30314554]
2025-07-28 14:02:53 - DEBUG - Next state: [0.9548085  0.95414734 0.95577747 0.95956767 0.9661688  0.9753
 0.9855379  0.9935145  0.9960294  0.9942445 ]
2025-07-28 14:02:53 - DEBUG - 
end of episode 0, step 177, episode_reward -1213.9978025104024, reward -1.1555835597658866

2025-07-28 14:02:54 - DEBUG - critic loss: 4.847624778747559
2025-07-28 14:02:54 - DEBUG - actor loss: 4.354471683502197
2025-07-28 14:02:54 - DEBUG - Using actor
2025-07-28 14:02:54 - DEBUG - 
start of episode 0, step 178

2025-07-28 14:02:54 - DEBUG - State: [0.9548085  0.95414734 0.95577747 0.95956767 0.9661688  0.9753
 0.9855379  0.9935145  0.9960294  0.9942445 ]
2025-07-28 14:02:54 - DEBUG - Action: [3.8146973e-05 2.3841858e-06 8.6426735e-06 4.4998527e-03 4.1723251e-06
 2.0861626e-05 6.5267086e-05 4.1425228e-05 2.9802322e-06 3.1011522e+00]
2025-07-28 14:02:54 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:54 - DEBUG - Reward: -1.1875349665452481
2025-07-28 14:02:54 - DEBUG - Reward array: [-0.06347286 -0.06598911 -0.06824819 -0.07024128 -0.07106497 -0.0706542
 -0.06849242 -0.06605078 -0.06336654 -0.57995463]
2025-07-28 14:02:54 - DEBUG - Next state: [0.99171233 0.98957485 0.98771733 0.9861238  0.9854771  0.9857988
 0.9875198  0.98952335 0.99180436 0.99435776]
2025-07-28 14:02:54 - DEBUG - 
end of episode 0, step 178, episode_reward -1215.1853374769476, reward -1.1875349665452481

2025-07-28 14:02:54 - DEBUG - critic loss: 14.333702087402344
2025-07-28 14:02:54 - DEBUG - actor loss: 4.604395866394043
2025-07-28 14:02:54 - DEBUG - Using actor
2025-07-28 14:02:54 - DEBUG - 
start of episode 0, step 179

2025-07-28 14:02:54 - DEBUG - State: [0.99171233 0.98957485 0.98771733 0.9861238  0.9854771  0.9857988
 0.9875198  0.98952335 0.99180436 0.99435776]
2025-07-28 14:02:54 - DEBUG - Action: [3.1590462e-05 2.0861626e-06 7.1525574e-06 3.7330389e-03 3.2782555e-06
 1.6987324e-05 5.4538250e-05 3.4272671e-05 2.3841858e-06 3.0751801e+00]
2025-07-28 14:02:54 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:54 - DEBUG - Reward: -1.0745875799737041
2025-07-28 14:02:54 - DEBUG - Reward array: [-0.05753341 -0.0555099  -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -0.57995462]
2025-07-28 14:02:54 - DEBUG - Next state: [0.99707717 0.9990194  1.         1.         1.         1.
 1.         1.         1.         1.        ]
2025-07-28 14:02:54 - DEBUG - 
end of episode 0, step 179, episode_reward -1216.2599250569212, reward -1.0745875799737041

2025-07-28 14:02:54 - DEBUG - critic loss: 16.157184600830078
2025-07-28 14:02:54 - DEBUG - actor loss: 4.6932878494262695
2025-07-28 14:02:54 - DEBUG - Using actor
2025-07-28 14:02:54 - DEBUG - 
start of episode 0, step 180

2025-07-28 14:02:54 - DEBUG - State: [0.99707717 0.9990194  1.         1.         1.         1.
 1.         1.         1.         1.        ]
2025-07-28 14:02:54 - DEBUG - Action: [2.8014183e-05 1.7881393e-06 6.2584877e-06 3.3292174e-03 2.9802322e-06
 1.4901161e-05 4.7981739e-05 2.9802322e-05 2.0861626e-06 2.6799965e+00]
2025-07-28 14:02:54 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:54 - DEBUG - Reward: -0.8008049282848926
2025-07-28 14:02:54 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05458274 -0.05566591 -0.0603329  -0.30314654]
2025-07-28 14:02:54 - DEBUG - Next state: [1.        1.        1.        1.        1.        1.        0.9999307
 0.9988674 0.9944893 0.9874428]
2025-07-28 14:02:54 - DEBUG - 
end of episode 0, step 180, episode_reward -1217.060729985206, reward -0.8008049282848926

2025-07-28 14:02:54 - DEBUG - critic loss: 19.01426887512207
2025-07-28 14:02:54 - DEBUG - actor loss: 4.635373115539551
2025-07-28 14:02:54 - DEBUG - Using actor
2025-07-28 14:02:54 - DEBUG - 
start of episode 0, step 181

2025-07-28 14:02:54 - DEBUG - State: [1.        1.        1.        1.        1.        1.        0.9999307
 0.9988674 0.9944893 0.9874428]
2025-07-28 14:02:54 - DEBUG - Action: [2.8014183e-05 1.7881393e-06 5.9604645e-06 3.2591820e-03 2.9802322e-06
 1.4603138e-05 4.7683716e-05 2.9504299e-05 2.0861626e-06 2.1795740e+00]
2025-07-28 14:02:54 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:54 - DEBUG - Reward: -1.188167636784048
2025-07-28 14:02:54 - DEBUG - Reward array: [-0.07896005 -0.08822742 -0.09638101 -0.10334875 -0.10963265 -0.11125994
 -0.10690443 -0.09959466 -0.09071005 -0.30314868]
2025-07-28 14:02:54 - DEBUG - Next state: [0.9795976  0.9733333  0.96829015 0.96427315 0.9608517  0.95999414
 0.9623152  0.9664064  0.9717552  0.9779713 ]
2025-07-28 14:02:54 - DEBUG - 
end of episode 0, step 181, episode_reward -1218.2488976219902, reward -1.188167636784048

2025-07-28 14:02:54 - DEBUG - critic loss: 12.975960731506348
2025-07-28 14:02:54 - DEBUG - actor loss: 4.377232551574707
2025-07-28 14:02:54 - DEBUG - Using actor
2025-07-28 14:02:54 - DEBUG - 
start of episode 0, step 182

2025-07-28 14:02:54 - DEBUG - State: [0.9795976  0.9733333  0.96829015 0.96427315 0.9608517  0.95999414
 0.9623152  0.9664064  0.9717552  0.9779713 ]
2025-07-28 14:02:54 - DEBUG - Action: [3.8146973e-05 2.3841858e-06 8.6426735e-06 3.8760900e-03 4.4703484e-06
 1.9967556e-05 6.3776970e-05 3.9637089e-05 2.9802322e-06 1.8192816e+00]
2025-07-28 14:02:54 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:54 - DEBUG - Reward: -0.6495664500328986
2025-07-28 14:02:54 - DEBUG - Reward array: [-0.07038322 -0.06105128 -0.05583539 -0.05567085 -0.05743938 -0.05951919
 -0.06142966 -0.0631484  -0.06465421 -0.10043489]
2025-07-28 14:02:54 - DEBUG - Next state: [0.98601186 0.99384266 0.9987027  0.99886256 0.99716604 0.99523014
 0.9935048  0.9919935  0.9906995  0.9896109 ]
2025-07-28 14:02:54 - DEBUG - 
end of episode 0, step 182, episode_reward -1218.898464072023, reward -0.6495664500328986

2025-07-28 14:02:54 - DEBUG - critic loss: 26.176191329956055
2025-07-28 14:02:54 - DEBUG - actor loss: 4.281923770904541
2025-07-28 14:02:54 - DEBUG - Using actor
2025-07-28 14:02:54 - DEBUG - 
start of episode 0, step 183

2025-07-28 14:02:54 - DEBUG - State: [0.98601186 0.99384266 0.9987027  0.99886256 0.99716604 0.99523014
 0.9935048  0.9919935  0.9906995  0.9896109 ]
2025-07-28 14:02:54 - DEBUG - Action: [2.8908253e-05 1.7881393e-06 6.2584877e-06 3.1644106e-03 3.2782555e-06
 1.4603138e-05 4.8577785e-05 2.9504299e-05 2.0861626e-06 1.4861622e+00]
2025-07-28 14:02:54 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:54 - DEBUG - Reward: -0.6422255719525555
2025-07-28 14:02:54 - DEBUG - Reward array: [-0.06606391 -0.06535023 -0.06390045 -0.06223112 -0.06036317 -0.05831875
 -0.05620904 -0.05497892 -0.05451281 -0.10029716]
2025-07-28 14:02:54 - DEBUG - Next state: [0.98951244 0.9901105  0.9913438  0.9927954  0.9944619  0.9963399
 0.9983412  0.99953955 1.         1.        ]
2025-07-28 14:02:54 - DEBUG - 
end of episode 0, step 183, episode_reward -1219.5406896439756, reward -0.6422255719525555

2025-07-28 14:02:54 - DEBUG - critic loss: 49.54887771606445
2025-07-28 14:02:54 - DEBUG - actor loss: 4.632643699645996
2025-07-28 14:02:54 - DEBUG - Using actor
2025-07-28 14:02:54 - DEBUG - 
start of episode 0, step 184

2025-07-28 14:02:54 - DEBUG - State: [0.98951244 0.9901105  0.9913438  0.9927954  0.9944619  0.9963399
 0.9983412  0.99953955 1.         1.        ]
2025-07-28 14:02:54 - DEBUG - Action: [2.80141830e-05 1.78813934e-06 5.96046448e-06 3.03655863e-03
 3.27825546e-06 1.40070915e-05 4.70876694e-05 2.83122063e-05
 1.78813934e-06 1.24216795e+00]
2025-07-28 14:02:54 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:54 - DEBUG - Reward: -0.5909124261819465
2025-07-28 14:02:54 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -0.10029716]
2025-07-28 14:02:54 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:54 - DEBUG - 
end of episode 0, step 184, episode_reward -1220.1316020701577, reward -0.5909124261819465

2025-07-28 14:02:54 - DEBUG - critic loss: 2.0185060501098633
2025-07-28 14:02:54 - DEBUG - actor loss: 4.434416770935059
2025-07-28 14:02:54 - DEBUG - Using actor
2025-07-28 14:02:54 - DEBUG - 
start of episode 0, step 185

2025-07-28 14:02:54 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:54 - DEBUG - Action: [2.6226044e-05 1.4901161e-06 5.6624413e-06 2.8321147e-03 2.9802322e-06
 1.2814999e-05 4.3809414e-05 2.5928020e-05 1.7881393e-06 1.0469451e+00]
2025-07-28 14:02:54 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:54 - DEBUG - Reward: -0.5909124261819465
2025-07-28 14:02:54 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -0.10029716]
2025-07-28 14:02:54 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:54 - DEBUG - 
end of episode 0, step 185, episode_reward -1220.7225144963397, reward -0.5909124261819465

2025-07-28 14:02:54 - DEBUG - critic loss: 35.81216812133789
2025-07-28 14:02:54 - DEBUG - actor loss: 4.458309650421143
2025-07-28 14:02:54 - DEBUG - Using actor
2025-07-28 14:02:54 - DEBUG - 
start of episode 0, step 186

2025-07-28 14:02:54 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:54 - DEBUG - Action: [2.5629997e-05 1.4901161e-06 5.3644180e-06 2.7397275e-03 2.9802322e-06
 1.2516975e-05 4.2915344e-05 2.5331974e-05 1.7881393e-06 8.7740541e-01]
2025-07-28 14:02:54 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:54 - DEBUG - Reward: -0.5451280684121953
2025-07-28 14:02:54 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -0.05451281]
2025-07-28 14:02:54 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:54 - DEBUG - 
end of episode 0, step 186, episode_reward -1221.267642564752, reward -0.5451280684121953

2025-07-28 14:02:54 - DEBUG - critic loss: 3.536026954650879
2025-07-28 14:02:54 - DEBUG - actor loss: 4.314818859100342
2025-07-28 14:02:54 - DEBUG - Using actor
2025-07-28 14:02:54 - DEBUG - 
start of episode 0, step 187

2025-07-28 14:02:54 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:54 - DEBUG - Action: [2.5033951e-05 1.4901161e-06 5.3644180e-06 2.6512146e-03 2.9802322e-06
 1.2218952e-05 4.2021275e-05 2.4437904e-05 1.4901161e-06 7.2946161e-01]
2025-07-28 14:02:54 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:54 - DEBUG - Reward: -0.5451280684121953
2025-07-28 14:02:54 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -0.05451281]
2025-07-28 14:02:54 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:54 - DEBUG - 
end of episode 0, step 187, episode_reward -1221.812770633164, reward -0.5451280684121953

2025-07-28 14:02:54 - DEBUG - critic loss: 47.68870162963867
2025-07-28 14:02:54 - DEBUG - actor loss: 4.506114959716797
2025-07-28 14:02:54 - DEBUG - Using actor
2025-07-28 14:02:54 - DEBUG - 
start of episode 0, step 188

2025-07-28 14:02:54 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:54 - DEBUG - Action: [2.4437904e-05 1.4901161e-06 5.0663948e-06 2.5662780e-03 2.9802322e-06
 1.1622906e-05 4.0829182e-05 2.3543835e-05 1.4901161e-06 5.9649706e-01]
2025-07-28 14:02:54 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:54 - DEBUG - Reward: -0.5451280684121953
2025-07-28 14:02:54 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -0.05451281]
2025-07-28 14:02:54 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:54 - DEBUG - 
end of episode 0, step 188, episode_reward -1222.3578987015762, reward -0.5451280684121953

2025-07-28 14:02:54 - DEBUG - critic loss: 37.376068115234375
2025-07-28 14:02:54 - DEBUG - actor loss: 4.68419885635376
2025-07-28 14:02:54 - DEBUG - Using actor
2025-07-28 14:02:54 - DEBUG - 
start of episode 0, step 189

2025-07-28 14:02:54 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:54 - DEBUG - Action: [2.3841858e-05 1.4901161e-06 5.0663948e-06 2.4825335e-03 2.9802322e-06
 1.1026859e-05 3.9339066e-05 2.2649765e-05 1.4901161e-06 4.7732502e-01]
2025-07-28 14:02:54 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:54 - DEBUG - Reward: -0.5451280684121953
2025-07-28 14:02:54 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -0.05451281]
2025-07-28 14:02:54 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:54 - DEBUG - 
end of episode 0, step 189, episode_reward -1222.9030267699884, reward -0.5451280684121953

2025-07-28 14:02:54 - DEBUG - critic loss: 39.861595153808594
2025-07-28 14:02:54 - DEBUG - actor loss: 4.7153706550598145
2025-07-28 14:02:54 - DEBUG - Using actor
2025-07-28 14:02:54 - DEBUG - 
start of episode 0, step 190

2025-07-28 14:02:54 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:54 - DEBUG - Action: [2.2947788e-05 1.1920929e-06 4.7683716e-06 2.3987889e-03 2.9802322e-06
 1.0728836e-05 3.7848949e-05 2.1457672e-05 1.1920929e-06 3.7599802e-01]
2025-07-28 14:02:54 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:54 - DEBUG - Reward: -0.9815005369191462
2025-07-28 14:02:54 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05470073 -0.05772676 -0.06908751 -0.08993766
 -0.11430443 -0.13932724 -0.16297274 -0.18441784]
2025-07-28 14:02:54 - DEBUG - Next state: [1.         1.         0.999814   0.99689484 0.98704123 0.972242
 0.95841914 0.94671863 0.9372562  0.9296637 ]
2025-07-28 14:02:54 - DEBUG - 
end of episode 0, step 190, episode_reward -1223.8845273069076, reward -0.9815005369191462

2025-07-28 14:02:54 - DEBUG - critic loss: 17.902170181274414
2025-07-28 14:02:54 - DEBUG - actor loss: 4.3471479415893555
2025-07-28 14:02:54 - DEBUG - Using actor
2025-07-28 14:02:55 - DEBUG - 
start of episode 0, step 191

2025-07-28 14:02:55 - DEBUG - State: [1.         1.         0.999814   0.99689484 0.98704123 0.972242
 0.95841914 0.94671863 0.9372562  0.9296637 ]
2025-07-28 14:02:55 - DEBUG - Action: [2.8610229e-05 1.7881393e-06 5.9604645e-06 2.7483702e-03 3.8743019e-06
 1.3113022e-05 4.6789646e-05 2.6524067e-05 1.7881393e-06 3.1391323e-01]
2025-07-28 14:02:55 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:55 - DEBUG - Reward: -1.24306016482737
2025-07-28 14:02:55 - DEBUG - Reward array: [-0.20151731 -0.19795509 -0.17637906 -0.15201974 -0.1275037  -0.10465098
 -0.08479389 -0.07006118 -0.06412756 -0.06405165]
2025-07-28 14:02:55 - DEBUG - Next state: [0.9241436  0.925259   0.9324146  0.94147813 0.9519935  0.9635492
 0.9755824  0.98626614 0.99114895 0.99121404]
2025-07-28 14:02:55 - DEBUG - 
end of episode 0, step 191, episode_reward -1225.1275874717348, reward -1.24306016482737

2025-07-28 14:02:55 - DEBUG - critic loss: 16.867551803588867
2025-07-28 14:02:55 - DEBUG - actor loss: 3.6315622329711914
2025-07-28 14:02:55 - DEBUG - Using actor
2025-07-28 14:02:55 - DEBUG - 
start of episode 0, step 192

2025-07-28 14:02:55 - DEBUG - State: [0.9241436  0.925259   0.9324146  0.94147813 0.9519935  0.9635492
 0.9755824  0.98626614 0.99114895 0.99121404]
2025-07-28 14:02:55 - DEBUG - Action: [3.4570694e-05 2.0861626e-06 7.4505806e-06 3.0949712e-03 5.0663948e-06
 1.6093254e-05 5.5730343e-05 3.1590462e-05 2.0861626e-06 2.6076376e-01]
2025-07-28 14:02:55 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:55 - DEBUG - Reward: -0.8430321808280135
2025-07-28 14:02:55 - DEBUG - Reward array: [-0.06478468 -0.06570466 -0.06578206 -0.06517248 -0.06741032 -0.07518312
 -0.08909378 -0.10473016 -0.11803377 -0.12713717]
2025-07-28 14:02:55 - DEBUG - Next state: [0.99058867 0.9898128  0.98974794 0.9902604  0.98839974 0.9823412
 0.97277814 0.96350545 0.95653975 0.9521638 ]
2025-07-28 14:02:55 - DEBUG - 
end of episode 0, step 192, episode_reward -1225.9706196525628, reward -0.8430321808280135

2025-07-28 14:02:55 - DEBUG - critic loss: 27.706607818603516
2025-07-28 14:02:55 - DEBUG - actor loss: 3.263331174850464
2025-07-28 14:02:55 - DEBUG - Using actor
2025-07-28 14:02:55 - DEBUG - 
start of episode 0, step 193

2025-07-28 14:02:55 - DEBUG - State: [0.99058867 0.9898128  0.98974794 0.9902604  0.98839974 0.9823412
 0.97277814 0.96350545 0.95653975 0.9521638 ]
2025-07-28 14:02:55 - DEBUG - Action: [2.5331974e-05 1.4901161e-06 5.0663948e-06 2.5072694e-03 3.5762787e-06
 1.1026859e-05 4.0829182e-05 2.2649765e-05 1.4901161e-06 1.8824905e-01]
2025-07-28 14:02:55 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:55 - DEBUG - Reward: -10.587422042874191
2025-07-28 14:02:55 - DEBUG - Reward array: [-0.13338174 -0.1513526  -0.19669933 -0.29245378 -0.49822669 -0.88845568
 -1.49123572 -2.08511831 -2.37703846 -2.47345972]
2025-07-28 14:02:55 - DEBUG - Next state: [0.94931954 0.9417438  0.9256564  0.9002282  0.86365    0.81991607
 0.775892   0.74395865 0.73050743 0.72629833]
2025-07-28 14:02:55 - DEBUG - 
end of episode 0, step 193, episode_reward -1236.558041695437, reward -10.587422042874191

2025-07-28 14:02:55 - DEBUG - critic loss: 13.68520736694336
2025-07-28 14:02:55 - DEBUG - actor loss: 3.171687602996826
2025-07-28 14:02:55 - DEBUG - Using actor
2025-07-28 14:02:55 - DEBUG - 
start of episode 0, step 194

2025-07-28 14:02:55 - DEBUG - State: [0.94931954 0.9417438  0.9256564  0.9002282  0.86365    0.81991607
 0.775892   0.74395865 0.73050743 0.72629833]
2025-07-28 14:02:55 - DEBUG - Action: [1.0162592e-04 8.0466270e-06 2.4139881e-05 6.0957670e-03 1.7881393e-05
 4.9173832e-05 1.5586615e-04 9.1195107e-05 7.7486038e-06 2.3296565e-01]
2025-07-28 14:02:55 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:55 - DEBUG - Reward: -14.78197889608545
2025-07-28 14:02:55 - DEBUG - Reward array: [-2.55861841 -2.73666586 -2.95130505 -2.76622506 -1.92551789 -1.01607429
 -0.45965157 -0.20338026 -0.10105735 -0.06348315]
2025-07-28 14:02:55 - DEBUG - Next state: [0.72266483 0.7152987  0.7067842  0.7141037  0.7518454  0.8090179
 0.8693855  0.9235671  0.9655669  0.99170345]
2025-07-28 14:02:55 - DEBUG - 
end of episode 0, step 194, episode_reward -1251.3400205915225, reward -14.78197889608545

2025-07-28 14:02:55 - DEBUG - critic loss: 18.474163055419922
2025-07-28 14:02:55 - DEBUG - actor loss: 3.3995120525360107
2025-07-28 14:02:55 - DEBUG - Using actor
2025-07-28 14:02:55 - DEBUG - 
start of episode 0, step 195

2025-07-28 14:02:55 - DEBUG - State: [0.72266483 0.7152987  0.7067842  0.7141037  0.7518454  0.8090179
 0.8693855  0.9235671  0.9655669  0.99170345]
2025-07-28 14:02:55 - DEBUG - Action: [1.5348196e-04 1.3411045e-05 3.8444996e-05 7.9339743e-03 2.9504299e-05
 7.5995922e-05 2.3156404e-04 1.3798475e-04 1.2516975e-05 2.1937847e-01]
2025-07-28 14:02:55 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:55 - DEBUG - Reward: -0.5451280684121953
2025-07-28 14:02:55 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -0.05451281]
2025-07-28 14:02:55 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:55 - DEBUG - 
end of episode 0, step 195, episode_reward -1251.8851486599347, reward -0.5451280684121953

2025-07-28 14:02:55 - DEBUG - critic loss: 27.46588706970215
2025-07-28 14:02:55 - DEBUG - actor loss: 3.8478360176086426
2025-07-28 14:02:55 - DEBUG - Using actor
2025-07-28 14:02:55 - DEBUG - 
start of episode 0, step 196

2025-07-28 14:02:55 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:55 - DEBUG - Action: [1.6987324e-05 8.9406967e-07 3.2782555e-06 1.9180775e-03 2.3841858e-06
 6.8545341e-06 2.7418137e-05 1.4603138e-05 8.9406967e-07 8.2483292e-02]
2025-07-28 14:02:55 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:55 - DEBUG - Reward: -0.5451280684121953
2025-07-28 14:02:55 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -0.05451281]
2025-07-28 14:02:55 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:55 - DEBUG - 
end of episode 0, step 196, episode_reward -1252.4302767283468, reward -0.5451280684121953

2025-07-28 14:02:55 - DEBUG - critic loss: 28.645484924316406
2025-07-28 14:02:55 - DEBUG - actor loss: 4.526484489440918
2025-07-28 14:02:55 - DEBUG - Using actor
2025-07-28 14:02:55 - DEBUG - 
start of episode 0, step 197

2025-07-28 14:02:55 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:55 - DEBUG - Action: [1.6093254e-05 8.9406967e-07 2.9802322e-06 1.8325448e-03 2.3841858e-06
 6.2584877e-06 2.5629997e-05 1.3411045e-05 5.9604645e-07 6.3191056e-02]
2025-07-28 14:02:55 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:55 - DEBUG - Reward: -0.5451280684121953
2025-07-28 14:02:55 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -0.05451281]
2025-07-28 14:02:55 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:55 - DEBUG - 
end of episode 0, step 197, episode_reward -1252.975404796759, reward -0.5451280684121953

2025-07-28 14:02:55 - DEBUG - critic loss: 15.39754867553711
2025-07-28 14:02:55 - DEBUG - actor loss: 3.699843406677246
2025-07-28 14:02:55 - DEBUG - Using actor
2025-07-28 14:02:55 - DEBUG - 
start of episode 0, step 198

2025-07-28 14:02:55 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:55 - DEBUG - Action: [1.4901161e-05 5.9604645e-07 2.6822090e-06 1.7437339e-03 2.0861626e-06
 5.9604645e-06 2.4139881e-05 1.2516975e-05 5.9604645e-07 4.8205256e-02]
2025-07-28 14:02:55 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:55 - DEBUG - Reward: -0.5451280684121953
2025-07-28 14:02:55 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -0.05451281]
2025-07-28 14:02:55 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:55 - DEBUG - 
end of episode 0, step 198, episode_reward -1253.5205328651712, reward -0.5451280684121953

2025-07-28 14:02:55 - DEBUG - critic loss: 4.636315822601318
2025-07-28 14:02:55 - DEBUG - actor loss: 2.729840040206909
2025-07-28 14:02:55 - DEBUG - Using actor
2025-07-28 14:02:55 - DEBUG - 
start of episode 0, step 199

2025-07-28 14:02:55 - DEBUG - State: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:55 - DEBUG - Action: [1.40070915e-05 5.96046448e-07 2.38418579e-06 1.65581703e-03
 2.08616257e-06 5.36441803e-06 2.26497650e-05 1.16229057e-05
 5.96046448e-07 3.71170044e-02]
2025-07-28 14:02:55 - DEBUG - Recovery bound: 0.6
2025-07-28 14:02:55 - DEBUG - Reward: -0.5451280684121953
2025-07-28 14:02:55 - DEBUG - Reward array: [-0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281 -0.05451281
 -0.05451281 -0.05451281 -0.05451281 -0.05451281]
2025-07-28 14:02:55 - DEBUG - Next state: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
2025-07-28 14:02:55 - DEBUG - 
end of episode 0, step 199, episode_reward -1254.0656609335833, reward -0.5451280684121953

2025-07-28 14:02:55 - DEBUG - critic loss: 5.070734977722168
2025-07-28 14:02:55 - DEBUG - actor loss: 2.153733730316162
